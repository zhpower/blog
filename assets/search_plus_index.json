{"/blog/jekyll/2024-04-27-git.html": {
    "title": "git",
    "keywords": "Jekyll",
    "url": "/blog/jekyll/2024-04-27-git.html",
    "body": "在Git中，你可以使用git diff命令来比较不同分支中某个文件的差异。以下是具体的命令： git diff &lt;branch1&gt;..&lt;branch2&gt; -- &lt;file&gt; 其中，&lt;branch1&gt;和&lt;branch2&gt;是你想要比较的两个分支的名称，&lt;file&gt;是你想要比较的文件的路径。这个命令会显示出&lt;branch1&gt;和&lt;branch2&gt;之间&lt;file&gt;的差异。 例如，如果你想要比较master分支和dev分支中README.md文件的差异，你可以使用以下命令： git diff master..dev -- README.md 这个命令会显示出master分支和dev分支中README.md文件的差异。希望这个信息对你有所帮助！"
  },"/blog/jekyll/2022-05-02-App_misc.html": {
    "title": "linux dev misc",
    "keywords": "Jekyll",
    "url": "/blog/jekyll/2022-05-02-App_misc.html",
    "body": "pthread_mutex_t&amp;pthread_cond_t 函数定义： int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex) int pthread_cond_broadcast(pthread_cond_t *cond) 函数说明： pthread_cond_wait ：有两个输入参数，一个是pthread_cond_t，是函数将要等待的信号，另一个是 pthread_mutex_t，一个互斥锁。用于对信号量进行保护，防止多个线程同时对其进行操作。在线程开始等待信号量前，必须由本线程对互斥锁进行锁定，然后pthread_cond_wait会更新条件等待队列，并且释放互斥量，允许其他线程进行访问；当cond 满足条件允许线程继续执行时，wait_cond也会先对mutex 进行锁定，对cond进行处理，然后再允许线程继续运行。所以pthread_cond_wait() 后的pthread_mutex_unlock()还是必要的。 #include &lt;pthread.h&gt; #include &lt;iostream&gt; #include &lt;unistd.h&gt; using namespace std; static pthread_mutex_t mtx = PTHREAD_MUTEX_INITIALIZER; static pthread_cond_t cond = PTHREAD_COND_INITIALIZER; static void* func_1(void* arg){ cout &lt;&lt; \"func_1 start\" &lt;&lt; endl; pthread_mutex_lock(&amp;mtx); cout &lt;&lt; \"func_1 lock mtx\" &lt;&lt; endl; cout &lt;&lt; \"func_1 wait cond\" &lt;&lt; endl; pthread_cond_wait(&amp;cond, &amp;mtx); cout &lt;&lt; \"func_1 unlock mtx\" &lt;&lt; endl; pthread_mutex_unlock(&amp;mtx); cout &lt;&lt; \"func_1 end\" &lt;&lt; endl; sleep(5); return NULL; } static void* func_2(void* arg){ cout &lt;&lt; \"func_2 start\" &lt;&lt; endl; pthread_mutex_lock(&amp;mtx); cout &lt;&lt; \"func_2 lock mtx\" &lt;&lt; endl; cout &lt;&lt; \"func_2 wait cond\" &lt;&lt; endl; pthread_cond_wait(&amp;cond, &amp;mtx); cout &lt;&lt; \"func_2 unlock mtx\" &lt;&lt; endl; pthread_mutex_unlock(&amp;mtx); cout &lt;&lt; \"func_2 end\" &lt;&lt; endl; sleep(5); return NULL; } int main(){ pthread_t tid1, tid2; cout &lt;&lt; \"main create thread\" &lt;&lt; endl; pthread_create(&amp;tid1, NULL, func_1, NULL); pthread_create(&amp;tid2, NULL, func_2, NULL); sleep(3); cout &lt;&lt; \"main boradcast signal\" &lt;&lt; endl; pthread_cond_broadcast(&amp;cond); // pthread_cond_signal(&amp;cond); cout &lt;&lt; \"main join thread\" &lt;&lt; endl; pthread_join(tid1, NULL); pthread_join(tid2, NULL); cout &lt;&lt; \"main end\" &lt;&lt; endl; return 0; } char *a vs char a[] 首先要搞清楚编译程序占用的内存的分区形式： 一、预备知识—程序的内存分配 一个由c/C++编译的程序占用的内存分为以下几个部分: 栈区（stack）—由编译器自动分配释放，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈。 堆区（heap）—一般由程序员分配释放，若程序员不释放，程序结束时可能由OS回收。注意它与数据结构中的堆是两回事，分配方式倒是类似于链表，呵呵。 全局区（静态区）（static）—全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域，未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。程序结束后由系统释放。 字符常量区—常量字符串就是放在这里的。程序结束后由系统释放。 程序代码区 这是一个别人写的，非常详细 int a=0; //全局初始化区 char p1; //全局未初始化区 main() { int b; //栈 char s[]=\"abc\"; //栈 char p2; //栈 char p3=\"123456\"; //123456\\0在常量区，p3在栈上。 static int c = 0; //全局（静态）初始化区 p1 = (char)malloc(10); p2 = (char)malloc(20); //分配得来得10和20字节的区域就在堆区。 strcpy(p1,\"123456\"); //123456\\0放在常量区，编译器可能会将它与p3指向的\"123456\"优化成一个地方。 } 首先，我们要知道 char *a中的a是个指向字符类型的指针，这是一个变量； char a[]中的a也是一个指向字符类型的指针，但它是一个常量，常量是不能再给它赋值的，就像比不能写 3=2 这样的代码来给3赋值, 但可以对她指向的内存内容进行修改。 通过阅读我们可以知道，char * a=“abc”和char a[]=”abc”在内存中存放是有差别的， char *a=“abc”中的“abc”是存放于字符常量区的，指针a只是指向了这个地址； char a[]=”abc”中的“abc”其实是放在栈中的，它是字符常量区中“abc”的一份拷贝。 看看下面这段代码你就明白了 #include &lt;stdio.h&gt; int main() { char * a1 = \"abc\"; char a2[] = \"abc\"; char * a3 = \"abc\"; char a4[] = \"abc\"; printf(\"char * a:%p\\n\", a1);//打印a1的值 printf(\"char a2[]:%p\\n\",a2);//打印a2的值 printf(\"char *a3:%p\\n\", a3);//打印a2的值 printf(\"char a4[]:%p\\n\",a4);//打印a2的值 return 0; } 我在这段代码里声明了两个字符指针变量、两个数组常量指针，代码执行结果如下： 显而易见字符指针变量a 和a3的值是一样的，这说明它们指向同一块内存，这块内存就是上文所说的字符常量区； 字符数组指针a2和a3的值不同且相差4字节，这说明它们指向的内存是不相同的，它们的“abc”其实是对字符常量区中“abc”的一份拷贝，并且数据是存放在栈中的，至于它们的地址相差四个字节，是因为字符数组中在结尾加了一个结束符——‘\\0’（也称为NUL）。 至于之前说的“不能直接将一个字符串常量赋值给字符数组”可以这样理解：的确是不能直接赋值，但可以通过复制以后再赋值呀，即把字符串拷贝到栈中，然后给数组指针赋值！代码的话就是：char a[]=“abc”。 我们再来考虑一个问题：能不能修改char *a指向的字符常量区的值呢？ 代码如下： #include &lt;stdio.h&gt; #include &lt;string.h&gt; int main() { char * a=\"abc\"; *a = 'b'; printf(\"%c\\n\",*a); return 0; } 我将指针a所指向的第一个字符——‘a’修改为字符‘b’。 结果程序崩溃了 这说明字符常量区的数据是不可以修改的！为什么呢？因为在你的程序中可能有很多个类似于char *a这样的指针变量在使用到了字符常量区的“abc”，如果你在这里通过指针修改了“abc”的值，那么程序中使用“abc”的其他地方就变得不确定了！ 其实如果你翻看了《c和指针》你还会发现，在K&amp;R C标准中，这里的修改操作是可以的，因为在该标准中字符串常量是分开存储的，而不是只存储在一个地方。 怎么样，有没有感受到C语言指针的危险和魅力所在？ char a[ ] 的应用场景: 编译器首先判断数组的容量，然后分配一片内存来存储数组的每个元素。如果是字符串赋值方式，则容量是strlen(字符串)+1, 赋值时在尾部加 0 char a[ ] 必须在申明的同时给它赋值， 否则编译器无法知道应该分配多大的内存给该数组 //如下操作会导致 编译错误，编译器不能知道d这个数组的大小 char d[]; char d[] = a; char a[ ]的两种赋值方式， char a[ ]的优点 char a[] = \"dfdsfsdfas\"; // char a[]的优点 直接把字符串复制给某个数组，长度+1 char a[] = {'a','a','b','c'}; // 不会有结尾符\\0 sizeof(a) 返回的是 a数组容量 * sizeof(a[0]) char *s = “dfdsf” 的应该场景: 把s指向内存的字符串常量区，不能通过s[index] 来修改它, 修改则会crash sizeof(s) 返回的是 sizeof(char *) #include &lt;stdio.h&gt; /*----------------------------------------------------------------------------- * char b[], 遵循 “右左原则 ” 来查看变量的类型， 所以它是一个数组，字符数组 * 它有两种赋值方式 * 1. char b[] = {'1','2','3'}; * 2. char b[] = \"123\"; 等价与 char b[4] = {'1','2','3', 0}; *------------------------------------------------------------------------------*/ int main(int argc, char *argv[]){ char *a = \"12345\"; // a 是指针， 指向了字符常量区中\"12345\"的地址 char b[] = \"12345\"; // b 是首先是数组，存储的元素是{'1', '2','3','4', '5', 0}; char bb[] = {'1', '2','3','4', '5'}; // bb 是没有结尾符的 char bbb[5] = {'1', '2','3','4', '5'}; int c[] = {1,2,3,4,5}; // char a[ ] 需要在申明的同时给它赋值， 否则编译器无法知道应该分配多大的内存给该数组 // 编译错误，编译器不能知道d这个数组的大小 // char d[]; // char d[] = a; // 编译错误 把指针赋值数组 // b = a; //sizeof 返回变量占用的内存大小 // 数组的sizeof 计算是 sizeof(成员)×数目 printf(\"sizeof(a):%ld sizeof(b):%ld sizeof(bb):%ld sizeof(bbb):%ld sizeof(c):%ld\\n\", \\ sizeof(a), sizeof(b), sizeof(bb), sizeof(bbb), sizeof(c)); b[2] = 'g'; printf(\"%s():%d\\n\",__FUNCTION__,__LINE__); a[2] = 'r'; // 修改字符常量区会导致 crash printf(\"%s():%d\\n\",__FUNCTION__,__LINE__); a = \"dfasdfa\"; printf(\"%s\\n\",a); return 0; } 输出如下: sizeof(a):8 sizeof(b):6 sizeof(bb):5 sizeof(bbb):5 sizeof(c):20 main():23 Segmentation fault (core dumped) mmap() 以下是mmap()函数实现的基本过程： kernel在当前进程的虚拟地址空间中分配满足条件的虚拟地址块 分配vm_area_struct结构来管理该虚拟地址块，并插入到进程的虚拟地址区域链表中 通过文件描述符，找到对应设备驱动注册的file_operations,并调用它的mmap函数。 在该文件描述符的mmap中，通过调用remap_pfn_range函数来建立页表，并记录文件地址和虚拟地址的映射关系。 此时只是虚拟地址，并没有关联到内存。 进程在读写该地址时，触发缺页，从而分配内存，载入文件数据，建立虚拟地址与内存的映射。 fork() 的进程空间 当父进程使用 malloc 分配内存后，这块内存可以被它 fork 的子进程访问。让我详细解释一下。 内存分配： 父进程使用 malloc 分配的内存位于堆（heap）中。这块内存用于存储动态分配的数据，例如字符串、数组等。 fork 过程： 当父进程调用 fork 创建子进程时，操作系统会复制父进程的地址空间。 这包括代码段、数据段、堆和栈。但是，实际的复制并不会立即发生。 Copy-on-Write（写时复制）： 写时复制是一种优化策略，用于避免不必要的内存复制。 在 fork 之后，父子进程共享相同的物理内存页，但这些页被标记为只读。 如果父进程或子进程尝试修改这些共享的内存页，操作系统会创建一个副本，使得父子进程之间不会相互影响。 因此，父进程和子进程仍然可以访问 fork 之前分配的所有数据，包括使用 malloc 分配的堆内存。 总之，父进程使用 malloc 分配的内存可以被它 fork 的子进程访问，但在修改时会进行复制，以保持数据的独立性¹²。 如果您还有其他问题，欢迎继续提问！ 😊"
  },"/blog/jekyll/2022-04-27-bit.html": {
    "title": "位运算",
    "keywords": "Jekyll",
    "url": "/blog/jekyll/2022-04-27-bit.html",
    "body": "1.位运算概述 从现代计算机中所有的数据二进制的形式存储在设备中。即 0、1 两种状态，计算机对二进制数据进行的运算(+、-、*、\\/)都是叫位运算，即将符号位共同参与运算的运算。 口说无凭，举一个简单的例子来看下 CPU 是如何进行计算的，比如这行代码： int a = 35; int b = 47; int c = a + b; 计算两个数的和，因为在计算机中都是以二进制来进行运算，所以上面我们所给的 int 变量会在机器内部先转换为二进制在进行相加： 35: 0 0 1 0 0 0 1 1 47: 0 0 1 0 1 1 1 1 ———————————————————— 82: 0 1 0 1 0 0 1 0 所以，相比在代码中直接使用(+、-、*、/ )运算符，合理的运用位运算更能显著提高代码在机器上的执行效率。 2.位运算概览 ![[image-20230313173955848.png]] 3.与运算符&amp; 定义：参加运算的两个数据，按二进制位进行”与”运算。 3.1 运算规则： 0&amp;0=0 0&amp;1=0 1&amp;0=0 1&amp;1=1 总结：两位同时为1，结果才为1，否则结果为0。 例如：3&amp;5 即 0000 0011&amp; 0000 0101 = 0000 0001，因此 3&amp;5 的值得1。 注意：负数按补码形式参加按位与运算。 3.2 与运算符用途 3.2.1清零 如果想将一个单元清零，即使其全部二进制位为0，只要与一个各位都为零的数值相与，结果为零。 3.2.2取一个数的指定位 比如取数 X=1010 1110 的低4位，只需要另找一个数Y，令Y的低4位为1，其余位为0，即Y=0000 1111，然后将X与Y进行按位与运算（X&amp;Y=0000 1110）即可得到X的指定位。 3.2.3判断奇偶 只要根据最未位是0还是1来决定，为0就是偶数，为1就是奇数。因此可以用if ((a \\&amp; 1) == 0)代替if (a \\% 2 == 0)来判断a是不是偶数。 4 或运算符| 定义：参加运算的两个对象，按二进制位进行”或”运算。 4.1运算规则： 0 0=0 0 1=1 1 0=1 1 1=1 总结：参加运算的两个对象只要有一个为1，其值为1。 例如：3 5即 0000 0011 0000 0101 = 0000 0111，因此，3 5的值得7。　 注意：负数按补码形式参加按位或运算。 4.2或运算的用途： 4.2.1常用来对一个数据的某些位设置为1 比如将数 X=1010 1110 的低4位设置为1，只需要另找一个数Y，令Y的低4位为1，其余位为0，即Y=0000 1111，然后将X与Y进行按位或运算（X Y=1010 1111）即可得到。 5异或运算符^ 定义：参加运算的两个数据，按二进制位进行”异或”运算。 5.1 运算规则： 0^0=0 0^1=1 1^0=1 1^1=0 总结：参加运算的两个对象，如果两个相应位相同为0，相异为1。 异或的几条性质: 1、交换律 2、结合律 (a^b)^c == a^(b^c) 3、对于任何数x，都有 x^x=0，x^0=x 4、自反性: a^b^b=a^0=a; 5.2 异或运算的用途： 5.2.1翻转指定位 比如将数 X=1010 1110 的低4位进行翻转，只需要另找一个数Y，令Y的低4位为1，其余位为0，即Y=0000 1111，然后将X与Y进行异或运算（X^Y=1010 0001）即可得到。 5.2.2与0相异或值不变 例如：1010 1110 ^ 0000 0000 = 1010 1110 5.2.3交换两个数 void Swap(int &amp;a, int &amp;b){     if (a != b){         a ^= b;         b ^= a;         a ^= b;     } } 6取反运算符~ 定义：参加运算的一个数据，按二进制进行”取反”运算。 6.1 运算规则：　 ~1=0 ~0=1 总结：对一个二进制数按位取反，即将0变1，1变0。 6.2 取反运算符的用途： 6.2.1使一个数的最低位为零 使a的最低位为0，可以表示为：a &amp; ~1。~1的值为 1111 1111 1111 1110，再按”与”运算，最低位一定为0。因为” ~”运算符的优先级比算术运算符、关系运算符、逻辑运算符和其他运算符都高。 7.左移运算符« 定义：将一个运算对象的各二进制位全部左移若干位（左边的二进制位丢弃，右边补0）。 设 a=1010 1110，a = a« 2 将a的二进制位左移2位、右补0，即得a=1011 1000。 7.1 «1 左移 1位 相当于乘2 若左移时舍弃的高位不包含1，则每左移一位，相当于该数乘以2。 8右移运算符» 定义：将一个数的各二进制位全部右移若干位，正数左补0，负数左补1，右边丢弃。 例如：a=a»2 将a的二进制位右移2位，左补0 或者 左补1得看被移数是正还是负。 8.1 »1 右移一位相当于除2 操作数每右移一位，相当于该数除以2。 9复合赋值运算符 位运算符与赋值运算符结合，组成新的复合赋值运算符，它们是： &amp;= 例：a&amp;=b 相当于 a=a&amp;b = 例：a =b 相当于 a=a b &gt;&gt;= 例：a»=b 相当于 a=a»b «= 例：a«=b 相当于 a=a« b ^= 例：a^=b 相当于 a=a^b 运算规则：和前面讲的复合赋值运算符的运算规则相似。 不同长度的数据进行位运算：如果两个不同长度的数据进行位运算时，系统会将二者按右端对齐，然后进行位运算。 以”与运算”为例说明如下：我们知道在C语言中long型占4个字节，int型占2个字节，如果一个long型数据与一个int型数据进行”与运算”，右端对齐后，左边不足的位依下面三种情况补足， 1）如果整型数据为正数，左边补16个0。 2）如果整型数据为负数，左边补16个1。 3）如果整形数据为无符号数，左边也补16个0。 如：long a=123；int b=1；计算a&amp; b。 如：long a=123；int b=-1；计算a&amp; b。 如：long a=123；unsigned intb=1；计算a &amp; b。"
  },"/blog/jekyll/2021-04-27-ffmpeg.html": {
    "title": "ffmpeg命令",
    "keywords": "Jekyll",
    "url": "/blog/jekyll/2021-04-27-ffmpeg.html",
    "body": "01. 视频分割 ffmpeg -ss 00:00:00 -i input.mp4 -c copy -t 60 output.mp4 -ss 表示视频分割的起始时间，-t 表示分割时长，同时也可以用 00:01:00表示 注意-ss 要放在 -i 之前 02. 视频区域裁剪： ffmpeg -i 3.mkv -filter_complex crop=1024:50:0:550 -y 4.mkv 03. 视频预览 ffplay 3.mkv -vf crop=1024:50:0:550 04. 视频放大,缩小 ffmpeg -i 2.mp4 -vf \"scale=1280:64\" 4.mp4 scale =w:h 表示放大后的大小 05. 列出所有format list all pix format ffmpeg -pix_fmts 06. 图片转换 ffmpeg -itemp.jpg-s1024x680-pix_fmtyuvj420p9.yuv ffmpeg.exe -i agf-dog-1280x960.jpg -vf scale=1920:1080 agf-dog-1920x1080.jpg 07. 视频format转换 YUV -&gt; RGB ffmpeg -s 360x270 -pix_fmt yuv420p -i 2_test_360x270_50.yuv -pix_fmt rgb24 aaaa.rgb ffmpeg -s 640x480 -pix_fmt nv12 -i 640x480_1.jpg -vf scale=640:480,setsar=1:1 640x480_1_nv12.yuv -hide_banner 08. 视频叠加 ffmpeg -i input1 -i input2 -filter_complex overlay=x:youtput 09. 视频旋转 mp4向左旋转90度 ffmpeg -i input.mp4 -metadata:s:v rotate=\"90\" -codec copy outut.mp4 mp4向右旋转90度 ffmpeg -i input.mp4 -metadata:s:v rotate=\"-90\" -codec copy outut.mp4 10. 视频镜像 mp4左右镜像翻转 ffmpeg -i input.mp4 -vf \"hflip\" outut.mp4 mp4上下镜像翻转 ffmpeg -i input.mp4 -vf \"vflip\" outut.mp4 11. mp4转raw data ffmpeg -i video.mp4 -c:v rawvideo -pix_fmt yuv420p out.yuv ffmpeg -i input.mp4 -vf \"format=nv12\" -c:v rawvideo -an output.nv12 ffmpeg -i input.mp4 -pix_fmt nv21 -f rawvideo output.nv21 12. 图片旋转 图片向右旋转90度 ffmpeg -i input.png -vf rotate='90*PI/180' -y rotate60.png 图片向右旋转90度 ffmpeg -i input.png -vf rotate='-90*PI/180' -y rotate_90.png 图片像左旋转90度 ffmpeg -i input.png -vf transpose=2 -y transpose2.png 图片像右旋转90度 ffmpeg -i input.png -vf transpose=1 -y transpose2.png 逆时针(向左)旋转90°，然后垂直（上下）翻转 ffmpeg -i input.png -vf transpose=0 -y transpose0.png 13. 图片镜像 图片左右镜像翻转 ffmpeg -i input.png -vf hflip -y hflip.png 图片上下镜像翻转 ffmpeg -i input.png -vf vflip -y vflip.png yuv数据左右镜像翻转 ffmpeg -s 1920x1080 -pix_fmt nv12 -i nv12_1.yuv -vf hflip -y hflip_nv12.yuv 播放左右翻转后的yuv数据 ffplay -video_size 1920x1080 -pixel_format nv12 hflip_nv12.yuv 14. 音频音量调节大小 音量翻倍，写在滤镜里 ffmpeg -i input.wav -af volume=2 -y output.wav 音量翻倍，不写在滤镜中 ffmpeg -i input.wav -vol 2000 -y output.wav 15. 调节播放速度 ffmpeg -i test1.mp4 -vf \"setpts=0.25*PTS\" test2.mp4 四倍慢速： ffmpeg -i test1.mp4 -vf \"setpts=4*PTS\" test2.mp4"
  },"/blog/jekyll/2020-10-02-FuncTrace.html": {
    "title": "Function Trace",
    "keywords": "Jekyll",
    "url": "/blog/jekyll/2020-10-02-FuncTrace.html",
    "body": "函数跟踪 __cyg_profile_func_enter 和 __cyg_profile_func_exit 是用于函数调用追踪的特殊函数。当你使用 -finstrument-functions编译选项时，编译器会在每个函数的开始和结束处插入这两个函数. 这样，你可以实现函数调用的检测和分析。 这里是一个简单的例子，首先我们有一个用于跟踪函数的 func_trace.c 文件： #include &lt;stdio.h&gt; static FILE *fp_trace; void __attribute__((constructor)) traceBegin(void) { fp_trace = fopen(\"func_trace.out\", \"w\"); } void __attribute__((destructor)) traceEnd(void) { if (fp_trace != NULL) { fclose(fp_trace); } } void __cyg_profile_func_enter(void *func, void *caller) { if (fp_trace != NULL) { fprintf(fp_trace, \"entry %p %p\\n\", func, caller); } } void __cyg_profile_func_exit(void *func, void *caller) { if (fp_trace != NULL) { fprintf(fp_trace, \"exit %p %p\\n\", func, caller); } } 然后，我们编写一个简单的测试代码 main.c： #include &lt;stdio.h&gt; int foo(void) { return 2; } int bar(void) { zoo(); return 1; } void zoo(void) { foo(); } int main(int argc, char **argv) { bar(); } 接下来，将 main.c 与 func_trace.o 一起编译，并加上 -finstrument-functions 选项： gcc main.c func_trace.o -finstrument-functions 运行 ./a.out，就会产生 func_trace.out 文件，其中记录了函数调用的信息。你可以使用 addr2line 命令来查看函数名： addr2line -f -e ./a.out $ADDRESS 这样，你就可以得到函数调用关系。如果想进一步处理这些跟踪数据，可以使用工具如 graphviz 来创建可视化的调用关系图。 自动化单元测试"
  },"/blog/jekyll/2020-06-22-misc.html": {
    "title": "Kernel Misc",
    "keywords": "Jekyll",
    "url": "/blog/jekyll/2020-06-22-misc.html",
    "body": "kref kref_init 是一个用于初始化内核对象引用计数器（krefs）的函数。它允许你为你的对象添加引用计数，确保在多个地方使用和传递对象时，代码的正确性。以下是关于 kref_init 的一些重要信息： 初始化： 在分配内存并创建对象后，你需要调用 kref_init 来初始化引用计数器。例如： struct my_data *data; data = kmalloc(sizeof(*data), GFP_KERNEL); if (!data) return -ENOMEM; kref_init(&amp;data-&gt;refcount); 这将在 kref 中的 refcount 设置为 1。 使用规则： 在对指针进行非临时拷贝（尤其是传递给另一个执行线程）之前，必须使用 kref_get 增加引用计数。 在完成对指针的处理后，必须调用 kref_put。如果这是对指针的最后一次引用，释放程序将被调用。 示例： void data_release(struct kref *ref) { struct my_data *data = container_of(ref, struct my_data, refcount); kfree(data); } void more_data_handling(void *cb_data) { struct my_data *data = cb_data; // 处理 data kref_put(&amp;data-&gt;refcount, data_release); } int my_data_handler(void) { int rv = 0; struct my_data *data; data = kmalloc(sizeof(*data), GFP_KERNEL); if (!data) return -ENOMEM; kref_init(&amp;data-&gt;refcount); kref_get(&amp;data-&gt;refcount); // 创建线程处理数据 // ... kref_put(&amp;data-&gt;refcount, data_release); return rv; } 在上述示例中，两个线程处理数据的顺序并不重要，kref_put 会在数据不再被引用时释放它。 请注意，遵循这些规则可以确保正确管理内核对象的引用计数，避免内存泄漏和悬挂指针。 IDR(ID Range) IDR 是一种用于管理连续整数范围的数据结构，通常用于内核中需要为对象分配唯一标识符的场景。 idr_alloc 函数用于在 Linux 内核中分配 IDR（ID Range）对象中的未使用的 ID。 以下是 idr_alloc 函数的用法： 首先，您需要初始化一个 IDR。对于静态分配的 IDR，您可以使用 DEFINE_IDR() 宏；对于动态分配的 IDR，您可以使用 idr_init() 函数。 调用 idr_alloc() 来分配一个未使用的 ID。 使用 idr_find() 查询与该 ID 相关的指针。 使用 idr_remove() 释放该 ID。 如果需要更改与某个 ID 相关联的指针，您可以调用 idr_replace()。这通常用于保留 ID，通过将 NULL 指针传递给分配函数，然后使用保留的 ID 初始化对象，最后将初始化的对象插入 IDR。 到目前为止，所有用户都满足了 UINT_MAX 的限制，因此他们使用 idr_alloc_u32()。 如果需要按顺序分配 ID，您可以使用 idr_alloc_cyclic()。请注意，处理较大数量的 ID 时，IDR 的效率会降低，因此使用这个函数会有一些代价。 当您使用完 IDR 后，可以调用 idr_destroy() 来释放 IDR 占用的内存。这不会释放 IDR 指向的对象；如果您想这样做，请使用其中一个迭代器来执行此操作。 您可以使用 idr_is_empty() 来查看当前是否分配了任何 ID。 如果在从 IDR 分配一个新 ID 时需要带锁，您可能需要传递一组限制性的 GFP 标志，但这可能导致 IDR 无法分配内存。为了解决该问题，您可以在获取锁之前调用 idr_preload()，然后在分配之后调用 idr_preload_end()。 #include &lt;linux/idr.h&gt; int main(void) { struct idr my_idr; int id1, id2; void *ptr1, *ptr2; // Initialize the IDR idr_init(&amp;my_idr); // Allocate two unused IDs id1 = idr_alloc(&amp;my_idr, \"sample1\", 0, 0, GFP_KERNEL); id2 = idr_alloc(&amp;my_idr, \"sample2\", 0, 0, GFP_KERNEL); // Associate pointers with the IDs ptr1 = (void *)0xdeadbeef; ptr2 = (void *)0xcafebabe; idr_replace(&amp;my_idr, ptr1, id1); idr_replace(&amp;my_idr, ptr2, id2); // Look up pointers by ID ptr1 = idr_find(&amp;my_idr, id1); ptr2 = idr_find(&amp;my_idr, id2); // Free the IDs idr_remove(&amp;my_idr, id1); idr_remove(&amp;my_idr, id2); // Destroy the IDR idr_destroy(&amp;my_idr); return 0; } 非一致性内存 和一致性 dma_alloc_noncoherent 它是Linux内核中的一个DMA内存分配函数，用于分配一段物理内存，使其可以被DMA硬件访问12. 这个函数的作用是在非一致性内存（non-coherent memory）上分配一块区域，以便设备可以使用它作为DMA的源或目标地址。让我详细解释一下这个函数的用途和参数。 dma_alloc_noncoherent函数的原型如下： void *dma_alloc_noncoherent(struct device *dev, size_t size, dma_addr_t *dma_handle, gfp_t flag); dev: 指向设备结构的指针，表示要为哪个设备分配内存。 size: 要分配的内存大小（以字节为单位）。 dma_handle: 用于返回DMA地址的指针。这个地址可以转换为与总线宽度相同的无符号整数，并传递给设备作为分配区域的DMA地址基址。 flag: 用于指定内存分配的GFP_标志（类似于kmalloc()中的标志）。例如，可以使用GFP_KERNEL来分配普通内核内存。 非一致性内存是一种特殊类型的内存，写入它的数据可以立即被处理器或设备读取，而无需考虑缓存效应。需要注意的是，CPU不能直接引用dma_addr_t，因为物理地址空间和DMA地址空间之间可能存在转换。 使用dma_alloc_noncoherent分配的内存区域不保证一致性，因此在使用之前，可能需要手动刷新处理器的写缓冲区，以确保设备可以正确读取该内存。 释放由dma_alloc_noncoherent分配的内存时，应使用dma_free_noncoherent函数： void dma_free_noncoherent(struct device *dev, size_t size, void *cpu_addr, dma_addr_t dma_handle); dev、size和dma_handle参数必须与传递给dma_alloc_noncoherent的相同。 cpu_addr是由dma_alloc_noncoherent返回的虚拟地址。 请注意，与其他内存分配函数不同，这些函数只能在启用IRQ的情况下调用。 如果你的驱动程序需要大量较小的DMA一致性内存区域，你可以使用DMA池（dma_pool）来分配和管理这些区域，而不是使用dma_alloc_coherent()。DMA池类似于kmem_cache，但它使用dma_alloc_coherent()而不是__get_free_pages() dma_alloc_wc 这个函数允许驱动程序申请带缓存一致性的DMA内存。缓存一致性是指确保CPU和DMA设备之间的数据一致性，以避免数据不一致的问题。使用dma_alloc_wc分配的内存区域旨在在CPU和DMA设备之间保持一致，以便数据正确传输。 释放由dma_alloc_wc分配的内存时，应使用dma_free_wc函数： void dma_free_wc(struct device *dev, size_t size, void *cpu_addr, dma_addr_t dma_handle); dev、size和dma_handle参数必须与传递给dma_alloc_wc的相同。 cpu_addr是由dma_alloc_wc返回的虚拟地址。 adf 定时器 timer_setup 它是Linux内核中用于初始化定时器的函数。它能够方便地设置和初始化一个计时器，并通过设置参数来灵活地控制计时器的行为1. 合理使用timer_setup函数可以让我们更好地处理时间相关的任务，提高操作系统的性能和可靠性。 在Linux内核中，定时器通常使用timer_list结构体来表示。下面是timer_list结构体的一些关键字段： entry: 定时器列表元素，用于将定时器挂载在内核定时器链表上。 expires: 定时器定时时间。 function: 定时器回调函数，定时器时间到时执行该函数。 flags: 标志位，用于设置定时器的属性。 在旧版本的内核中，我们使用init_timer函数来初始化定时器。而在新版本中，这个函数变成了timer_setup函数。下面是timer_setup函数的定义： void timer_setup(struct timer_list *timer, void (*callback)(struct timer_list *), unsigned int flags); 使用timer_setup函数时，我们需要传入以下参数： timer: 要初始化的定时器。 callback: 定时器的回调函数，此函数的形参是当前定时器的变量。 flags: 标志位，可以设置定时器的属性。 #include &lt;linux/kernel.h&gt; #include &lt;linux/module.h&gt; #include &lt;linux/timer.h&gt; MODULE_LICENSE(\"GPL\"); static struct timer_list my_timer; void my_timer_callback(struct timer_list *timer) { printk(KERN_ALERT \"This line is printed after 5 seconds.\\n\"); } static int init_module_with_timer(void) { printk(KERN_ALERT \"Initializing a module with timer.\\n\"); // Setup the timer for initial use timer_setup(&amp;my_timer, my_timer_callback, 0); // Set the timer interval to 5000 milliseconds (5 seconds) mod_timer(&amp;my_timer, jiffies + msecs_to_jiffies(5000)); return 0; } static void exit_module_with_timer(void) { printk(KERN_ALERT \"Goodbye, cruel world!\\n\"); del_timer(&amp;my_timer); } module_init(init_module_with_timer); module_exit(exit_module_with_timer); 高精度定时器 hrtimer_init 是 Linux 内核中与高精度定时器（HRTimer）相关的函数之一。让我为您详细介绍一下，并提供一个示例代码： HRTimer 简介： HRTimer 是 Linux 内核中的高精度定时器，用于提供纳秒级别的时钟精度。 与传统的定时器相比，HRTimer 允许更精确地控制定时事件，适用于对时间要求较高的场景，如看门狗、USB、以太网、块设备、虚拟机等子系统。 hrtimer_init 函数： hrtimer_init 用于初始化一个 struct hrtimer 实例。 参数： timer：指向要初始化的 HRTimer 实例的指针。 clock_id：时钟的种类，例如 CLOCK_MONOTONIC 表示自系统开机以来的单调递增时间。 mode：定时器的模式，可以是绝对时间（HRTIMER_MODE_ABS）或相对时间（HRTIMER_MODE_REL）。 示例代码： 下面是一个使用 HRTimer 的简单示例代码，用于在内核中启动一个相对时间的 HRTimer： #include &lt;linux/hrtimer.h&gt; #include &lt;linux/ktime.h&gt; #include &lt;linux/module.h&gt; MODULE_LICENSE(\"GPL\"); static struct hrtimer my_timer; static ktime_t interval; static enum hrtimer_restart my_timer_callback(struct hrtimer *timer) { // Your timer callback logic here // For demonstration purposes, let's print a message. pr_info(\"HRTimer callback executed!\\n\"); return HRTIMER_RESTART; } static int __init my_module_init(void) { // Initialize the HRTimer interval = ktime_set(1, 0); // Set interval to 1 second hrtimer_init(&amp;my_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL); my_timer.function = my_timer_callback; // Start the timer hrtimer_start(&amp;my_timer, interval, HRTIMER_MODE_REL); pr_info(\"HRTimer module initialized\\n\"); return 0; } static void __exit my_module_exit(void) { // Cleanup: Stop the timer hrtimer_cancel(&amp;my_timer); pr_info(\"HRTimer module removed\\n\"); } module_init(my_module_init); module_exit(my_module_exit); 在上述示例中，我们初始化了一个相对时间的 HRTimer，设置了回调函数 my_timer_callback，并启动了定时器。 内核线程 kthread_create_worker() 函数是Linux内核中用于创建内核线程的一个函数。通过设置标志参数和格式化字符串，可以指定创建内核线程的行为和名称。它分配并初始化了一个kthread_worker结构体，并使用它来创建内核线程. 以下是kthread_create_worker函数的一些关键参数： cpu: 如果大于等于0，将创建特定于某个CPU的工作线程；如果不想创建特定于CPU的工作线程，可以将CPU域赋值为-1。 flags: 可以设置一些标志位，根据需要来控制内核线程的行为。 namefmt: 一个格式化字符串，用于指定内核线程的名称。 这个函数会分配内存并初始化kthread_worker结构，然后返回指向该结构的指针。您可以根据具体需求使用这个函数来创建和管理内核线程。 如果您需要一个示例代码，以下是一个简单的例子，展示了如何在模块初始化时创建一个内核线程，以及如何在卸载模块时关闭该内核线程： #include &lt;linux/module.h&gt; #include &lt;linux/kthread.h&gt; #include &lt;linux/delay.h&gt; MODULE_LICENSE(\"GPL\"); static int demo_thr(void *data) { while (!kthread_should_stop()) { msleep_interruptible(2000); printk(KERN_INFO \"Thread is running...\\n\"); } return 0; } static struct task_struct *thr = NULL; static int kthread_demo_init(void) { thr = kthread_run(demo_thr, NULL, \"kthread-demo\"); if (!thr) { printk(KERN_ERR \"Failed to create kthread\\n\"); return -ENOMEM; } return 0; } static void kthread_demo_exit(void) { if (thr) { kthread_stop(thr); thr = NULL; } } module_init(kthread_demo_init); module_exit(kthread_demo_exit); 在这个示例中，我们使用kthread_run函数创建一个名为kthread-demo的内核线程，它每隔2秒打印一条信息。在卸载模块时，我们使用kthread_stop来关闭该内核线程。 工作队列 schedule_work 函数是Linux内核中的一个重要函数，用于将一个工作项（work）添加到工作队列（workqueue）中。这个函数的作用是在后台执行一些延迟较长的任务，而不会阻塞主线程的执行。 以下是关于schedule_work函数的一些要点： 功能：将工作项添加到默认的工作队列（通常是system_wq）中，以便稍后执行。 调用方式：schedule_work(&amp;my_work);，其中my_work是一个已经初始化的工作项。 工作队列：工作队列是一种异步执行机制，用于处理延迟的或非实时的任务。 延迟执行：schedule_work会将工作项添加到工作队列中，等待系统调度执行。这样，主线程可以继续执行其他任务，而不必等待工作项完成。 工作项回调函数：工作项的实际执行逻辑由回调函数定义。当工作项被调度执行时，会调用这个回调函数。 以下是一个简单的示例代码，展示了如何使用INIT_WORK和schedule_work来创建和调度一个工作项： #include &lt;linux/init.h&gt; #include &lt;linux/module.h&gt; #include &lt;linux/kernel.h&gt; #include &lt;linux/workqueue.h&gt; MODULE_LICENSE(\"GPL\"); static struct work_struct my_work; // 工作项的回调函数 static void my_work_handler(struct work_struct *work) { printk(KERN_INFO \"My work handler is running...\\n\"); // 在这里执行您的工作逻辑 } static int init_my_module(void) { printk(KERN_INFO \"Initializing my kernel module with workqueue...\\n\"); // 初始化工作项 INIT_WORK(&amp;my_work, my_work_handler); // 将工作项添加到工作队列 schedule_work(&amp;my_work); return 0; } static void cleanup_my_module(void) { printk(KERN_INFO \"Cleaning up my kernel module...\\n\"); } module_init(init_my_module); module_exit(cleanup_my_module); 在这个示例中，我们首先定义了一个名为my_workqueue的工作队列结构体，以及一个名为my_work的工作项。然后，在init_my_module函数中使用create_singlethread_workqueue来创建一个名为my_workqueue的工作队列。接着，我们使用INIT_WORK来初始化工作项，并使用schedule_work来调度它。 alloc_ordered_workqueue 用于创建有序的工作队列（workqueue）。让我详细介绍一下，并提供一个示例代码： alloc_ordered_workqueue 简介： alloc_ordered_workqueue 函数用于分配一个有序的工作队列。 有序工作队列是一种特殊类型的工作队列，它确保工作项按照提交的顺序执行。 函数签名： struct workqueue_struct *alloc_ordered_workqueue(const char *name, unsigned int flags); 参数说明： name：工作队列的名称。 flags：标志位，用于配置工作队列的行为。 示例代码： 下面是一个简单的示例代码，展示如何使用 alloc_ordered_workqueue 创建一个有序的工作队列： #include &lt;linux/init.h&gt; #include &lt;linux/module.h&gt; #include &lt;linux/workqueue.h&gt; static struct workqueue_struct *my_ordered_wq; static void my_work_handler(struct work_struct *work) { pr_info(\"Work item executed!\\n\"); } static DECLARE_WORK(my_work, my_work_handler); static int __init my_module_init(void) { my_ordered_wq = alloc_ordered_workqueue(\"my_ordered_wq\", 0); if (!my_ordered_wq) { pr_err(\"Failed to create ordered workqueue\\n\"); return -ENOMEM; } queue_work(my_ordered_wq, &amp;my_work); return 0; } static void __exit my_module_exit(void) { destroy_workqueue(my_ordered_wq); } module_init(my_module_init); module_exit(my_module_exit); MODULE_LICENSE(\"GPL\"); MODULE_DESCRIPTION(\"Ordered Workqueue Example\"); 在此示例中，我们创建了一个名为 “my_ordered_wq” 的有序工作队列，并将一个工作项 my_work 提交到队列中。工作项的处理函数 my_work_handler 将在有序的顺序中执行。 create_singlethread_workqueue create_singlethread_workqueue 是 Linux 内核中的一个函数，用于创建一个只包含单个工作线程的工作队列（workqueue）。让我详细介绍一下：🙂 create_singlethread_workqueue 简介： create_singlethread_workqueue 函数用于创建一个只包含一个工作线程的工作队列。 无论系统中有多少个 CPU，这个工作队列都只会有一个工作线程。 函数签名： struct workqueue_struct *create_singlethread_workqueue(const char *name); 参数说明： name：工作队列的名称。 工作原理： create_singlethread_workqueue 创建的工作队列只有一个工作线程。 所有提交到这个工作队列的工作项都会由这个单一的工作线程按顺序执行。 示例代码： 下面是一个简单的示例代码，展示如何使用 create_singlethread_workqueue 创建一个只包含单个工作线程的工作队列： #include &lt;linux/init.h&gt; #include &lt;linux/module.h&gt; #include &lt;linux/workqueue.h&gt; static struct workqueue_struct *my_singlethread_wq; static void my_work_handler(struct work_struct *work) { pr_info(\"Work item executed!\\n\"); } static DECLARE_WORK(my_work, my_work_handler); static int __init my_module_init(void) { my_singlethread_wq = create_singlethread_workqueue(\"my_singlethread_wq\"); if (!my_singlethread_wq) { pr_err(\"Failed to create singlethread workqueue\\n\"); return -ENOMEM; } queue_work(my_singlethread_wq, &amp;my_work); return 0; } static void __exit my_module_exit(void) { destroy_workqueue(my_singlethread_wq); } module_init(my_module_init); module_exit(my_module_exit); MODULE_LICENSE(\"GPL\"); MODULE_DESCRIPTION(\"Singlethread Workqueue Example\"); 在此示例中，我们创建了一个名为 “my_singlethread_wq” 的工作队列，并将一个工作项 my_work 提交到队列中。这个工作项的处理函数 my_work_handler 将在单一的工作线程中按顺序执行。 completion init_completion() 是Linux内核中用于完成事件通知机制的一个函数，主要用于进程间或线程间的同步。这个函数初始化一个 completion 结构体，该结构体用于表示某个事件是否已经发生。在多线程或多进程编程中，有时需要一个线程或进程等待另一个线程或进程完成某个任务。 让我们来详细了解一下 init_completion() 函数的功能和用法： 初始化completion结构体： completion 结构体用于维护“complete”状态，表示某个任务是否已完成。 结构体定义如下： struct completion { unsigned int done; struct swait_queue_head wait; }; done 字段表示完成状态，初始值为 0。 swait_queue_head 是一个等待队列头，用于管理等待该完成事件的线程。 init_completion() 函数： 动态定义及初始化一个信号量： #define init_completion(x) __init_completion(x) static inline void __init_completion(struct completion *x) { x-&gt;done = 0; init_swait_queue_head(&amp;x-&gt;wait); } 这个函数实际上是初始化了 completion 结构体中的信号量。 等待完成： 等待信号量的释放： void __sched wait_for_completion(struct completion *x) { wait_for_common(x, MAX_SCHEDULE_TIMEOUT, TASK_UNINTERRUPTIBLE); } 发信端： complete() 函数用于唤醒等待该完成事件的单个线程： void complete(struct completion *x) { unsigned long flags; raw_spin_lock_irqsave(&amp;x-&gt;wait.lock, flags); if (x-&gt;done != UINT_MAX) x-&gt;done++; swake_up_locked(&amp;x-&gt;wait); raw_spin_unlock_irqrestore(&amp;x-&gt;wait.lock, flags); } 同时唤醒所有等待线程： complete_all() 函数用于唤醒等待此特定完成事件的所有线程： void complete_all(struct completion *x) { unsigned long flags; lockdep_assert_RT_in_threaded_ctx(); raw_spin_lock_irqsave(&amp;x-&gt;wait.lock, flags); x-&gt;done = UINT_MAX; swake_up_all_locked(&amp;x-&gt;wait); raw_spin_unlock_irqrestore(&amp;x-&gt;wait.lock, flags); } 完整示例 #include &lt;linux/module.h&gt; #include &lt;linux/init.h&gt; #include &lt;linux/completion.h&gt; #include &lt;linux/delay.h&gt; #include &lt;linux/kthread.h&gt; MODULE_LICENSE(\"GPL\"); MODULE_AUTHOR(\"kevin\"); static struct completion my_completion; static int my_thread(void *data){ pr_info(\"My thread is waiting for completion...\\n\"); wait_for_completion(&amp;my_completion); pr_info(\"My thread woke up! Event completed.\\n\"); return 0; } static int __init my_init(void){ pr_info(\"Initializing my module...\\n\"); init_completion(&amp;my_completion); // Start a new kernel thread kthread_run(my_thread, NULL, \"my_thread\"); // Simulate some work... msleep(2000); pr_info(\"Completing the event...\\n\"); complete(&amp;my_completion); return 0; } static void __exit my_exit(void){ pr_info(\"Exiting my module...\\n\"); } module_init(my_init); module_exit(my_exit); kobject_uevent_env 它是 Linux 内核 中的一个函数，用于在 kobject 状态发生变化时发送 uevent 到用户空间。让我详细解释一下： kobject： kobject 是内核中的一个抽象对象，用于表示各种内核数据结构，例如设备、驱动程序、总线等。 每个 kobject 都有一个名称、引用计数和其他属性。 uevent： uevent 是用户空间事件的缩写，用于通知用户空间程序内核中的状态变化。 例如，当设备插入或移除时，内核会生成相应的 uevent。 kobject_uevent_env 函数： 这个函数用于发送 uevent 到用户空间。 它接受一个指向 kobject 的指针和一个表示 uevent 的环境变量数组。 用户空间程序可以监听这些事件并做出相应的处理。 使用示例： 在设备驱动程序中，当设备状态发生变化时，例如设备插入或移除，可以使用 kobject_uevent_env 发送相应的 uevent。 用户空间程序收到这些事件后，可以根据需要执行操作。 以下是一个简单的示例代码，展示了如何在内核模块中使用 kobject_uevent_env 发送 uevent： #include &lt;linux/module.h&gt; #include &lt;linux/init.h&gt; #include &lt;linux/kobject.h&gt; static struct kobject *my_kobj; static int my_uevent(struct kset *kset, struct kobject *kobj, struct kobj_uevent_env *env) { // Add custom environment variables to the uevent add_uevent_var(env, \"MY_CUSTOM_VAR=hello_world\"); return 0; } static struct kset_uevent_ops my_uevent_ops = { .uevent = my_uevent, }; static int __init my_module_init(void) { my_kobj = kobject_create_and_add(\"my_kobject\", NULL); if (!my_kobj) return -ENOMEM; my_kobj-&gt;kset = kset_create_and_add(\"my_kset\", NULL, NULL); if (!my_kobj-&gt;kset) { kobject_put(my_kobj); return -ENOMEM; } my_kobj-&gt;kset-&gt;uevent_ops = &amp;my_uevent_ops; return 0; } static void __exit my_module_exit(void) { kset_unregister(my_kobj-&gt;kset); kobject_put(my_kobj); } module_init(my_module_init); module_exit(my_module_exit); MODULE_LICENSE(\"GPL\"); 在此示例中，我们创建了一个名为 my_kobject 的 kobject，并将其添加到一个名为 my_kset 的 kset 中。然后，我们设置了一个自定义的 uevent，将环境变量 MY_CUSTOM_VAR 添加到 uevent 中。 请注意，实际应用中，您需要根据您的需求自定义更多的环境变量和处理逻辑。 benchmark DRM kernel aspects (display and render): IGT GPU Tools (IGT): main DRM test suite, used for CI https://gitlab.freedesktop.org/drm/igt-gpu-tools/ OpenGL aspects: drawElements Quality Program (dEQP): OpenGL/OpenGL ES/Vulkan conformance tests https://android.googlesource.com/platform/external/deqp/ glmark2: OpenGL 2.0 and ES 2.0 benchmark tool https://github.com/glmark2/glmark2/ Patch series continuous integration: EzBench: a collection of tools to benchmark graphics-related patch-series https://github.com/freedesktop/ezbench/ General benchmarking (including graphics): Phoronix Test Suite: automated benchmarking tool https://github.com/phoronix-test-suite/phoronix-test-suite/"
  },"/blog/linux/2018-08-01-DeviceResourceManage.html": {
    "title": "设备资源管理模块",
    "keywords": "linux",
    "url": "/blog/linux/2018-08-01-DeviceResourceManage.html",
    "body": "1.解决的问题 相信每一个写过Linux driver的工程师，都在probe函数中遇到过上面的困惑：在顺序申请多种资源（IRQ、Clock、memory、regions、ioremap、dma、等等）的过程中，只要任意一种资源申请失败，就要回滚释放之前申请的所有资源。 于是在函数的最后，就一定会出现很多的goto标签，用于释放不同的资源（如上面的exit_free_irq、exit_free_dma、等等）。 在申请资源出错时，小心翼翼的goto到正确的标签上，以便释放已申请资源。 这样在代码中，整个函数被大段的、重复的如下代码充斥。 if (!condition) { err = xxx; goto xxx; } 既浪费精力容易出错，也不美观。 有困惑，就有改善的办法。 方法就是Linux设备模型中的device resource management（设备资源管理）。 2.解决的思路 devres提供了一种机制，用资源节点的形式记录它申请的资源，并在系统中为设备分配一个链表，当申请某个资源时，就构建一个资源节点，然后把它加入到这个链表中，对应的释放函数也会被记录，以便在driver detach的时候，自动释放。 为了使用devres机制，资源要对各自的资源分配函数重新封装，加入资源节点的申请、添加和释放，一般新函数名改成了devm_xxx()的形式。driver作者只管调用这些devm_xxx()接口来申请资源，不用考虑释放，设备模型会在适当的时候释放它们。 device resource management位于“drivers/base/devres.c”中，它实现了上述机制。 3.提供的接口 以下是devres提供的几个基本接口 interface Description devres_alloc( ) // 分配资源节点 devres_free( ) // 释放资源节点 devres_add( ) // 添加资源节点到链表 devres_destroy( ) // 释放资源 devres_release_all() //释放所有资源 4.接口的使用 其他资源模块，可以通过调用devres提供的接口，利用devres机制实现资源的自动释放。 4.1 资源节点函数的应用举例 下面的代码是利用devres机制实现分配中断资源函数 devm_request_threaded_irq( ), 上层模块可以调用它来分配中断资源，在出错时，不必考虑对该资源的释放，系统会自动释放。 主要涉及到devres_alloc()、devres_free()和devres_add() 4.2 资源释放函数的应用举例 资源释放函数devres_destroy()的使用举例，资源模块可以用它来封装资源释放函数。 5. 函数的内部实现 5.1 devres_alloc() devrs_alloc()函数的实现，主要调用了内部函数alloc_dr(), 它会分配size+sizeof(struct devres)的内存大小, struct devres用于存储资源节点信息，并记录release 函数。 5.2 devres_add() devres_add()主要实现把资源节点添加到设备的资源链表中。 5.3 devres_destroy() devres_destroy()主要涉及到以下几个内部函数： devres_remove() //查找到资源节点，并从链表中删除 find_dr() //根据release函数指针、match函数查找资源节点 devres_free() //释放资源节点 可以结合上面它的使用实例来学习。 5.4 devers_release_all() devers_release_all()的调用会释放所有资源。它的被调用时机有两个： really_probe()失败 设备与驱动分离时, deriver_dettach时 就是driver_remove时。"
  },"/blog/jekyll/2018-05-20-memory_check.html": {
    "title": "进程内存检查",
    "keywords": "Jekyll",
    "url": "/blog/jekyll/2018-05-20-memory_check.html",
    "body": "1.进程内存映射文件smaps 在内核的数据结构中，进程、进程使用内存、虚拟内存块和一个二进制程序文件的对应关系图如下。 查看/proc/${PID}/smaps，可以得到每一个vm_area_node的详细信息。 下图是一个具体的vm_area_node信息。 1.1 两种映射 下面两种映射的介绍，是为了下一节解释各字段含义做准备。 文件映射 就是存储介质(比如：磁盘)中的数据通过文件系统映射到内存再通过文件映射映射到虚拟空间，这样，用户就可以在用户空间通过 open, read, write 等函数区操作文件内容。代码中函数open(), read(), write(), close(), mmap(fd，…)… 操作的虚拟地址都属于文件映射。 匿名映射 就是用户空间要求内核分配一定的物理内存来存储数据，这部分内存不属于任何文件。内核就使用匿名映射将内存中的某段物理地址与用户空间一一映射，这样用户就可用直接操作虚拟地址来范围这段物理内存。比如使用malloc(), mmap(NULL，…)申请内存。 1.2 各字段含义 第一行 08048000-080bc000: 该虚拟内存段的开始和结束位置 r-xp:内存段的权限，分别是可读、可写、可运行、私有或共享，最后一位p代表私有，s代表共享(如共享的内存， shm). 如果有”w”，表示是库的数据区. 00000000: 虚拟内存段起始地址在对应的映射文件中以页为单位的偏移量， 对匿名映射，它等于0或者vm_start/PAGE_SIZE 03:02: 文件的主设备号和次设备号。 对有名映射来说，是映射的文件所在设备的设备号 对匿名映射来说，因为没有文件在磁盘上，所以没有设备号，始终为00:00。 13130: 被映射到虚拟内存的文件的索引节点号,通过该节点可以找到对应的文件， 对匿名映射来说，因为没有文件在磁盘上，所以为0 /bin/bash: 被映射到虚拟内存的文件名称。后面带(deleted)的是内存数据，可以被销毁。 对有名映射来说，是映射的文件名。 对匿名映射来说，是此段虚拟内存在进程中的角色。[stack]表示在进程中作为栈使用，[heap]表示堆。其余情况比如mmap(NULL, ….)则无显示。 Size 虚拟内存空间大小。但是这个内存值不一定是物理内存实际分配的大小，因为在用户态上，虚拟内存总是延迟分配的。这个值计算也非常简单，就是该VMA的开 始位置减结束位置。 延迟分配:就是当进程申请内存的时候，Linux会给他先分配页，但是并不会区建立页与页框的映射关系，也就是并不会分配物理内存，而当真正使用的时候，就会产生一个缺页异常，硬件跳转page fault处理程序执行，在其中分配物理内存，然后修改页表(创建页表项)。异常处理完毕，返回程序用户态，继续执行。 Rss resident set size 实际分配的内存，这部分物理内存已经分配，不需要缺页中断就可以使用的。但可能是和其他进程共享的。 这里有一个公式计算Rss： Rss=Shared_Clean+Shared_Dirty+Private_Clean+Private_Dirty Shared_Clean Shared_Dirty Private_Clean Private_Dirty share/private：表示该页面是共享还是私有。 dirty/clean： 表示该页面是否被修改过，如果修改过（dirty），在页面被淘汰的时候，就会把该脏页面回写到交换分区(换出，swap out)。有 一个标志位用于表示页面是否dirty。 share/private_dirty/clean 计算逻辑： 查看该page的引用数，如果引用&gt;1，则归为shared，如果是1，则归为private，再查看该page的flag，是否标记为_PAGE_DIRTY，如果不是，则认为干净的 Pss proportional set size 平摊计算后的实际物理使用内存(有些内存会和其他进程共享，例如mmap进来的)。实际上包含上面private_clean+private_dirty，和按比例均分的shared_clean、shared_dirty。 举个计算Pss的例子： 如果进程A有x个private_clean页面，有y个private_dirty页面，有z个shared_clean仅和进程B共享，有h个shared_dirty页面和进程B、C共享。那么进程A的Pss为：x + y + z/2 + h/3 Referenced 当前页面被标记为已引用或者包含匿名映射（The amount of memory currently marked as referenced or a mapping associated with a file may contain anonymous pages）。在Linux内存管理的页面替换算法中，当某个页面被访问后，Referenced标志被设置，如果该标志设置了，就不能将该页移出。 Anonymous 匿名映射的物理内存，这部分内存不是来自于文件。 VmFlags vm_area的各种属性，具体如下： 1.3 不同变量的位置 一个库映射到内存， 一般分为代码段、数据段和只读数据段 r- --p: so中的字符串常数 rw--p: so中的全局变量，静态变量 r- -xp: so的代码段，常量 - ---p: 表示该 VMA 是私有的，不可执行，且不可读写. 这通常用于保护敏感数据或代码，防止其被修改或执行 下面这段代码展示了不同变量的存储位置： 2.free 命令 free 命令用于显示系统的内存状态，包括物理内存、交换内存（swap）和内核缓冲区内存。详细输出如下： Mem 行（第二行）显示了内存的使用情况。 Swap行（第三行）显示了交换空间的使用情况。 total: 表示系统总的可用物理内存和交换空间大小。 used : 表示已经被使用的物理内存和交换空间。 free : 表示还有多少物理内存和交换空间可用使用。 shared: 显示被共享使用的物理内存大小。 buff/cache: 显示被 buffer 和 cache 使用的物理内存大小。 available: 显示还可以被应用程序使用的物理内存大小。 2.1 buffer与cache buffer: 缓冲区 CPU 在进行一系列操作时，先在内存的一块区域进行，一系列操作完成后，再一次性把该内存区域提交给外部设备，来对这个区域操作。 比如写一堆数据给硬盘，就先写到内存的一块区域，写好后一次写回到硬盘。又比如读数据，先在内存划出一块区域，让硬盘控制器写数据到这块区域，写好后，CPU 直接访问该区域得到数据。这个内存区域就叫buffer 缓冲区是内存或存储的一部分，用于在等待从输入设备传输到输出设备时存放项目。 操作系统通常在打印文档时使用缓冲区。这个过程称为排队（spooling），它将要打印的文档发送到缓冲区，而不是立即发送到打印机。如果打印机没有自己的内部存储器，或者内存已满，操作系统的缓冲区会保存等待打印的信息，同时打印机以自己的速度从缓冲区打印。 通过将文档排队到缓冲区，处理器可以继续解释和执行指令，同时打印机进行打印。这使用户可以在打印机打印时继续在计算机上进行其他任务。多个打印作业在缓冲区中排队（发音为“Q”）。一个名为打印排队程序（print spooler）的程序拦截操作系统中要打印的文档，并将其放入队列中 cache：缓存 CPU 要访问一块数据时，首先访问内存的某个区域，看是否有该数据的缓存，有则直接访问，没有则访问它的来源地。 CPU 利用内存或高速缓存对数据的再备份，为以后的再次访问提供方便 缓存如今的大多数计算机通过缓存（发音为“cash”）来提高处理速度。 缓存有两种主要类型：内存缓存和磁盘缓存。让我们详细了解一下内存缓存。 L1 缓存： L1 缓存直接内置在处理器芯片中。 它通常容量很小，范围从 8 KB 到 128 KB。 L1 缓存存储经常使用的指令和数据，以便快速访问。 L2 缓存： L2 缓存比 L1 缓存稍慢，但容量更大。 它的大小范围从 64 KB 到 16 MB。 一些现代处理器包括高级传输缓存，这是一种直接内置在处理器芯片上的 L2 缓存类型。 使用高级传输缓存的处理器的性能比不使用它的处理器要快得多。 现今的个人计算机通常具有 512 KB 到 12 MB 的高级传输缓存。 缓存通过存储经常使用的指令和数据来显著加快处理时间。 当处理器需要一条指令或数据时，它按照以下顺序搜索内存：L1 缓存，然后是 L2 缓存，然后是 RAM。 如果所需信息在内存中找不到，处理器必须搜索速度较慢的存储介质，例如硬盘或光盘。 2.2. 手动释放缓存 首先，使用sync命令将未写入磁盘的数据同步到磁盘，以确保文件系统的完整性。 然后，通过设置/proc/sys/vm/drop_caches来释放内存缓存： echo 1 &gt; /proc/sys/vm/drop_caches：释放页缓存。 echo 2 &gt; /proc/sys/vm/drop_caches：释放 dentries 和 inodes。 echo 3 &gt; /proc/sys/vm/drop_caches：释放所有缓存。 3.mtrace mtrace 是 Linux 系统内核自带的一个内存追踪函数。它会在每个内存申请函数（malloc、realloc、calloc）的位置记录下信息，并在每个内存释放的位置记录下 free 的内存信息。其中包含有内存申请的地址、内存申请的大小、释放内存的地址、释放内存的大小。 具体来说，mtrace 函数的作用如下： 安装钩子函数，用于跟踪内存分配和释放。 记录有关内存分配和释放的跟踪信息。 可以用于发现程序中的内存泄漏和试图释放未分配内存的情况。 使用方式： 在代码中包含 &lt;mcheck.h&gt; 头文件。 在程序启动时调用 mtrace() 函数，开启内存分配和释放跟踪。 程序结束时，可以调用 muntrace() 函数关闭内存分配和释放跟踪。 运行mtrace脚本，分析跟踪日志，生成报告。 请注意，mtrace 的跟踪输出通常是文本形式，不一定易于人类阅读。GNU C 库提供了一个 Perl 脚本 mtrace，用于解析跟踪日志并生成人类可读的输出。为了获得最佳效果，建议编译时启用调试，以便在可执行文件中记录行号信息。不过，mtrace 的跟踪会带来性能损耗.如果 MALLOC_TRACE 没有指向有效且可写的路径， 则mtrace不会记录信息。 4.strace与ltrace ltrace 用于跟踪程序的库函数调用，而 strace 则用于跟踪系统调用。 它们都基于 ptrace 系统调用，但跟踪库函数和跟踪系统调用之间存在差异。 通过它们，我们也可以对应用的内存申请、释放进行跟踪。 ltrace 的工作原理： ptrace 附加到正在运行的程序。 定位程序的 PLT。 使用 PTRACE_POKETEXT 设置软件断点（int $3 指令）覆盖库函数的 PLT 中的汇编 trampoline。 恢复程序执行。 strace 应该也是相类似的工作原理 4.1 strace strace 是一个强大的 Linux 命令，用于诊断、调试和统计。它允许您跟踪正在运行的程序的系统调用和接收的信号。下面是一些关于 strace 的参数使用方法。 -c：统计每个系统调用的执行时间、次数和错误次数。 示例：打印执行 uptime 时系统调用的时间、次数和错误次数： strace -c uptime -f：跟踪子进程，这些子进程是由当前跟踪的进程创建的。 -i：在系统调用时打印指令指针。 -t：跟踪的每一行都以时间为前缀。 -tt：如果给出两次，则打印时间将包括微秒。 -ttt：如果给定三次，则打印时间将包括微秒，并且前导部分将打印为自启动以来的秒数。 -T：显示花费在系统调用上的时间。 限定表达式： -e trace=set：仅跟踪指定的系统调用集。例如，trace=open,close,read,write 表示仅跟踪这四个系统调用。 -e trace=file：跟踪所有以文件名作为参数的系统调用。示例：打印执行 ls 时与文件有关的系统调用： strace -e trace=file ls -e trace=process：跟踪涉及进程管理的所有系统调用。 -e trace=network：跟踪所有与网络相关的系统调用。 -e trace=signal：跟踪所有与信号相关的系统调用。 -e trace=ipc：跟踪所有与 IPC 相关的系统调用。 -e trace=memory：跟踪所有与 momory 相关的系统调用。 其他参数： -o 文件名：将跟踪输出写入文件而不是 stderr。 -p pid：使用进程 ID pid 附加到该进程并开始跟踪 下面是运行 strace ls 的输出 4.2 ltrace ltrace 是一个用于跟踪程序库调用的 Linux 工具。它可以拦截并记录被执行进程调用的动态库函数，以及该进程接收到的信号。此外，ltrace 还可以拦截并打印程序执行的系统调用。 常用参数和示例： -c：统计每个系统调用的执行时间、次数和错误次数。 示例：打印执行 uptime 时系统调用的时间、次数和错误次数： ltrace -c uptime -f：跟踪子进程，这些子进程是由当前跟踪的进程创建的。 -i：在系统调用时打印指令指针。 -t：跟踪的每一行都以时间为前缀。 -tt：如果给出两次，则打印时间将包括微秒。 -ttt：如果给定三次，则打印时间将包括微秒，并且前导部分将打印为自启动以来的秒数。 -T：显示花费在系统调用上的时间。 限定表达式： -e trace=set：仅跟踪指定的系统调用集。例如，trace=open,close,read,write 表示仅跟踪这四个系统调用。 -e trace=file：跟踪所有以文件名作为参数的系统调用。示例：打印执行 ls 时与文件有关的系统调用： ltrace -e trace=file ls -e trace=process：跟踪涉及进程管理的所有系统调用。 -e trace=network：跟踪所有与网络相关的系统调用。 -e trace=signal：跟踪所有与信号相关的系统调用。 -e trace=ipc：跟踪所有与 IPC 相关的系统调用。 其他参数： -o 文件名：将跟踪输出写入文件而不是 stderr。 -p pid：使用进程 ID pid 附加到该进程并开始跟踪。 下面是运行 ltrace ls 的输出"
  },"/blog/graphic/2018-03-21-YUV.html": {
    "title": "YUV编码",
    "keywords": "graphic",
    "url": "/blog/graphic/2018-03-21-YUV.html",
    "body": "1.简介 YUV数据由Y、U、V三个分量组成，现在通常说的YUV指的是YCbCr。 Y：表示亮度（Luminance、Luma），占8bit（1字节） Cb、Cr：表示色度（Chrominance、Chroma） Cb（U）：蓝色色度分量，占8bit（1字节） Cr（V）：红色色度分量，占8bit（1字节） 2.采样方式(444, 422, 420的区别) 把Y、U、V数据转变为R、G、B时用到 2.1 采样方式 采样方式通常用A:B:C的形式来表示，比如4:4:4、4:2:2、4:2:0等 A：假定在一块A*2个像素的概念区域，一般都是4. B：第1行的色度(UV)采样数目。 C：第2行的色度(UV)采样数目 所以这里的B,C指的分别是在第一行，第二行UV采样的数目。 C的值一般要么等于B，要么等于0 示意图1： 示意图2 上图中，不管是哪种采样格式，Y分量都是全水平、全垂直分辨率采样的，每一个像素都有自己独立的Y分量 2.2 占用字节数 由上可以推算出不同采样方式下每个像素需要的平均字节数。 4:4:4 一个像素YUV各占一个字节，总共3个字节 24bit 4:2:2 8个像素 ： 8个Y + 2个U +2个V +2个U +2个V = 16字节 每个像素：16字节/8 = 2个字节 16bit 4:2:0 8个像素 ： 8个Y + 2个U +2个V = 12字节 每个像素：12字节/8 = 1.5个字节 12bit 3.存储方式(Planar, Semi-Planar和Packed的区别) 存储格式，表示的是Y、U、V数据是如何排列和存储的。 读取或写入Y、U、V数据时用到. 3.1 分类 YUV的存储格式可以分为3大类： 名称 特点 Planar(平面) Y、U、V分量分开单独存储,名称通常以字母p结尾, 3个planar Semi-Planar（半平面） Y分量单独存储，U、V分量交错存储, 名称通常以字母sp结尾, 1个planar Packed（紧凑） 或者叫Interleaved(交错), Y、U、V分量交错存储, 1个planar 3.2 444 I444 和YV24 主要是UV次序的不同 semi-planar NV24 和NV42 主要是UV交替次序的不同 3.3 422 Planar I422 YV16 区别：VU 次序 Semi-Planar NV16 NV61 区别：VU 次序 Packed UYVY YUYV YVYU 区别：VU 次序 3.4 420 Planar I420 YV12 采样方式420 I420，像素示意图 Semi-Planar NV12 NV21 采样方式420，各种存储方式， 像素示意图 4.借助ffmpeg格式转换 PNG -&gt; YUV ffmpeg -i in.png -s 512x512 -pix_fmt yuv420p out.yuv YUV -&gt; PNG ffmpeg -s 512x512 -pix_fmt yuv420p -i in.yuv out.jpg YUV 文件只是存储数据的文件，没有大小信息，所以转换时一定要给出它的尺寸 PNG 文件含有尺寸信息，所以转YUV时可以不指定大小，默认原大小 5.借助ffplay显示YUV 可以通过ffplay显示YUV数据。 YUV中直接存储的是所有像素的颜色信息（可以理解为是图像的一种原始数据） 必须得设置YUV的尺寸（-s）、像素格式（-pix_fmt）才能正常显示 ffplay -s 512x512 -pix_fmt yuv420p in.yuv # 在ffplay中 # -s已经过期，建议改为：-video_size # -pix_fmt已经过期，建议改为：-pixel_format ffplay -video_size 512x512 -pixel_format yuv420p in.yuv 6.GLSL实现YUV转RGBA 6.1 基本计算公式 根据的标准不同，有不同的计算公式。下面是一个可以在shader中使用的计算方法。 只要先得到Y,U,V， 就可以按下面方法转换RGB \" yuv.y = yuv.y - 0.5; \\n\" \" yuv.z = yuv.z - 0.5; \\n\" \" \\n\" \" rgb.r = yuv.x + 1.402 * yuv.z; \\n\" \" rgb.g = yuv.x - 0.34413 * yuv.y - 0.71414 * yuv.z; \\n\" \" rgb.b = yuv.x + 1.772 * yuv.y; \\n\" YUV到RGBA的转换其实就两个要点 构建合适的纹理 在shader中提前YUV 6.2 YUV444P-&gt;ARGB 6.2.1 构建纹理 static GLuint build_texture_4_yuv444p(int width, int height, void *data){ GLuint texture; glGenTextures(1, &amp;texture); glBindTexture(GL_TEXTURE_2D, texture); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glTexImage2D(GL_TEXTURE_2D, 0, GL_RED, width, height, 0, GL_RED, GL_UNSIGNED_BYTE, data); glBindTexture(GL_TEXTURE_2D, 0); return texture; } 6.2.2 在shader中提取YUV static const char* yuv444_2_rgba_frag_src = \"uniform sampler2D Sampler; \\n\" \"varying highp vec2 TexCoord; \\n\" \"void main (void) \\n\" \"{ \\n\" \" highp vec3 yuv; \\n\" \" highp vec3 rgb; \\n\" \" yuv.x = texture2D(Sampler, TexCoord).r; \\n\" \" yuv.y = texture2D(Sampler, vec2(TexCoord.x, TexCoord.y+0.3333333)).r;\\n\" \" yuv.z = texture2D(Sampler, vec2(TexCoord.x, TexCoord.y+0.6666667)).r;\\n\" \" \\n\" \" yuv.y = yuv.y - 0.5; \\n\" \" yuv.z = yuv.z - 0.5; \\n\" // 矩阵计算方法 \" rgb = mat3( \\n\" \"1, 1, 1, \\n\" \"0, -.34413, 1.772, \\n\" \"1.402, -.71414, 0 \\n\" \" ) * yuv; \\n\" \" \\n\" \" gl_FragColor = vec4(rgb, 1.0); \\n\" \"} \\n\"; 6.3 NV24-&gt;ARGB 6.3.1 构建纹理 这里需要构建两个纹理，一个是Y的纹理， 一个是UV的纹理 static GLuint build_texture_4_nv24_y(int width, int height, void *y_data){ GLuint texture; glGenTextures(1, &amp;texture); glBindTexture(GL_TEXTURE_2D, texture); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glTexImage2D(GL_TEXTURE_2D, 0, GL_LUMINANCE, width, height, 0, GL_LUMINANCE, GL_UNSIGNED_BYTE, y_data); glBindTexture(GL_TEXTURE_2D, 0); return texture; } static GLuint build_texture_4_nv24_uv(int width, int height, void *uv_data){ GLuint texture; glGenTextures(1, &amp;texture); glBindTexture(GL_TEXTURE_2D, texture); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glTexImage2D(GL_TEXTURE_2D, 0, GL_LUMINANCE_ALPHA, width, height, 0, GL_LUMINANCE_ALPHA, GL_UNSIGNED_BYTE, uv_data); glBindTexture(GL_TEXTURE_2D, 0); return texture; } 6.3.2 在shader中提取YUV static const char* nv24_2_rgba_frag_src = \"uniform sampler2D Sampler_y; \\n\" \"uniform sampler2D Sampler_uv; \\n\" \"varying highp vec2 TexCoord; \\n\" \"void main (void) \\n\" \"{ \\n\" \" highp vec3 yuv; \\n\" \" highp vec3 rgb; \\n\" \" \\n\" \" yuv.x = texture2D(Sampler_y, TexCoord).r; \\n\" \" yuv.y = texture2D(Sampler_uv, TexCoord).r; \\n\" \" yuv.z = texture2D(Sampler_uv, TexCoord).a; \\n\" \" \\n\" \" yuv.y = yuv.y - 0.5; \\n\" \" yuv.z = yuv.z - 0.5; \\n\" \" \\n\" \" rgb.r = yuv.x + 1.402 * yuv.z; \\n\" \" rgb.g = yuv.x - 0.34413 * yuv.y - 0.71414 * yuv.z; \\n\" \" rgb.b = yuv.x + 1.772 * yuv.y; \\n\" \" \\n\" \" gl_FragColor = vec4(rgb, 1.0); \\n\" \"} \\n\"; 6.4 NV16-&gt;ARGB 6.4.1 构建纹理 这里需要构建两个纹理，一个是Y的纹理， 一个是UV的纹理 static GLuint build_texture_4_nv16_y(int width, int height, void *data){ GLuint texture; glGenTextures(1, &amp;texture); glBindTexture(GL_TEXTURE_2D, texture); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glTexImage2D(GL_TEXTURE_2D, 0, GL_LUMINANCE, width, height, 0, GL_LUMINANCE, GL_UNSIGNED_BYTE, data); glBindTexture(GL_TEXTURE_2D, 0); return texture; } 注意glTexImage2D()的第四参数值发生了变化 static GLuint build_texture_4_nv16_uv(int width, int height, void *data){ GLuint texture; glGenTextures(1, &amp;texture); glBindTexture(GL_TEXTURE_2D, texture); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glTexImage2D(GL_TEXTURE_2D, 0, GL_LUMINANCE_ALPHA, width/2, height, 0, GL_LUMINANCE_ALPHA, GL_UNSIGNED_BYTE, data); glBindTexture(GL_TEXTURE_2D, 0); return texture; } 6.4.2 在shader中提取YUV 与NV24方法相同 6.5 NV12-&gt;ARGB 6.5.1 构建纹理 这里需要构建两个纹理，一个是Y的纹理， 一个是UV的纹理 static GLuint build_texture_4_nv12_y(int width, int height, void *data){ GLuint texture; glGenTextures(1, &amp;texture); glBindTexture(GL_TEXTURE_2D, texture); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glTexImage2D(GL_TEXTURE_2D, 0, GL_LUMINANCE, width, height, 0, GL_LUMINANCE, GL_UNSIGNED_BYTE, data); glBindTexture(GL_TEXTURE_2D, 0); return texture; } 注意glTexImage2D()的第四,五参数值发生了变化 static GLuint build_texture_4_nv12_uv(int width, int height, void *data){ GLuint texture; glGenTextures(1, &amp;texture); glBindTexture(GL_TEXTURE_2D, texture); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); CHK_GL_ERR(); glTexImage2D(GL_TEXTURE_2D, 0, GL_LUMINANCE_ALPHA, width/2, height/2, 0, GL_LUMINANCE_ALPHA, GL_UNSIGNED_BYTE, data); CHK_GL_ERR(); glBindTexture(GL_TEXTURE_2D, 0); return texture; } 6.5.2 在shader中提取YUV 与NV24方法相同 6.6 直接提取YUV数据 static const char* yuv420_frag_src = \"#version 300 es \\n\" \"#extension GL_OES_EGL_image_external_essl3 : enable \\n\" \"#extension GL_EXT_YUV_target : enable \\n\" \"precision mediump float; \\n\" \"uniform __samplerExternal2DY2YEXT uTexSampler; \\n\" \"in vec2 varTexCoord; \\n\" \"out vec4 rgb; \\n\" \"void main() \\n\" \"{ \\n\" \" vec4 yuv = texture(uTexSampler, varTexCoord); \\n\" \" yuv.y = yuv.y - 0.5; \\n\" \" yuv.z = yuv.z - 0.5; \\n\" \" \\n\" \" rgb.r = yuv.x + 1.402 * yuv.z; \\n\" \" rgb.g = yuv.x - 0.34413 * yuv.y - 0.71414 * yuv.z; \\n\" \" rgb.b = yuv.x + 1.772 * yuv.y; \\n\" \" rgb.a = 1.0; \\n\" \"} \\n\";"
  },"/blog/jekyll/2013-03-02-cobalt.html": {
    "title": "Cobalt",
    "keywords": "Jekyll",
    "url": "/blog/jekyll/2013-03-02-cobalt.html",
    "body": "Starboard 在 Cobalt 的上下文中，Starboard 是一个重要的概念。让我为你解释一下： Starboard 是什么？ Starboard 是 Cobalt 的一个关键组件，用于抽象操作系统功能和平台特性，使其能够在不同平台上运行。 它是一个用于移植的抽象层，包含了一系列用于处理不同操作系统和平台特性的实现片段。 Starboard 的目标是将 Cobalt 与底层操作系统和硬件隔离开来，使 Cobalt 能够在不同设备上无缝运行。 如何使用 Starboard？ 在 Cobalt 的源代码中，你会看到 Starboard 的相关目录和文件，这些文件包含了特定平台的实现细节。 Starboard 将平台特定的功能封装在这些文件中，以便 Cobalt 可以在不同平台上运行。 Starboard 的设计目标是只包含 Cobalt 实际使用的平台特定功能，而不包含不必要的部分。 总之，Starboard 是 Cobalt 的一个关键组件，用于处理操作系统和平台差异，使 Cobalt 能够在不同设备上运行。 360 Video 在Youtube video 360中涉及到的几个函数及流程： A Video Frame, 它将被渲染到一个球面上。 Skia Skia 是一个开源的 2D 图形库，它提供了通用的 API，可以在各种硬件和软件平台上使用。它作为 Google Chrome 和 ChromeOS、Android、Flutter 等产品的图形引擎123。 Skia 是用 C++ 编写的完整的 2D 图形库，用于绘制文本、几何图形和图像。 它抽象了平台特定的图形 API（这些 API 在不同平台之间有所不同）。 最初由 Skia Inc. 开发，后来于 2005 年被 Google 收购，并于 2008 年以 New BSD 自由软件许可证 的形式发布为开源软件3。 egl opengl cobalt 中egl opengl API的跟踪 cobalt/renderer/egl_and_gles.h cobalt/renderer/rasterizer/egl/graphics_state.cc cobalt中wayland SbWindowPrivate::SbWindowPrivate(wl_compositor* compositor, wl_shell* shell, const SbWindowOptions* options, float pixel_ratio) { width = kWindowWidth; height = kWindowHeight; video_pixel_ratio = pixel_ratio; if (options &amp;&amp; options-&gt;size.width &gt; 0 &amp;&amp; options-&gt;size.height &gt; 0) { width = options-&gt;size.width; height = options-&gt;size.height; } surface = wl_compositor_create_surface(compositor); shell_surface = wl_shell_get_shell_surface(shell, surface); wl_shell_surface_add_listener(shell_surface, &amp;shell_surface_listener, this); wl_shell_surface_set_title(shell_surface, \"cobalt\"); struct wl_region* region; region = wl_compositor_create_region(compositor); wl_region_add(region, 0, 0, width, height); wl_surface_set_opaque_region(surface, region); wl_region_destroy(region); egl_window = wl_egl_window_create(surface, width, height); WindowRaise(); }"
  },"/blog/jekyll/2003-08-20-OpenGL_misc.html": {
    "title": "OpenGL",
    "keywords": "Jekyll",
    "url": "/blog/jekyll/2003-08-20-OpenGL_misc.html",
    "body": "glInvalidateFramebuffer vs glClear glInvalidateFramebuffer 和 glClear 是OpenGL中两个不同的函数，它们的作用和用法有所不同： glInvalidateFramebuffer： 功能：glInvalidateFramebuffer 用于显式地标记帧缓冲区的某些部分为无效。这样，GPU就知道这些部分的内容不再需要，可以避免不必要的数据交换。 应用场景：通常在使用帧缓冲区对象（FBO）时，当我们切换到不同的FBO或者不再需要某些颜色、深度或模板缓冲区的内容时，可以调用该函数。 性能影响：尽管在RenderDoc等工具中可能显示glInvalidateFramebuffer的耗时较高，但实际上，只有少数几次调用不会对渲染性能产生影响。 glClear： 功能：glClear 用于清除当前帧缓冲区的内容，包括颜色缓冲区、深度缓冲区和模板缓冲区。 应用场景：在每一帧开始时，我们通常会调用glClear来准备帧缓冲区，以便进行新的绘制。 性能影响：glClear的性能开销通常较小，但在某些情况下，如果频繁调用，可能会影响性能。 总结： glInvalidateFramebuffer 用于标记帧缓冲区的部分内容为无效，以减少不必要的数据交换。 glClear 用于清除整个帧缓冲区的内容，以准备进行新的绘制。 在使用RenderDoc等工具时，可以忽略glInvalidateFramebuffer的耗时，但需要关注片上高速缓存回写内存的消耗 。 glDiscardFramebufferEXT void glDiscardFramebufferEXT(enum target, sizei numAttachments, const enum *attachments); 这个扩展提供了一个新的命令，glDiscardFramebufferEXT，它会使得指定帧缓冲附件的内容变为未定义状态。在未来的操作修改内容之前，这些指定缓冲区的内容是未定义的，只有被修改的区域保证包含有效内容。有效地使用此命令可以为实现提供新的优化机会。 一些 OpenGL ES 实现会将帧缓冲图像缓存到一个小的快速内存池中。在渲染之前，这些实现必须将逻辑缓冲区（如颜色、深度、模板等）的现有内容加载到该内存中。渲染后，这些缓冲区中的一部分或全部也会被存储回外部内存，以便将来再次使用其内容。在许多应用程序中，逻辑缓冲区在渲染开始时被清除。如果是这样，加载或存储这些缓冲区的工作就是浪费的。 即使没有这个扩展，如果渲染的一帧从全屏清除开始，OpenGL ES 实现也可以优化掉在渲染帧之前加载帧缓冲区内容的步骤。有了这个扩展，应用程序可以使用 DiscardFramebufferEXT 来表示帧缓冲区的内容将不再需要。在这种情况下，OpenGL ES 实现也可以优化掉在渲染帧后存储帧缓冲区内容的步骤。 glDiscardFramebufferEXT的工作是告知驱动程序你不关心framebuffer的内容。什么驱动程序(或GPU)决定用它做什么 - 这不取决于你。驱动程序可以将所有内容重置为0，或者它可以保持原样，或者当您下次调用glClear时它将使用此信息并且将更有效地执行它(例如通过为内容分配新内存，而不是执行memset与0值)。不要担心它会做什么 Texture obj与RBO的区别 FBO(Frame Buffer Object)即帧缓冲区对象，是一个可添加缓冲区的容器，可以为其添加纹理或渲染缓冲区对象（RBO),它们的区别如下图 shader 初始化 变量 uniform变量 uniform变量是外部application程序传递给（vertex和fragment）shader的变量。因此它是application通过函数glUniform**（）函数赋值的。在（vertex和fragment）shader程序内部，uniform变量就像是C语言里面的常量（const ），它不能被shader程序修改。 attribute变量 attribute变量是只能在vertex shader中使用的变量。它不能在fragment shader中声明attribute变量，也不能被fragment shader中使用。一般用attribute变量来表示一些顶点的数据，如：顶点坐标，法线，纹理坐标，顶点颜色等。在application中，一般用函数glBindAttribLocation（）来绑定每个attribute变量的位置，然后用函数glVertexAttribPointer（）为每个attribute变量赋值。 varying变量 varying变量是vertex和fragment shader之间做数据传递用的。一般vertex shader修改varying变量的值，然后fragment shader使用该varying变量的值。因此varying变量在vertex和fragment shader二者之间的声明必须是一致的。application不能使用此变量。 资源释放 dmabuf资源释放主要考虑texture，eglImage 和dmabuf， FBO不需要考虑。 texture、 eglImage和 dmabuf是一体的，释放时需要调用glDeleteTextures， eglDestroyImageKHR， close(dmabuf)， 三个都完成后 dmabuf才真正释放。 如果texture附加到一个FBO上，glDeleteTextrues()后会使得该FBO的附加纹理为0. 如果前面已经attach 一个纹理到FBO， 在attach 新纹理到另一个FBO时，要先把前一个FBO的纹理设置为0, 否则释放不掉。 int main(int argc, char const *argv[]){ init_dev(); egl_Init(); dmabuf_fd = allocate_dmabuf(1920*1080*4); textureid = create_texture_for_dmabuf(dmabuf_fd, 1920, 1080, &amp;eglImg); glGenFramebuffers(1, &amp;FBO2); glBindFramebuffer(GL_FRAMEBUFFER, FBO2); glBindTexture(GL_TEXTURE_EXTERNAL_OES, textureid); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_EXTERNAL_OES, textureid, 0); if (glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE) { assert(0); } // 得到当前附加纹理ID为 1 glGetFramebufferAttachmentParameteriv(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_FRAMEBUFFER_ATTACHMENT_OBJECT_NAME, &amp;text); free_dmabuf(dmabuf_fd); glDeleteTextures(1, &amp;textureid); eglDestroyImageKHR(g_EGLDisplay, eglImg); // 完成后 /sys/kernel/debug/dmabuf/bufferinfo 中dmabuf已经释放 // 得到当前附加纹理ID为 0 glGetFramebufferAttachmentParameteriv(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_FRAMEBUFFER_ATTACHMENT_OBJECT_NAME, &amp;text); glDeleteFramebuffers(1, &amp;FBO2); eglDestroyContext(g_EGLDisplay, g_EGLContext); return 0; int main(int argc, char const *argv[]){ init_dev(); egl_Init(); dmabuf_fd1 = allocate_dmabuf(1920*1080*4); textureid1 = create_texture_for_dmabuf(dmabuf_fd1, 1920, 1080, &amp;eglImg1); dmabuf_fd2 = allocate_dmabuf(1920*1080*4); textureid2 = create_texture_for_dmabuf(dmabuf_fd2, 1920, 1080, &amp;eglImg2); glGenFramebuffers(1, &amp;FBO1); glBindFramebuffer(GL_FRAMEBUFFER, FBO1); glBindTexture(GL_TEXTURE_EXTERNAL_OES, textureid1); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_EXTERNAL_OES, textureid1, 0); if (glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE) { assert(0); } // 注意要设置FBO 的纹理为0， 否则后面不能真正释放 glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_EXTERNAL_OES, 0, 0); glGenFramebuffers(1, &amp;FBO2); glBindFramebuffer(GL_FRAMEBUFFER, FBO2); glBindTexture(GL_TEXTURE_EXTERNAL_OES, textureid2); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_EXTERNAL_OES, textureid2, 0); if (glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE) { assert(0); } free_dmabuf(dmabuf_fd1); glDeleteTextures(1, &amp;textureid1); eglDestroyImageKHR(g_EGLDisplay, eglImg1); free_dmabuf(dmabuf_fd2); glDeleteTextures(1, &amp;textureid2); eglDestroyImageKHR(g_EGLDisplay, eglImg2); // 完成后 /sys/kernel/debug/dmabuf/bufferinfo 中dmabuf已经释放 glDeleteFramebuffers(1, &amp;FBO1); glDeleteFramebuffers(1, &amp;FBO2); eglDestroyContext(g_EGLDisplay, g_EGLContext); return 0; 纹理过滤 一个纹理通常是由很多的像素点组成的，那么通过纹理坐标如何得到对应点应该的颜色，这就是纹理采样方式或纹理过滤。 下面是两种重要的纹理采样(纹理过滤)： GL_NEAREST:邻近过滤，这个是默认纹理过滤方式，OpenGL会选择中心点最接近纹理坐标的那个像素. 这种方式放大有颗粒感 GL_LINEAR：线性过滤，它会基于纹理坐标附近的纹理像素，计算出一个插值，近似出这些纹理像素之间的颜色，一个纹理像素的中心距离纹理坐标越近，那么这个纹理像素的颜色对最终的样本颜色的贡献越大， 放大后较平滑。 二者放大后的效果比较 当纹理被放大或缩小贴到一个平面时，我们可以设置不同的纹理采样(纹理过滤)方式，达到不同的效果。它所涉及到的OpenGL 函数如下： glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST); // 缩小 glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); // 放大 纹理环绕 纹理坐标的范围通常是从(0, 0)到(1, 1)，那如果我们把纹理坐标设置在范围之外会发生什么？OpenGL默认的行为是重复这个纹理图像。 环绕方式 描述 GL_REPEAT 对纹理的默认行为。重复纹理图像。 GL_MIRRORED_REPEAT 和GL_REPEAT一样，但每次重复图片是镜像放置的。 GL_CLAMP_TO_EDGE 纹理坐标会被约束在0到1之间，超出的部分会重复纹理坐标的边缘，产生一种边缘被拉伸的效果。 GL_CLAMP_TO_BORDER 超出的坐标为用户指定的边缘颜色 相关函数 glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_MIRRORED_REPEAT); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_MIRRORED_REPEAT); 如果我们选择GL_CLAMP_TO_BORDER选项，我们还需要指定一个边缘的颜色。这需要使用glTexParameter函数的fv后缀形式，用GL_TEXTURE_BORDER_COLOR作为它的选项，并且传递一个float数组作为边缘的颜色值： float borderColor[] = { 1.0f, 1.0f, 0.0f, 1.0f }; glTexParameterfv(GL_TEXTURE_2D, GL_TEXTURE_BORDER_COLOR, borderColor); glMapBufferRange glMapBufferRange 是一个 OpenGL 函数，用于将指定缓冲对象的一部分数据映射到客户端的地址空间中,可以减少一次CPU 内存数据的读写。 以下是关于 glMapBufferRange 的详细说明： 作用： glMapBufferRange 允许你直接访问缓冲对象的数据，以便在客户端代码中进行读取或写入操作。 通过映射缓冲区的一部分，你可以有效地操作其中的数据。 参数： target：目标缓冲对象类型，通常为 GL_ARRAY_BUFFER 或 GL_ELEMENT_ARRAY_BUFFER。 offset：要映射的数据在缓冲对象中的偏移量。 length：要映射的数据的长度。 access：访问权限，可以是 GL_READ_ONLY、GL_WRITE_ONLY 或 GL_READ_WRITE。 返回值：映射后的指针，用于访问缓冲区数据。 使用场景： 在顶点缓冲对象（VBO）中，你可以使用 glMapBufferRange 来更新顶点数据。 在像素缓冲对象（PBO）中，你可以使用它来处理像素数据。 总之，glMapBufferRange 允许你映射缓冲对象的一部分数据，以便在客户端代码中直接访问和操作。 #include &lt;GL/glew.h&gt; #include &lt;GLFW/glfw3.h&gt; #include &lt;iostream&gt; int main() { // Initialize GLFW and create a window if (!glfwInit()) { std::cerr &lt;&lt; \"Failed to initialize GLFW\" &lt;&lt; std::endl; return -1; } GLFWwindow* window = glfwCreateWindow(800, 600, \"OpenGL Sample\", nullptr, nullptr); if (!window) { std::cerr &lt;&lt; \"Failed to create GLFW window\" &lt;&lt; std::endl; glfwTerminate(); return -1; } glfwMakeContextCurrent(window); // Initialize GLEW if (glewInit() != GLEW_OK) { std::cerr &lt;&lt; \"Failed to initialize GLEW\" &lt;&lt; std::endl; return -1; } // Create a buffer object (VBO) GLuint vbo; glGenBuffers(1, &amp;vbo); glBindBuffer(GL_ARRAY_BUFFER, vbo); // Allocate storage for the buffer glBufferData(GL_ARRAY_BUFFER, 1024, nullptr, GL_DYNAMIC_DRAW); // Map a portion of the buffer GLintptr offset = 0; GLsizeiptr size = 512; GLvoid* mappedData = glMapBufferRange(GL_ARRAY_BUFFER, offset, size, GL_MAP_WRITE_BIT | GL_MAP_INVALIDATE_BUFFER_BIT); if (mappedData) { // Modify the data in the mapped region // ... // Unmap the buffer glUnmapBuffer(GL_ARRAY_BUFFER); } else { std::cerr &lt;&lt; \"Failed to map buffer\" &lt;&lt; std::endl; } // Main loop while (!glfwWindowShouldClose(window)) { // Render your scene using the modified buffer data // ... glfwSwapBuffers(window); glfwPollEvents(); } // Cleanup glDeleteBuffers(1, &amp;vbo); glfwDestroyWindow(window); glfwTerminate(); return 0; } static void DumpTexture(GLuint TextureId, GLuint x0, GLuint y0, GLuint x1, GLuint y1){ int fbo0; glGetIntegerv( GL_FRAMEBUFFER_BINDING, &amp;fbo0); GLuint fbo; glGenFramebuffers(1, &amp;fbo); glBindFramebuffer(GL_FRAMEBUFFER, fbo); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, TextureId, 0); if (glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE) { printf(\"glCheckFramebufferStatus() failed\\n\"); return; } GLuint size = (x1-x0)* (y1-y0)*4; GLuint pbo_down; glGenBuffers(1, &amp;pbo_down); glBindBuffer(GL_PIXEL_PACK_BUFFER, pbo_down); glBufferData(GL_PIXEL_PACK_BUFFER, size, NULL, GL_STREAM_READ); glReadPixels(x0,y0, x1, y1, GL_RGBA, GL_UNSIGNED_BYTE, 0); GLubyte *src = (GLubyte*)glMapBufferRange(GL_PIXEL_PACK_BUFFER,0, size, GL_MAP_READ_BIT); GLubyte *buffer = malloc(size); memcpy(buffer, src, size); glUnmapBuffer(GL_PIXEL_PACK_BUFFER); glBindBuffer(GL_PIXEL_PACK_BUFFER, 0); stbi_write_png(\"/tmp/texture_img.png\", (int)(x1-x0), (int)(y1-y0), 4, buffer, (int)((x1-x0)*4)); glBindFramebuffer(GL_FRAMEBUFFER, fbo0); } freetype 下图是freetype调用的基本框架。 参看上图，在绘制字符时以baseline为水平基准，则所有的字符就会对齐。"
  },"/blog/jekyll/2002-08-10-Wayland-Misc.html": {
    "title": "Wayland Misc",
    "keywords": "Jekyll",
    "url": "/blog/jekyll/2002-08-10-Wayland-Misc.html",
    "body": "Expat Expat 是一个用 C 编写的流式 XML 解析库。它在处理文件大小超出内存限制且性能和灵活性至关重要的情况下表现出色。许多应用程序、库和硬件都使用了 Expat，并且还有一些绑定和第三方封装。 以下是关于 Expat 的一些重要信息： 什么是 Expat？ Expat 是一个流式解析器，应用程序在开始解析之前向解析器注册处理程序，以处理 XML 文档中发现的相关结构（例如开始标签等）。 主要特点： 流式解析：Expat 是流式解析器，它在解析之前注册处理程序，然后在文档中发现相关结构时调用这些处理程序。 适用于大文件：Expat 适用于那些文件太大而无法放入内存的情况。 性能优越：Expat 在解析速度和灵活性方面表现出色。 广泛使用：许多应用程序、库和硬件都使用了 Expat。 绑定和封装：Expat 还有一些绑定和第三方封装，使其更易于在不同环境中使用。 请查看 这篇介绍性文章 示例 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;expat.h&gt; // 回调函数：处理开始标签 void startElement(void *userData, const char *name, const char **atts) { printf(\"Start element: %s\\n\", name); } // 回调函数：处理结束标签 void endElement(void *userData, const char *name) { printf(\"End element: %s\\n\", name); } int main() { // 创建解析器 XML_Parser parser = XML_ParserCreate(NULL); if (!parser) { fprintf(stderr, \"Error creating XML parser.\\n\"); return 1; } // 设置回调函数 XML_SetElementHandler(parser, startElement, endElement); // XML 数据（示例） const char *xmlData = \"&lt;root&gt;&lt;item&gt;Apple&lt;/item&gt;&lt;item&gt;Banana&lt;/item&gt;&lt;/root&gt;\"; // 解析 XML 数据 if (XML_Parse(parser, xmlData, strlen(xmlData), 1) == XML_STATUS_ERROR) { fprintf(stderr, \"Error parsing XML data.\\n\"); XML_ParserFree(parser); return 1; } // 释放解析器 XML_ParserFree(parser); return 0; } libffi libffi 是一个用 C 编写的可移植的外部函数接口库。它为不同的调用约定提供了一个高级别的编程接口，允许程序员在运行时调用任何由调用接口描述指定的函数。FFI 代表外部函数接口，是允许在一种语言中编写的代码调用另一种语言中编写的代码的接口。libffi 实际上只提供了完整特性的外部函数接口的最底层、与机器相关的部分。在libffi之上必须存在一个处理两种语言之间传递的值的类型转换层。 以下是关于 libffi 的一些重要信息： 什么是 libffi？ 编译器为高级语言生成遵循某些约定的代码。其中之一是“调用约定”。“调用约定”实际上是编译器对函数参数在进入函数时的位置的一组假设。“调用约定”还指定了函数的返回值在哪里找到。有些程序在编译时可能不知道要传递给函数的参数。例如，解释器可能在运行时告知调用给定函数所使用的参数的数量和类型。libffi 可以在这些程序中使用，以提供从解释器程序到编译代码的桥梁。libffi 库为各种调用约定提供了一个可移植的高级别编程接口，允许程序员在运行时调用任何由调用接口描述指定的函数。FFI 代表外部函数接口。外部函数接口是允许在一种语言中编写的代码调用另一种语言中编写的代码的接口。libffi 实际上只提供了完整特性的外部函数接口的最底层、与机器相关的部分。在libffi之上必须存在一个处理两种语言之间传递的值的类型转换层。 支持的平台：libffi 已经移植到许多不同的平台。发布时，已经测试了以下基本配置： 架构：AArch64（ARM64）、Alpha、ARC、ARM、AVR32、Blackfin 等。 操作系统：Linux、iOS、Windows 等。 编译器：Clang、GCC、MSVC 等。 如想了解更多关于 libffi 的细节，可以查看 libffi 官方网页。 示例 : 在这个示例中，我们使用了 libffi 来调用标准库函数 puts，并传递了不同的字符串作为参数。这个示例展示了如何使用 libffi 动态地调用外部函数。 #include &lt;stdio.h&gt; #include &lt;ffi.h&gt; int main() { ffi_cif cif; ffi_type *args[1]; void *values[1]; char *s; ffi_arg rc; // 初始化参数信息向量 args[0] = &amp;ffi_type_pointer; values[0] = &amp;s; // 初始化 cif if (ffi_prep_cif(&amp;cif, FFI_DEFAULT_ABI, 1, &amp;ffi_type_sint, args) == FFI_OK) { s = \"Hello World!\"; ffi_call(&amp;cif, (void (*)(void))puts, &amp;rc, values); // rc 现在保存了对 puts 的调用结果 // 更改 s 的值后，可以再次调用 puts() s = \"This is cool!\"; ffi_call(&amp;cif, (void (*)(void))puts, &amp;rc, values); } return 0; }"
  },"/blog/jekyll/2002-06-11-Weston.html": {
    "title": "Weston Misc",
    "keywords": "Jekyll",
    "url": "/blog/jekyll/2002-06-11-Weston.html",
    "body": "1. 启动Weston 1.1 实现内容 解析cmdline 初始化log系统 创建wl_display对象，并侦听client接入 创建weston_compositor对象，从而创建global resource compositor 和 shm， 以前其他资源 load backend， 默认为drm_backend, 在drm_backend初始化的过程中会load gl_renderer load shell, 默认为desktop-shell.so 调用wl_display_run( ) 循环等待event的发生 1.2 伪代码 int wet_main(int argc, char *argv[], const struct weston_testsuite_data *test_data){ // 初始化 layoutput_list wl_list_init(&amp;wet.layoutput_list); ... // parse command line ... // init log system ... // 调用wayland提供的函数wl_display_create() // 创建 wl_display 对象 display = wl_display_create(); ... // 创建 weston_compositor 对象 // --&gt; 创建 global resource compositor and shm 以及其他resource weston_compositor_create( ); // 读取config for compositor ... // load backend，通用的为load_drm_backend( ) // 最终调用 对应backend实现的weston_backend_init( ) // 在backend 初始化的过程中会装载 gl_renderer load_backend(compositor, backend) ... // 创建socket， 侦听client的连接请求 weston_create_listening_socket(display, socket_name) ... // load shell, 默认为 desktop-shell.so wet_load_shell(compositor, shell, ...) ... // loop, 循环等待event的发生 wl_display_run(display) ... // 退出流程，资源的释放 } 1.3 backend, renderer, shell的作用 结构图 backend { destroy() repaint_begin() //composite之前调用 repaint_cancel() // 中途取消 repaint_flush() // composite 完成后调用， 可用于实现提交到display create_output() // 创建weston_output device_changed() can_scanout_dmabuf() }Weston_backend, Compositor-&gt;backend renderer: renderer接口供backend内部使用，外部通过调用backend接口触发 { display_create() output_window_create() output_pbuffer_create() output_destroy() output_set_border() create_fence_fd() } gl_renderer_interface 2. Client 动作 2.1 Client的接入和global资源代理的创建 流程 连接display 获得registry，注册listener，用于处理weston资源变化时的callback 根据资源变化的callback， 创建各类资源的proxy 进入loop，不断调用wl_display_dispatch( )，使得wayland内部循环处理各类event 伪代码 static void global_resource_found(void* data, struct wl_registry* registry, uint32_t name, const char* interface, uint32_t version) { // 通过字符串interface 判断是什么resource， // 通过wl_registry_bind() 创建对应的 resource proxy if (strcmp(interface, \"wl_compositor\") == 0) { // 构建了 compositor 的 proxy compositor = wl_registry_bind(registry, name, &amp;wl_compositor_interface, 4)); }else if (strcmp(interface, \"wl_shm\") == 0) { // 构建了 shm 的proxy shm = wl_registry_bind(registry, name, &amp;wl_shm_interface, 1); } ... } // 当weston的global resoure发生变化时，通过如下回调函数通知到client wl_registry_listener registry_listener = { // 发现新global resource的回调函数 global_resource_found, // global resource remove的回调函数 global_resource_remove } int main(int argc, char** argv) { // 1. 调用wayland提供的 wl_display_connect( ), 连接到weston( wayland server) // 对应到weston启动中的weston_create_listening_socket() display = wl_display_connect(NULL); ... // 2. 获取 wl_registry, 并侦听它的callback registry= wl_display_get_registry(display); wl_registry_add_listener(registry, &amp;registry_listener, display); ... // 3. 循环等待， // 调用wl_display_dispatch( )，由wayland处理weston发来的event while(ret != -1){ ret = wl_display_dispatch( ); } } 2.2 内部weston - client 通讯机制 request: Client –&gt; Server event : Server –&gt; Client 术语上，Wayland 中把 Client 发给 Server 的跨进程函数调用称为 request，反方向的跨进程函数调用称为 event。 本质上，它们处理的方式是类似的。 要让两个进程通过 socket 进行函数调用，首先需要将调用抽象成数据流的形式。这个数据流应该包含函数名、参数等信息。 IPC 函数的接口定义是应该同时包含在 Client 和 Server 端的库中的，其中包含了接口对象所支持的 request 和 event 的函数签名。因此这部分不用传输，只要传输目标对象 id，方法 id 和参数列表这些信息就可以了。 这些信息会通过 wl_closure_marshal()写入 wl_closure 结构，再由 serialize_closure()变成数据流。 等到了目标进程后， 会从数据流通过 wl_connection_demarshal()转回 wl_closure。 IPC 图示 object IPC 机制 这个过程类似于 Android 中的 Parcel 机制。那么 问题来了，参数中的整形，字符串什么的都好搞，拷贝就行。但如果参数中包含对象，我们不能把整个对象 拷贝过去，也不能传引用过去。那么需要一种机制来作同一对象在 Server 和 Client 端的映射，这是通过 wl_map 实现的。 wl_map 在 Client 和 Server 端各有一个，它们分别存了 wl_proxy 和 wl_resource 的数组，且是 一一对应的。这些对象在这个数组中的索引作为它们的 id。这样，参数中的对象只要传 id，这个 id 被传到目 的地后会通过查找这个 wl_map 表来得到本地相应的对象。在功能上类似于 Android 中的 BpXXX 和 BnXXX。 wl_proxy 和 wl_resource 都包含 wl_object 对象。这个 wl_object 和面向对象语言里的对象概念类似，它有 interface 成员描述了这个对象所实现的接口，implementation 是这些接口的实现函数的函数指针数组，id 就是 在 wl_map 结构里数组中的索引。 前面所说的 Client 绑定 Server 端资源的过程就是在 Client 端创建 wl_proxy， 在 Server 端创建 wl_resource。然后 Client 就可以通过 wl_proxy 调用 Server 端对应 wl_resource 的 request， Server 端就可以通过 wl_resource 调用 Client 端对应 wl_proxy 的 event。 这个映射过程如下图所示(以 wl_registry 为例) 2.3 Client 创建各类资源proxy // wl_surface wl_surface = wl_compositor_create_surface(compositor) // wl_buffer wl_shm_pool = wl_shm_create_pool( ) wl_buffer = wl_shm_pool_create_buffer( ) // attach buffer to surface wl_surface_attach(wl_surface, wl_buffer) /* 以下与窗口的管理\\显示相关 */ // xdg_surface // xdg_wm_base 它也是一个global resouce，对应到 desktop-shell xdg_surface = xdg_wm_base_get_xdg_surface(xdg_wm_base, wl_surface) // xdg_toplevel xdg_toplevel = xdg_surface_get_toplevel(xdg_toplevel) // wl_keyboard // wl_seat 是一个global resource // 通过wl_keyboard 创建一个listener就可接收按键 wl_keyboard = wl_seat_get_keyboard(wl_seat) wl_keyboard_add_listener(wl_keyboard, keyboard_listener) // wl_pointer 鼠标指针 // 通过wl_pointer 创建一个listener可以接收鼠标的移动信息 wl_pointre = wl_seat_get_pointer(wl_weat) wl_pointer_add_listener(wl_pointer, pointer_listener) ... ... 2.4 Client 渲染 伪代码 simple-egl.c /*-------------------- egl 初始化工作 ------------------------*/ // egl lib 应该要支持wayland。 // 这样在调用一些egl接口时，在其内部会调用wayland接口与Wayland server交换信息 // 如函数：eglGetDisplay( ) , eglCreateWindowSurface( )， eglSwapBuffers 等 // 1. 获取egl_display egl_display = weston_platform_get_egl_display(EGL_PLATFORM_WAYLAND_KHR, wl_display, ...) or egl_display = eglGetDisplay(wl_display) // 2. 初始化 egl eglInitialize(egl_display) // 3. 通用elg 配置 eglGetConfigs() eglChooseConfig( ) eglCreateContext( ) /* ----------------------gl 准备工作------------------------------*/ // 1.创建 shader glCreateShader( ) // 2.创建 Program glCreateProgram( ) // 3. attach shader to program glAttachShader( ) // 4. Link program glLinkProgram( ) // 5. 使用program glUseProgram( ) /*-------------------------wl_surface 关联egl_surface----------------*/ wl_egl_window-&gt;surface = wl_surface; wl_egl_window-&gt;width = width; wl_egl_window-&gt;height = height; eglCreateWindowSurface(egl_display, ... , wl_egl_window) /*------------------------------------------------------------------*/ gl 绘制图形 /*-------------------------------------------------------------------*/ // 内部实现应该调用wayland接口来swap buffer eglSwapBuffers(egl_display, egl_surface) ... 2.5. Client 提交渲染好的surface wl_surface_commit( ) 3. 各个Surface的合成与呈现呈现· 3.1 流程 compositor遍历每个weston_output 发起repaint。weston_output_schedule_repaint( ) 通知weston_output具体实现–backend_output, 开始repaint的前期准备工作, 对应函数start_repaint_loop( )， drm实现暂无内容 backend_output通知compositor可以开始output repaint compositor 调用weston_output相关backend的repaint_begin( )，drm_backend 创建了pending_state compoistor 调用weston_output_repaint(), 开始repaint。 调用weston_compositor_build_view_list( ) 构建view_list, 得到output的一个paint_node_z_order_list 调用drm_backend assign_planes( ) 设置输出plane 调用drm_backend drm_output_repaint( ), 最终指向gl_renderer_repaint_output( ) 依据paint_node_z_order_list, OpenGL依次建立shader，texture等进行渲染 全部完成后，提交呈现 sequenceDiagram participant C as Compositor participant O as Weston_output participant B as Backend loop 遍历weston_output_list C -&gt;&gt; O: 要开始repaint_loop &lt;br /&gt;call backend_output start_repaint_loop( ) C -&gt;&gt; B: repaint_begin( ) Note right of B: 创建 pending_state C -&gt;&gt; O: 通知output repaint O -&gt;&gt; C: 构建view_list, build_view_list( ) Note left of C:构建paint_node_z_order_list C -&gt;&gt; B: assign_planes( ),设置输出plane C -&gt;&gt; B: drm_output_repaint( ) Note right of B: 调用OpenGL API &lt;br/&gt;结合paint_node_z_order_list&lt;br/&gt;进行渲染 end"
  },"/blog/graphic/2002-05-15-Wayland&Weston.html": {
    "title": "Wayland&amp;Weston",
    "keywords": "graphic",
    "url": "/blog/graphic/2002-05-15-Wayland&Weston.html",
    "body": "1.编译 预设环境 $export WLD=“~/xxxxxxxxx” //定义一个wayland目录，编译生成到这里 sudo apt install meson sudo apt install some_depenced_libs Wayland $ git clone https://gitlab.freedesktop.org/wayland/wayland.git $ cd wayland $ meson build/ --prefix=$WLD $ ninja -C build/ install $ cd .. Wayland protocols $ git clone https://gitlab.freedesktop.org/wayland/wayland-protocols.git $ cd wayland-protocols $ meson build/ --prefix=$WLD $ ninja -C build/ install $ cd .. Weston $ git clone https://gitlab.freedesktop.org/wayland/weston.git $ cd weston $ meson build/ --prefix=$WLD $ ninja -C build/ install $ cd .. 第三方依赖库的编译 需要的第三方库 Libxml2-dev Libexpat-dev Libffi-dev Libinput-dev Libdrm-dev Libxkbcommon-dev libpixman-1-dev libcairo2-dev libudev 它们有的通过configure配置然后make， 有的通过mesa, ninja编译. 需要注意设置正确的PKG_CONFIG_PATH，使的pkg-config可以找到相关的库信息。 如果是mesa，留意目录下是否有meson_options.txt, 其中定义了各种编译选项，可对它进行修改。 meson 交叉编译 在meson系统中进行交叉编译，需要为meson中添加参数 –cross-file xxx_filename, 在xxx_filename中定义gcc等的路径路径 下面是一个示例 [binaries] c = '/opt/cross-arm/bin/arm-linux-gnueabihf-gcc' cpp = '/opt/cross-arm/bin/arm-linux-gnueabihf-g++' ld ='/opt/cross-arm/bin/arm-linux-gnueabihf-ld' strip= '/opt/cross-arm/bin/arm-linux-gnueabihf-strip' pkgconfig ='/usr/bin/pkg-config' [host_machine] system = 'linux' cpu_family = 'aarch64' cpu = 'cortex-a73' endian = 'little 在configure系统中，则是export GCC CFLAG 等环境变量 指定输入输出 meson build_dir/ sourc_code_dir/ 2.运行 configure file copy weston.ini to ~/.config/ run weston. login as root ./weston –tty=2 Ctrl+Alt+Backspace –&gt; 退出Weston界面 如一般用户启动weston，这时要借助weston-launch 来完成。 相关code：libweston/weston-launch.c run weston-client test login as root export WAYLAND_DISPLAY=wayland-1 示例1, 指定backend 和shell Server: ./weston --tty=2 --shell=fullscreen-shell.so --backend= drm-backend.so Client: weston-simple-dmabuf-egl 示例2 Server：./weston --tty=2 --shell=fullscreen-shell.so --backend=fbdev-backend.so Client./weston-simple-damage 3.Wayland 3.1 code的组成 wayland主要由三部分组成。 Wayland提供了protocol的定义方式 在路径protocol文件夹下，以xml的形式定义了Wayland的核心协议。 如下面的xml，就定义了wl_display &lt;interface name=\"wl_display\" version=\"1\"&gt; &lt;description summary=\"core global object\"&gt; The core global object. This is a special singleton object. It is used for internal Wayland protocol features. &lt;/description&gt; ..... &lt;/interface&gt; xml到code的转换工具 xml到code的转换工具是wayland-scanner，它的source code在wayland目录下，可通过编译生成它。 wayland还实现了一个高效率的 Server+Client通信模式 Server端，主要是使用epoll+socket监听Client端事件，并对收到的消息反序列化。 Client端：wayland-client提供了已实现的序列化接口 总之，官方提供的Wayland源码，主要包括协议的定义、协议到代码的生成工具，以及一套实现好的通信模型 3.2 基础概念 几乎所有的Wayland API都需要Wayland全局对象作为参数。 名称 作用 wl_display 表示与服务器的连接。 wl_registry 全局对象注册表，全局对象需要通过它获取。 wl_compositor 窗口合成器，也是服务器。 wl_shm 内存管理器，与窗口合成器共享内存用。 wl_shell 支持窗口操作功能。 wl_seat 输入设备管理器。 。 通过capabilities( )回调函数得到pointer、keyboard等 wl_pointer 代表鼠标设备。 wl_keyboard 代表键盘设备。 Wayland没有提供Get函数来获取以上全局对象，只能通过wl_registry获取全局对象 3.2.1 Client端object的使用 Wayland中server提供给client使用的对象可以归为 global object和 resource object。 Global 也是一中resource。 Global object如 wl_display, wl_compositor, wl_seat 等。 它们在client端是通过bind来获取到一个client 对应对象，然后就可以对它进行操作 Resource object 在client端是通过Global object 来创建的， 如 wl_surface, wl_shell_surface 等。 3.2.2 Server端object的实现 Global 资源的创建： wayland/src/wayland-server.c wl_global_create( …., bind_xxx_function ) bind_xxx_function // 在client中调用wl_registry_bind函数时被call wl_resource_create( ) wayland protocal 提供的接口，创建一个resource object，并把它插入到client的map表中，以后就可以通过ID 找到对应的resource obj，有利于server&lt;–&gt;client 通讯调用对应函数 wl_resource_set_implementation( ) // 设定资源接口的实现, 可供client通过IPC调用 wl_priv_signal_emit( ) // wl_client_add_resource_created_listener will be notified 普通 Resource 的创建： 应该是由某些 对global 资源的操作触发 wl_resource_create() wl_resource_set_implementation( ) 3.2.3 Client Server通讯 Listener 是server –&gt; client 的通知方式. Client 注册listener 给server，有监听事件发生，server发信息给client. Server侧发生通知的函数命名特征: xxxx_send_xxxx( ) 3.2.4 Wayland Server实现 3.2.4 Wayland Client实现 3.3 简单的wayland app 流程 3.4 Wayland log 需设置环境变量： export WAYLAND_DEBUG=1 3.5 xml 其中最重要的wayland.xml中定义了如下接口： ./wayland/protocol/wayland.xml wl_display wl_registry wl_callback wl_compositor wl_shm_pool wl_shm wl_buffer wl_data_offer wl_data_source wl_data_device wl_data_device_manager wl_shell wl_shell_surface wl_surface wl_seat wl_pointer wl_keyboard wl_touch wl_output wl_region wl_subcompositor wl_subsurface 3.6 在线查看 wayland协议 各种协议查看 https://wayland.app/ The Wayland Protocol 中文版 https://wayland.arktoria.org/ 4.Weston 简介 Weston是基于wayland协议，实现的Compositor。 Weston的入口在（这里以10.0.0为例）: weston-10.0.0./compositor/main.c weston-10.0.0./compositor/executable.c 4.1 框架与对象 框架 Weston中有以下几个主要部分：Shell、Compositor、Render、backend、Input Shell：窗口管理器，画面层级、窗口信息、窗口生命周期、Focus窗口等等一些偏向于业务层的处理。默认的shell为desktop-shell，同时提供了其他shell实现（如ivi-shell） Compositor：负责画面的合成，使用DRM连接output，将画面输出到实际显示设备。 Render：负责渲染，比如gl-render，做一些纹理贴图操作。 Input：libinput模块，与evdev、uvdev模块交互，从底层设备节点接收touch、key等输入 backend: Weston 使用后端的概念来抽象其运行环境的底层接口。后端负责处理输入和生成输出 对象 4.2 main函数的基本框架 实现内容： 解析cmdline 初始化log系统 创建wl_display对象，并侦听client接入 创建weston_compositor对象，从而创建global resource compositor 和 shm， 以前其他资源 load backend， 默认为drm_backend, 在drm_backend初始化的过程中会load gl_renderer load shell, 默认为desktop-shell.so 调用wl_display_run( ) 循环等待event的发生 int wet_main(int argc, char *argv[], const struct weston_testsuite_data *test_data){ // 初始化 layoutput_list wl_list_init(&amp;wet.layoutput_list); ... // parse command line ... // init log system ... // 调用wayland提供的函数wl_display_create() // 创建 wl_display 对象 display = wl_display_create(); ... // 创建 weston_compositor 对象 // --&gt; 创建 global resource compositor and shm 以及其他resource weston_compositor_create( ); // 读取config for compositor ... // load backend，通用的为load_drm_backend( ) // 最终调用 对应backend实现的weston_backend_init( ) // 在backend 初始化的过程中会装载 gl_renderer load_backend(compositor, backend) ... // 创建socket， 侦听client的连接请求 weston_create_listening_socket(display, socket_name) ... // load shell, 默认为 desktop-shell.so wet_load_shell(compositor, shell, ...) ... // loop, 循环等待event的发生 wl_display_run(display) ... // 退出流程，资源的释放 } 4.3 backend创建 Weston 使用后端的概念来抽象其运行环境的底层接口。后端负责处理输入和生成输出。 作为 libweston 的用户，Weston 可以在不同的后端上运行，包括嵌套在其他 Wayland 合成器中的方式（使用 wayland 后端），也可以在 X11 上运行，或者在独立的后端上运行，例如 DRM/KMS。 大多数情况下，人们应该允许 Weston 自动选择后端，因为它会产生最佳结果。例如，在已经运行另一个图形环境的机器上运行 Weston 时，它会自动选择合适的后端，无论是另一个 Wayland 合成器还是 X11 服务器。 只有在你知道 Weston 自动选择的后端不是最佳选择，或者你想使用不同于默认加载的后端时，才需要手动指定后端。在这种情况下，可以使用 -B [backend] 命令行选项来选择后端。 可用的后端包括： drm：独立运行在 DRM/KMS 和 evdev 上（推荐）。 wayland：作为 Wayland 应用程序嵌套在另一个 Wayland 合成器实例中。 x11：作为 X11 应用程序嵌套在 X11 显示服务器实例中。 rdp：作为一个没有本地输入或输出的 RDP 服务器运行。 headless：无输入或输出运行，适用于测试套件。 pipewire：无输入，输出到 PipeWire 节点。 weston_backend_init { destroy() repaint_begin() //composite之前调用 repaint_cancel() // 中途取消 repaint_flush() // composite 完成后调用， 可用于实现提交到display create_output() // 创建weston_output device_changed() can_scanout_dmabuf() }Weston_backend, Compositor-&gt;backend 4.4 shell创建 weston提供了多种shell，比如：desktop shell，ivi-shell, kiosk shell, fullscreen shell等 4.5 head和output weston_head 和 weston_output 是libweston中的两个关键概念，用于管理显示输出和图像呈现。 weston_head（头部） weston_head 表示一个连接器或监视器。 在硬件驱动中，头部通常指的是一个显示器，但它也可以是另一个窗口系统中的窗口，或者是一个虚拟概念。 头部是一个可以呈现图像的位置。 weston_head 负责以下任务： 管理帧缓冲区。 跟踪损坏区域。 处理显示时序。 管理重绘状态机。 在显示硬件中，weston_head 表示一个CRTC（显示控制器），但仅在成功启用后才会如此。在头部的生命周期内，CRTC 可能会切换到另一个。 weston_head 的生命周期由libweston用户控制。 您可以通过将至少一个weston_head 附加到weston_output 来构建一个可供合成器使用的weston_output 对象，然后使用 weston_output_enable() 启用该输出。已启用的输出无法重新配置，但这在未来可能会发生变化。您可以使用 weston_output_disable() 来禁用一个输出，然后重新配置它，但这会导致可见的故障。 weston_output（输出） weston_output 决定了全局合成器坐标空间的哪一部分将被合成成图像以及何时进行合成。 该图像在附加的头部上呈现。 weston_output 负责以下任务： 帧缓冲区管理。 损坏区域跟踪。 显示时序。 重绘状态机。 视频模式、输出比例和输出变换是输出的属性。 在显示硬件中，weston_output 表示一个CRTC，但仅在成功启用后才会如此。CRTC 可能会在输出的生命周期内切换到另一个。 weston_output 的生命周期由libweston用户控制。 下面是各种case的流程图 Heads are being created on compositor start-up with a backend that manages head lifetimes completely on its own A compositor handles libweston notification of something with heads having changed. This happens on both compositor start-up and later due to hotplug A compositor creates and configures an output for a head or heads it wants to light up. A compositor finds out a head has been disconnected and proceeds to destroy the corresponding output. The backend realises that a piece of hardware has disappeared and needs to destroy the corresponding head. The head is released, and even when the compositor is not listening for head destroy signal, the output gets automatically disabled, though not destroyed. 4.6 layer, view, surface 4.7 create_surface 4.8 get_shell_surface 4.9 create_pool 4.10 surface_attach surface_damage 4.11 surface_commit 4.12 share buffer 4.12.1 create_shm_buffer 4.12.2 import dmabuf Client 基本流程如下： 绑定 linux_dmabuf wl_registry_bind(zwp_linux_dmabuf_v1_interface ) 创建一个param对象 zwp_linux_dmabuf_v1_create_params( zwp_linux_dmabuf_v1) 在param中设置dmbuf的各种信息(fd，width， height), YUV时，通过数组导入多个plane信息 zwp_linux_buffer_params_v1_add(dmabuf_fd) 对param对象添加listener zwp_linux_buffer_params_v1_add_listener() 依据param在Server侧导入dmabuf对象 zwp_linux_buffer_params_v1_create( ) 通过callback接收导入结果 params_listener callback create_succeeded() 4.13 weston event loop 4.14 weston idle 处理 4.15 gl-renderer weston中的几个renderer 4.16 libinput source code：https://gitlab.freedesktop.org/libinput/libinput 为了提高输入管理部分的模块性，Weston将对输入设备(键盘，鼠标，触摸屏等)的处理分离到一个单独的库，也就是libinput 中。具体地，它提供了设备检测，设备处理，输入事件处理等基本功能，类似于Android 中的EventHub。此外它还有pointer acceleration, touchpad support 及gesture recognition等功能。 libinput更像是一个框架，它将几个更底层的库的功能整合起来。它主要依赖于以下几个库: mtdev: Multi-touch 设备处理，比如它会将不带tracking ID的protocol A转化为 protocol B。 libevdev: 与kernel中evdev 模块对接。 libudev:主要用于和 udevd(userspace device)的通信，从而获取设备的增加删除事件。也可从kernel获取。 Weston 中的输入管理模块与libinput对接，它实现了两大部分的功能: 对输入设备的维护， 对输入事件的处理。 对于输入事件既会在Weston中做处理，也会传给相应的 client。 从事件处理模型上来看，libinput主循环监听udev monitor fd，它主要用于监听设备的添加删除事件。如果有设备添加，会打开该设备并把fd加入到libinput的主循环上。另一方面，Weston中会将 libinput 的 epoll fd加入主循环。这样形成级联的epoll，无论是 udev monitor 还是input device的fd有事件来，都会通知到Weston和libinput的主循环。 Weston中支持三种输入设备，分别是键盘，触摸和鼠标。一套输入设备属于一个seat(严格来说，seat中包括一套输入输出设备)。因此，weston_seat 中包含weston_keyboard,weston_pointer 和weston_touch三个结构。系统中可以有多个seat,它们的结构被串在weston_compositor 的 seat_list链表中。 可以看到，对于焦点处理，每个设备有自己的focus,它指向焦点窗口，用于拖拽和输入等。成员focus_resource_list 中包含了焦点窗口所在client中输入设备 proxy对应的 resource 对象。在这个 list 中意味着可以接收到相应的事件。 对于焦点处理，每个设备有自己的 focus，它指向焦点窗口，用于拖拽和输入等。成员focus_resource_list 中包含了焦点窗口所在 client 中输入设备 proxy 对应的 resource 对象。在这个list中的resource就可以接收到相应的事件。 相关函数weston_keyboard_send_key(), 参考 4.18.10 key的处理 4.16.1 udevd udev 是 Linux 系统中的一个重要组件，用于动态设备管理。详细介绍一下： udev 的全称是 “userspace device”，它是一个用户空间的设备管理工具。 功能： 接收来自内核的设备事件（uevents），例如设备的添加、移除或状态变化。 根据配置的一组规则，对设备进行识别和处理。 管理设备节点的权限和属性。 创建符号链接以提供有意义的设备名称。 工作流程： 内核发出设备事件（uevent）。 udev 守护进程（通常是 systemd-udevd.service）接收事件。 udev 根据配置的规则匹配设备属性，识别设备。 匹配的规则可能会创建符号链接、修改设备节点的权限或运行指定的程序。 规则文件： udev 规则存储在不同目录下的文件中，例如 /usr/lib/udev/rules.d、/run/udev/rules.d 和 /etc/udev/rules.d。 规则文件以 .rules 扩展名结尾。 每行包含至少一个键值对，用于匹配和赋值。 规则按照词法顺序处理，可以覆盖系统提供的规则。 库支持： udev 处理的所有设备信息存储在 udev 数据库中，并通过 libudev 库提供对存储数据和事件源的访问。 总之，udev 是一个关键的 Linux 设备管理工具，负责设备事件的处理、设备识别、权限管理和符号链接的创建 4.16.2 grab key 特殊情况下，shell对key的grab 4.17 Client创建窗口 4.17.1 创建shm窗口 4.17.2 创建egl窗口 4.18 调用的backtrace 4.18.1 Client eglSwapBuffers Client App 调用eglSwapBuffers 提交buffer给compositor的堆栈 4.18.2 wl_output global的创建 4.18.3 wl_surface_commit wl_surface_commit() 触发的后继操作 4.18.4 drm_output_repaint() drm_output_repaint() 的调用栈 4.18.5 repaint_views repaint_views() 的调用栈 4.18.6 第一次repaint的触发 4.18.7 送显的backtrace 4.18.8 weston-desktop-shell 4.18.9 Weston_keyboard 进程的创建 在weston.ini中的【input-method】设置 path= 空 来不创建它, 函数launch_input_method() 会检查path. 4.18.10 key的处理 4.19 weston misc 4.19.1 定时器函数 创建定时器：wl_event_loop_add_timer() Enable 定时器：wl_event_source_timer_update( source, ms_delay) // ms_delay ==0 disable 4.19.2 wayland signal wl_signal_add( , ) 添加一个listener到 listerner_list 链表 wl_signal_emit( , ) 触发一个signal, 从listener_list中调用每个listener notify listerner_list 其实就是一个callback链表 struct wl_listener { struct wl_list link; wl_notify_func_t notify; }; 4 12.3 libwayland-egl.so.xxx 由 wayland-1.20.0/egl下文件编译生成 主要功能生成/销毁wl_egl_window， 并获取它的大小属性 使用: client/backend-wayland 可以利用它来生成wl_egl_window, 然后传给eglCreateWindowSurface( ) 示例：./clients/simple-egl.c 好像不需要再分配buffer attch到 wl_surface, 参考simple-egl-window.c 4.19.4 weston_client_start() 在weston里定义， Weston call 它来 发起一个client 进程, 它会调用weston_client_launch() 4.19.5 weston-screenshooter 截屏进程， 被desktop-shell 进程call screenshooter_create( )创建 4.19.6 显示一帧的过程 epoll收到event 构建compositor View_list， 含有order信息 backend call gl_renderer set current surface 依次根据各个view的信息构建纹理，进行渲染 eglswapbuffer（） 遍历各个output，完成1～4 repaint_flash() -&gt; drm 上屏 4.19.7 repaint_timer_triger 4.19.8 Compositor sleep 相关 In weston.init, 相关配置 idle-time， 单位sec 在函数weston_compositor_wake()设置 多长时间无操作进入sleep状态 定时器compositor-&gt;idle_source， 在weston_compositor_create()中创建 在weston_compositor_offscreen() , weston_compositor_sleep() 中关闭定时器 4.19.9 surface与buffer Surface： Surface 是 DRM 中的一个概念，用于描述一个可绘制的区域。它是一个抽象的图形表面，可以用于绘制图像、文本或其他内容。 Surface 可以是屏幕上的一部分，也可以是一个窗口、一个图像或其他可视元素。 应用程序可以将图形绘制到 Surface 上，然后由 DRM 管理其显示。 例如，在 DRM 中，一个窗口可以有多个关联的 Surface，每个 Surface 对应一个缓冲区。 Buffer： Buffer 是一块内存区域，用于存储像素数据。在 DRM 中，它通常与 Surface 关联。 Buffer 可以是帧缓冲区、纹理、渲染缓冲区等。 Buffer 存储着图像的像素值，可以直接访问和操作。 例如，当应用程序绘制图像时，它将像素数据写入 Buffer，然后由 DRM 将其显示在屏幕上。 总结： Surface 是一个抽象的图形表面，用于绘制图像。 Buffer 是实际存储像素数据的内存区域，与 Surface 关联。 4.19.10 drm_virtual_output drm_backend_init_virtual_output_api () &lt;- #ifdef BUILD_DRM_VIRTUAL &lt;- /libweston/backend-drm/meson.build &lt;- remoting or pipewire in configure drm_virtual_output 用于 remoting or pipewire 场景， 在meson_options.txt 里配置 4.19.11 explicit-synchronization 绑定显示同步对象 wl_registry_bind(zwp_linux_explicit_synchronization_v1_interface) 针对surface创建sync对象 zwp_linux_explicit_synchronization_v1_get_synchronization(expliciti_sync, surface) Client 进行Opengl渲染，并通过sync 创建一个fence_fd eglCreateSyncKHR() --&gt; sync eglDupNativeFenceFDANDROID(sync) --&gt; fence_fd eglDestroySyncKHR(sync) 为surface_sync对象设置fence_fd， compositor将会等待它的完成 zwp_linux_surface_synchronization_v1_set_acquire_fence(fence_fd) 创建release对象，用于监听server callback zwp_linux_surface_synchronization_v1_get_release(surface_sync) 提交surface，compositor开始合成并通过callback 返回要client等待的fence_fd wl_surface_attach() wl_surface_commit() Client 等待上面callback 返回的fence_fd eglCreateSyncKHR(..fence_fd..) –&gt; sync eglWaitSyncKHR(..sync..) 4.20 shell weston提供有四种shell， desktop、 IVI、kiosk 和fullscreen-shell ./kiosk-shell/util.c ./kiosk-shell/kiosk-shell.c ./kiosk-shell/kiosk-shell-grab.c ./ivi-shell/hmi-controller.c ./ivi-shell/ivi-shell.c ./ivi-shell/ivi-layout-transition.c ./ivi-shell/ivi-layout.c ./fullscreen-shell/fullscreen-shell.c ./desktop-shell/input-panel.c ./desktop-shell/exposay.c ./desktop-shell/shell.c 4.20.1 kiosk-shell 在 Weston 中，kiosk-shell 是一种简单的窗口管理器（shell），专为单应用程序或单应用程序模式（kiosk 模式）设计。让我详细介绍一下： kiosk-shell 的功能： kiosk-shell 使所有顶层应用程序窗口全屏显示。 它支持定义将哪些应用程序放置在特定输出上。 这通过在 weston.ini 中相应输出部分的 app-ids= 字段中实现。 使用示例： 在 weston.ini 中，您可以指定哪些应用程序应该在特定输出上运行。 例如： [output] name=screen0 app-ids=org.domain.app1,com.domain.app2 要使用 kiosk-shell 运行 Weston，请在 weston.ini 中设置 shell=kiosk-shell.so，或使用命令行选项 –shell=kiosk-shell.so。 适用场景： kiosk-shell 适用于嵌入式设备、数字标牌、自助服务终端、展示台等场景，其中只有一个应用程序需要全屏显示。 4.20.2 ivi-shell IVI : In-Vehicle Information 在 Weston 项目中，IVI-shell 是一个高度可定制的外壳（shell），专注于那些需要对外壳窗口布局进行自定义控制的用例，而无需用户进行交互式布局配置。IVI-shell的示例用例包括汽车信息娱乐系统（IVI）应用程序或工业人机界面。通常情况下，当用户界面需要在一个或多个屏幕上精确定位多个应用程序表面时，IVI-shell 是一个理想的选择。 以下是关于 IVI-shell的一些重要信息： IVI-shell客户端协议： Wayland 客户端可以实现 ivi_application Wayland 协议，通过该协议，它们可以指定一个 ivi_id，以便 IVI控制器可以识别应用程序。这使得控制器可以为众所周知的应用程序实现特殊行为。此外，IVI-shell也可以处理使用xdg-shell协议的客户端，但在这些情况下，IVI-shell需要其他方式来识别客户端应用程序。 IVI-shell的组成部分： ivi-shell.so：负责处理应用程序ID，并提供抽象来通过ivi_layout_interface配置窗口布局。这个接口在IVI-shell组合器实现中讨论。 自定义 IVI 控制器：使用 ivi_layout_interface 来实现窗口管理器，负责配置窗口布局，即应用程序在屏幕上的位置。由于这种分离，必须在您的weston.ini中加载这两个模块才能使用IVI-shell。 IVI-shell的控制： IVI-shell提供了 ivi_layout_interface API，控制器必须使用它来控制IVI-shell的窗口布局。有关此 API 的定义，请参阅 ivi-shell/ivi-layout-export.h。 对于初始配置，控制器必须至少创建一个 ivi_layout_layer 并将其添加到一个 weston_output。图层允许将多个应用程序表面分组并一起控制，是组织和管理表面的主要机制。 控制器还必须使用触发器来获取对客户端表面的控制权。客户端表面显示为 ivi_layout_surface。这些表面具有 ID，允许控制器识别表面并相应地重新配置窗口布局。 总之，IVI-shell是一个强大的工具，用于在汽车信息娱乐系统、工业界面等场景中精确控制应用程序的窗口布局。 4.20.3 fullscreen-shell 下图是fullscreen-shell的初始化，以及surface commit时的处理。 可参考 [4.11 surface_commit] 4.21 wcap 在 Weston项目中，wcap 目录是用于处理 Weston 的屏幕录制功能的。具体来说，wcap 是一种特定于 Weston的无损视频格式，它仅记录帧之间的差异。这意味着它只捕获屏幕上发生变化的部分，而不是完整的每一帧。这对于屏幕录制非常有用，因为它可以减少文件大小并提高效率。 如果您在 Weston 中进行屏幕录制，生成的录制文件将以 .wcap 格式保存在当前工作目录中。要播放这些录制文件，您需要将 .wcap文件转换为其他媒体播放器可以理解的格式。例如，您可以使用 wcap-decode工具将 .wcap 文件转换为单独的PNG图像文件，以便查看每一帧的屏幕内容。 请注意，这里提到的 wcap 是一种专门用于 Weston 的格式，不同于其他常见的视频格式，如 MP4 或 AVI。 ./wcap/main.c ./wcap/wcap-decode.c"
  },"/blog/graphic/2001-02-01-DRM.html": {
    "title": "DRM子系统",
    "keywords": "graphic",
    "url": "/blog/graphic/2001-02-01-DRM.html",
    "body": "1.DRM总述 1.1在整个系统中的位置 App角度 DRM内部 wayland实例 2.图形buffer相关 2.1 dumb buffer 旧时的显卡由一块很小的显存（通常为640x480）加一块数模转换电路（DAC）组成，说白了就是一块 Framebuffer + Display Controller。显卡的功能极其简单，只负责将显存中的图像数据转换成RGB信号发送出去即可，而所有的绘图操作则都交给 CPU 来完成。行业里将这种显卡称为 VGA(Video Graphics Array) Card，它的显存则被称为“Dumb Frame Buffer”。而到了后期，随着显卡技术的不断发展，许多原来由 CPU 干的活，渐渐的都被显卡取代了。从最初支持某些特定绘图指令（如画点、画线）的显卡，到后来支持视频解码的 Video Card，再到现代支持复杂3D渲染指令（如OpenGL）的 GPU 显卡，CPU 绘图的繁重任务彻底得到了解放。与 VGA Card 相比较，行业里将后来显卡的显存称为“Smart Frame Buffer”。 首先从这两种称谓上我们就可以看出，dumb 是 smart 的反义词，因此 dumb 在这里的解释应该是“傻的”或“傻瓜式的”，而不是“哑的”。 dumb buffer 和 smart buffer 的区别就在于，你写到显存里的数据，是可以直接上屏显示的图像内容，还是一堆需要GPU解析的命令和资源数据。 与 dumb buffer 命名类似的还有： dumb-terminal：不支持特殊字符的终端，如“清屏”、“粗体”、“彩色字符”等等 dumb-panel：不带 GRAM 的 panel dumb-TV：与 Smart-TV 相反，指以前老式的黑白电视 如今的 IT 领域，dumb一词更多的代表 “功能简单的”、“老式的”、“传统的” 含义 2.1.1超简单DUMB实现 与dumb buffer相关的userspace接口有四个, 下表列出了它们的名字, 作用和对应要实现的函数 interface Description drm driver ioctl(fd, DRM_IOCTL_MODE_CREATE_DUMB, …) 向驱动申请一个dumb buffer，返回一个handle，指向新分配的buffer .dumb_create() ioctl(fd, DRM_IOCTL_MODE_MAP_DUMB, …) 为buffer map做准备，传入handle，得到一个offset .dumb_map_offset() ioctl(fd, DRM_IOCTL_MODE_DESTROY_DUMB, …) 销毁该dumb buffer .dumb_destroy() mmap(fd, …) 传入 buffer对应的offset，映射到进程空间，返回一个用户空间可使用的地址。 .fops.mmap() 2.1.1.1 简单应用程序 下面是一个简单的应用程序，演示了dumb buffer的申请，mmap，使用和销毁。 #include &lt;fcntl.h&gt; #include &lt;stdio.h&gt; #include &lt;sys/mman.h&gt; #include &lt;unistd.h&gt; #include &lt;xf86drm.h&gt; #define log(fmt, args...) printf(\"%s():%d \" fmt \"\\n\", __func__, __LINE__, ##args) #define err(fmt, args...) printf(\"\\033[35m%s():%d \" fmt \"\\033[0m\\n\", __func__, __LINE__, ##args) static int create_dumb_buffer(int fd, int width, int height){ int ret = 0; struct drm_mode_create_dumb create = {}; create.width = width; create.height =height; create.bpp = 4*8; // byte per pixel ret = drmIoctl(fd, DRM_IOCTL_MODE_CREATE_DUMB, &amp;create); if(ret){ err(\"ret:%d\", ret); return 0; } return create.handle; } static int get_dumb_buffer_offset(int fd, int handle){ struct drm_mode_map_dumb map = {}; map.handle = handle; int ret = drmIoctl(fd, DRM_IOCTL_MODE_MAP_DUMB, &amp;map); if(ret){ err(\"ret:%d\", ret); return 0; } return map.offset; } static void* mmap_dumb_buffer(int fd, int size, int offset){ void *addr = NULL; addr = mmap(0, size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, offset); if(!addr){ err(\"mmap dumb buffer offset:0x%x failed\", offset); return NULL; } return addr; } static void destroy_dumb_buffer(int fd, int handle){ struct drm_mode_destroy_dumb destroy = {}; destroy.handle = handle; int ret = drmIoctl(fd, DRM_IOCTL_MODE_DESTROY_DUMB, &amp;destroy); if(ret){ err(\"DRM_IOCTL_MODE_DESTROY_DUMB failed. ret:%d\", ret); return; } } int main(int argc, char **argv){ int fd; int width = 1024; int height = 1; int size = width*height; fd = open(\"/dev/dri/card0\", O_RDWR | O_CLOEXEC); if(fd&lt;=0){ err(\"open dev failed.\"); return -1; } int handle = create_dumb_buffer(fd, width, height); log(\"create dumb buffer, get handle:%d\", handle); int offset = get_dumb_buffer_offset(fd, handle); log(\"get dumb buffer offset:0x%x\", offset); void *addr = mmap_dumb_buffer(fd, size, offset); log(\"get dumb buffer addr:%p\",addr); //在addr所指向的buffer上进行绘图 memset(addr, 0, width*height); munmap(addr, size); destroy_dumb_buffer(fd, handle); log(\"destroy dumb buffer\"); getchar(); close(fd); return 0; } 2.1.1.2 实现简单的驱动 基于kernel 5.15.126， 主要是.dumb_create(), .dumb_map_offset(), .dumb_destroy, fops.mmap()的实现 #include &lt;linux/module.h&gt; #include &lt;linux/platform_device.h&gt; #include &lt;drm/drm_drv.h&gt; #include &lt;drm/drm_file.h&gt; #include &lt;drm/drm_ioctl.h&gt; #define DRIVER_NAME \"drm dumb driver\" #define DRIVER_DESC \"Virtual drm dumb driver\" #define DRIVER_DATE \"20191114\" #define DRIVER_MAJOR 1 #define DRIVER_MINOR 0 #define MAX_NUM 10 #define log(fmt, args...) printk(\"%s():%d \" fmt \"\\n\", __func__, __LINE__, ##args) #define err(fmt, args...) printk(\"\\033[35m%s():%d \" fmt \"\\033[0m\\n\", __func__, __LINE__, ##args) struct dumb_device { struct drm_device drm; struct platform_device *platform_dev; }; static struct dumb_device* dumb_device = NULL; static struct page *pages[MAX_NUM] = {0}; static u32 buffer_size[MAX_NUM] = {0}; static int page_idx = 0; static int dumb_mmap_impl(struct file* filp, struct vm_area_struct* vma) { unsigned long pfn_start = 0; unsigned long size = vma-&gt;vm_end - vma-&gt;vm_start; int ret = 0; int idx = 0; /********************************************************************* * vm_pgoff: 也是vm_are_struct的一个字段 * 表示偏移量，它是以page size计数的。 pg表示page计数，off表示偏移 *********************************************************************/ idx = vma-&gt;vm_pgoff; pfn_start = page_to_pfn(pages[idx]); log(\"idx:%d phy: 0x%lx, vm_pgoff: 0x%lx, vma-&gt;vm_start:0x%lx, size: 0x%lx\", idx, pfn_start &lt;&lt; PAGE_SHIFT, vma-&gt;vm_pgoff, vma-&gt;vm_start, size); ret = remap_pfn_range(vma, vma-&gt;vm_start, pfn_start, size, vma-&gt;vm_page_prot); if (ret) err(\"remap_pfn_range failed at [0x%lx 0x%lx]\", vma-&gt;vm_start, vma-&gt;vm_end); else{ unsigned long virt_start = (unsigned long)page_address(pages[idx]); log(\"map 0x%lx to 0x%lx, size: 0x%lx\", virt_start, vma-&gt;vm_start, size); } return 0; } static const struct file_operations dumb_driver_fops = { .owner = THIS_MODULE, .open = drm_open, .release = drm_release, .unlocked_ioctl = drm_ioctl, .compat_ioctl = drm_compat_ioctl, .mmap = dumb_mmap_impl, }; static void dumb_release(struct drm_device* dev) { log(); } static int dumb_create_impl(struct drm_file *file_priv, struct drm_device *dev, struct drm_mode_create_dumb* args) { u32 size = 0; log(); if(page_idx&gt;=MAX_NUM){ err(\"only support alloc %d buffers\", MAX_NUM); return -ENOMEM; } size = roundup((args-&gt;width * args-&gt;height * args-&gt;bpp/8), PAGE_SIZE); // 分配页面 pages[page_idx] = alloc_pages(GFP_KERNEL, get_order(size)); if (!pages[page_idx]) { err(\"alloc_pages() failed\"); return -ENOMEM; } buffer_size[page_idx] = size; // 赋值返回参数 args-&gt;size = size; args-&gt;pitch = args-&gt;width * args-&gt;bpp/8; args-&gt;handle = page_idx++; return 0; } static int dumb_map_offset_impl(struct drm_file *file_priv, struct drm_device *dev, uint32_t handle, uint64_t* offset) { log(\"%d\", handle); //根据handle得到一个offset，为了简单，这里直接使用handle *offset = 0x1000*(u64)handle; return 0; } static int dumb_destroy_impl(struct drm_file *file_priv, struct drm_device *dev, uint32_t handle){ log(\"handle:%d\", handle); free_pages((unsigned long)page_address(pages[handle]), get_order(buffer_size[handle])); return 0; } static struct drm_driver dumb_driver = { .fops = &amp;dumb_driver_fops, .release = dumb_release, .dumb_create = dumb_create_impl, .dumb_map_offset = dumb_map_offset_impl, .dumb_destroy = dumb_destroy_impl, .name = DRIVER_NAME, .desc = DRIVER_DESC, .date = DRIVER_DATE, .major = DRIVER_MAJOR, .minor = DRIVER_MINOR, }; static int __init dumb_drv_init(void) { int ret; struct platform_device* pdev = NULL; log(\"build time: %s %s\", __DATE__, __TIME__); pdev = platform_device_register_simple(DRIVER_NAME, -1, NULL, 0); if (IS_ERR(pdev)) return PTR_ERR(pdev); if (!devres_open_group(&amp;pdev-&gt;dev, NULL, GFP_KERNEL)) { ret = -ENOMEM; goto out_unregister; } // 分配 dumb_device = devm_drm_dev_alloc(&amp;pdev-&gt;dev, &amp;dumb_driver, struct dumb_device, drm); if (IS_ERR(dumb_device)) { ret = PTR_ERR(dumb_device); goto out_devres; } // 注册 ret = drm_dev_register(&amp;dumb_device-&gt;drm, 0); if (ret) goto out_devres; dumb_device-&gt;platform_dev = pdev; log(\"Finish\"); return 0; out_devres: devres_release_group(&amp;pdev-&gt;dev, NULL); out_unregister: platform_device_unregister(pdev); return ret; } static void __exit dumb_drv_exit(void) { struct platform_device *pdev = dumb_device-&gt;platform_dev; log(); drm_dev_unregister(&amp;dumb_device-&gt;drm); devres_release_group(&amp;pdev-&gt;dev, NULL); platform_device_unregister(pdev); } module_init(dumb_drv_init); module_exit(dumb_drv_exit); MODULE_AUTHOR(\"kevin\"); MODULE_DESCRIPTION(DRIVER_DESC); MODULE_LICENSE(\"GPL\"); 2.1.1.3 它们是如何衔接起来的 2.1.2 基于GEM的实现 GEM是系统提供的一套实现框架或者帮助工具。在各自实现私有的drm driver时，总有一些内容是相同或相似的，GEM就对这些相同部分进行了总结，抽象，然后实现了它们，供开发者使用。具体实现在drm_gem.c 2.1.2.1 实现代码 下面是基于GEM对上面driver实现的改造。 它利用了GEM 提供的如下函数： interface 功能 drm_gem_object_init() 初始化一个gem对象 drm_gem_handle_create() 通过gem对象生成一个handle drm_gem_object_lookup() 根据handle 找到对应的gem对象 drm_gem_dumb_map_offset() 通过gem对象生成一个offset drm_gem_mmap() 对mmap()的支持，如果开发者使用它，就可利用gem mmap的实现部分 struct drm_gem_object_funcs 使用gem对象时可能调用到一组函数,此处实现了.mmap,对应drm_gem_mmap() #include &lt;linux/module.h&gt; #include &lt;linux/platform_device.h&gt; #include &lt;drm/drm_gem.h&gt; #include &lt;drm/drm_drv.h&gt; #include &lt;drm/drm_file.h&gt; #include &lt;drm/drm_ioctl.h&gt; #define DRIVER_NAME \"drm dumb gem driver\" #define DRIVER_DESC \"Virtual drm dumb driver\" #define DRIVER_DATE \"20191116\" #define DRIVER_MAJOR 1 #define DRIVER_MINOR 0 #define log(fmt, args...) printk(\"%s():%d \" fmt \"\\n\", __func__, __LINE__, ##args) #define err(fmt, args...) printk(\"\\033[35m%s():%d \" fmt \"\\033[0m\\n\", __func__, __LINE__, ##args) #define DRM_GEM_OBJECT_TO_DUMB_BUFFER_OBJ(target) \\ container_of(target, struct dumb_buffer_object, gem_obj) struct dumb_device { struct drm_device drm; struct platform_device *platform_dev; }; struct dumb_buffer_object{ struct drm_gem_object gem_obj; struct page *start_page; u32 size; }; static struct dumb_device* dumb_device = NULL; static int dumb_gem_mmap_impl(struct file* filp, struct vm_area_struct* vma) { log(\"call drm_gem_mmap()\"); // 利用GEM方法进行mapping， // 在它里面会调用之前设置好的drm_gem_object_funcs.mmap() return drm_gem_mmap(filp, vma); } static const struct file_operations dumb_driver_fops = { .owner = THIS_MODULE, .open = drm_open, .release = drm_release, .poll = drm_poll, .read = drm_read, .llseek = noop_llseek, .mmap = dumb_gem_mmap_impl, .unlocked_ioctl = drm_ioctl, .compat_ioctl = drm_compat_ioctl, }; static int dumb_gem_obj_mmap(struct drm_gem_object *gem_obj, struct vm_area_struct *vma){ int ret = 0; unsigned long pfn_start = 0; unsigned long size = vma-&gt;vm_end - vma-&gt;vm_start; struct dumb_buffer_object *dumb_buffer_obj = NULL; dumb_buffer_obj = DRM_GEM_OBJECT_TO_DUMB_BUFFER_OBJ(gem_obj); log(\"mmaping dumb_buffer_obj:%p\", dumb_buffer_obj); pfn_start = page_to_pfn(dumb_buffer_obj-&gt;start_page); ret = remap_pfn_range(vma, vma-&gt;vm_start, pfn_start, size, vma-&gt;vm_page_prot); if (ret){ err(\"remap_pfn_range failed at [0x%lx 0x%lx]\", vma-&gt;vm_start, vma-&gt;vm_end); } return 0; } static const struct drm_gem_object_funcs dumb_gem_obj_funcs = { .open = NULL, .mmap = dumb_gem_obj_mmap, //.vm_ops = &amp;dumb_gem_vm_ops, // 赋值到struct vm_area_struct 的vm_ops, 供缺页时调用。 }; static void dumb_release(struct drm_device* dev) { log(); } static int dumb_create_gem_impl(struct drm_file* file_priv, struct drm_device* dev, struct drm_mode_create_dumb* args) { u32 size = 0; int ret = 0; struct dumb_buffer_object *dumb_buffer_obj; struct drm_gem_object *gem_obj; log(); size = ALIGN((args-&gt;width * args-&gt;height * args-&gt;bpp/8), PAGE_SIZE); //1. 分配buffer_obj // 可以在此处分配page,也可以在fault时再分配 dumb_buffer_obj = kzalloc(sizeof(*dumb_buffer_obj), GFP_KERNEL); size = roundup(size, PAGE_SIZE); log(\"page_size:%d\",size); // 2. 初始化dumb_buffer_obj内的drm_gem_object gem_obj = &amp;(dumb_buffer_obj-&gt;gem_obj); gem_obj-&gt;funcs = &amp;dumb_gem_obj_funcs; /* 设置该gem object的操作函数 */ drm_gem_object_init(dev, gem_obj, size); // 3. 利用GEM方法生成一个gem_obj对应的handle ret = drm_gem_handle_create(file_priv, gem_obj, &amp;args-&gt;handle); if(ret){ log(); } dumb_buffer_obj-&gt;start_page = alloc_pages(GFP_KERNEL, get_order(size)); if (!dumb_buffer_obj-&gt;start_page) { err(\"alloc_pages() failed\"); return -ENOMEM; } dumb_buffer_obj-&gt;size = size; // 4. 赋值返回参数 args-&gt;size = size; args-&gt;pitch = args-&gt;width*args-&gt;bpp/8; //TODO: 应计算得到 log(\"create dumb_buffer_obj:%p success, return handle:%d\", dumb_buffer_obj, args-&gt;handle); return 0; } static int dumb_map_offset_gem_impl(struct drm_file* file_priv, struct drm_device* dev, uint32_t handle, uint64_t* offset) { int ret; log(\"handle:%d\", handle); // 利用GEM方法得到一个offset ret =drm_gem_dumb_map_offset(file_priv, dev, handle, offset); if(ret){ err(\"drm_gem_dumb_map_offset failed. ret:%d\", ret); }else{ log(\"get offset:0x%llx from drm_gem_dumb_map_offset()\", *offset); } return ret; } static int dumb_release_gem_impl(struct drm_file *file_priv, struct drm_device *dev, u32 handle){ struct drm_gem_object *gem_obj; struct dumb_buffer_object *dumb_buffer_obj = NULL; log(\"\"); gem_obj = drm_gem_object_lookup(file_priv, handle); dumb_buffer_obj = DRM_GEM_OBJECT_TO_DUMB_BUFFER_OBJ(gem_obj); log(\"free page:%p\",dumb_buffer_obj-&gt;start_page); free_pages((unsigned long)page_address(dumb_buffer_obj-&gt;start_page), get_order(dumb_buffer_obj-&gt;size)); kfree(dumb_buffer_obj); return 0; } static struct drm_driver dumb_driver = { .driver_features = DRIVER_GEM, .fops = &amp;dumb_driver_fops, .release = dumb_release, .dumb_create = dumb_create_gem_impl, .dumb_map_offset = dumb_map_offset_gem_impl, .dumb_destroy = dumb_release_gem_impl, .name = DRIVER_NAME, .desc = DRIVER_DESC, .date = DRIVER_DATE, .major = DRIVER_MAJOR, .minor = DRIVER_MINOR, }; static int __init dumb_drv_init(void) { int ret; struct platform_device* pdev = NULL; log(\"build time: %s %s\", __DATE__, __TIME__); pdev = platform_device_register_simple(DRIVER_NAME, -1, NULL, 0); if (IS_ERR(pdev)) return PTR_ERR(pdev); if (!devres_open_group(&amp;pdev-&gt;dev, NULL, GFP_KERNEL)) { ret = -ENOMEM; goto out_unregister; } dumb_device = devm_drm_dev_alloc(&amp;pdev-&gt;dev, &amp;dumb_driver, struct dumb_device, drm); if (IS_ERR(dumb_device)) { ret = PTR_ERR(dumb_device); goto out_devres; } ret = drm_dev_register(&amp;dumb_device-&gt;drm, 0); if (ret) goto out_devres; dumb_device-&gt;platform_dev = pdev; log(\"Finish\"); return 0; out_devres: devres_release_group(&amp;pdev-&gt;dev, NULL); out_unregister: platform_device_unregister(pdev); return ret; } static void __exit dumb_drv_exit(void) { struct platform_device *pdev = dumb_device-&gt;platform_dev; log(); drm_dev_unregister(&amp;dumb_device-&gt;drm); devres_release_group(&amp;pdev-&gt;dev, NULL); platform_device_unregister(pdev); } module_init(dumb_drv_init); module_exit(dumb_drv_exit); MODULE_AUTHOR(\"kevin\"); MODULE_DESCRIPTION(DRIVER_DESC); MODULE_LICENSE(\"GPL\"); 2.1.2.2 流程图 2.2 PRIME PRIME 在 DRM 驱动中其实是一种buffer共享机制，它是基于 dma-buf 来实现的. 2010年2月9日，NVIDIA 官方发布了一项新的双显卡技术 —— Optimus Technology。该技术主要运用于带双显卡的笔记本（集成显卡+独立显卡），可以根据当前集成显卡的工作负载，自动的将一部分图形任务交给独立显卡去处理，以此来达到功耗和性能的最佳平衡。举例来说，一个带 Intel 集成显卡和 NVIDIA 独立显卡的笔记本，通常将集成显卡做为默认显卡，且充当了 Display Controller 的角色。当用户使用办公软件时，由于需要渲染的任务量不多，此时直接由 Intel 集成显卡来完成。而当用户玩3D游戏时，由于图形渲染的负载较重，此时系统会将部分或全部的任务交给 NVIDIA 独立显卡去处理，等处理完后再将结果送回给集成显卡做最后的合成显示。而这整个过程都是由软硬件自动完成的，中间无需人为干预，用户体验十分流畅。只可惜，该技术只能用在 Windows 系统上，Linux 系统不支持。 当时的 Linux 开源社区，Dave Airlie （RedHat Graphics 工程师，DRM 社区 maintainer）在业余时间里研究起 Optimus 技术，并琢磨着怎样在 Linux 平台上实现类似的功能。结果不到2周时间，他就做出了该方案的原型设计，并在自己的笔记本上（Intel集成显卡+ATI独立显卡）实现了该功能的验证。 他将这项技术命名为“PRIME”。 命名为PRIME 主要是映射Optimus Optimus Prime 就是变形金刚 擎天柱的名字！ NVIDIA 当初给他们 Optimus 技术命名的精妙之处：擎天柱本身所具有的变形能力，形象的表达了 Optimus 这项技术可以在功耗和性能之间来回自由变换。 Dave 将他这项 Linux 下的技术命名为 “PRIME”，其实是很巧妙的玩了一把文字游戏，隐晦的告诉大家：DRM Prime 技术就是用来对标 NVIDIA Optimus 技术的。 2.2.1 PRIME的基本实现 为了实现设备间的buffer共享，需要有一套机制来导出、导入buffer。提供buffer的驱动负责导出buffer，使用buffer的设备导入buffer。 DMA_BUF已经提供了这样一套机制。 在DRM的实现中就使用了这套机制，具体是通过借助dmabuf fd来完成的。 导出buffer的驱动对外提供一个fd，来代表一个buffer， 而要使用这个buffer的其他设备驱动就通过这个fd导入buffer，从而访问该buffer。 在DRM中我们需要实现一定的DMA_BUF接口来支持buffer的导出、导入。 下图是一个在不同设备驱动之间导入、导出dma_buf的简单示意图 2.2.1.1 export驱动实现 在驱动的实现中主要添加 .prime_handle_to_fd 和 .prime_fd_to_handle_impl的实现。 interface 实现功能 prime_handle_to_fd 需要实现buffer handle 到dmabuf fd的转换 prime_fd_to_handle_impl 需要实现dmabuf fd 到buffer handle的转换 下面是支持buffer导出的简单实现. 在前面code的基础上添加了对dma-buf export的支持,主要是对struct dma_buf_ops的实现。 结构dma_buf_ops struct dma_buf_ops结构如下： #include &lt;linux/module.h&gt; #include &lt;linux/platform_device.h&gt; #include &lt;linux/slab.h&gt; #include &lt;linux/dma-buf.h&gt; #include &lt;drm/drm_drv.h&gt; #include &lt;drm/drm_file.h&gt; #include &lt;drm/drm_ioctl.h&gt; #define DRIVER_NAME \"drm prime driver\" #define DRIVER_DESC \"test drm prime driver\" #define DRIVER_DATE \"20191124\" #define DRIVER_MAJOR 1 #define DRIVER_MINOR 0 #define log(fmt, args...) printk(\"%s():%d \" fmt \"\\n\", __func__, __LINE__, ##args) #define err(fmt, args...) printk(\"\\033[35m%s():%d \" fmt \"\\033[0m\\n\", __func__, __LINE__, ##args) struct dumb_device { struct drm_device drm; struct platform_device* platform_dev; }; #define MAX_NUM 10 static struct dumb_device* dumb_device = NULL; static struct page* pages[MAX_NUM] = {0}; static u32 buffer_size[MAX_NUM] = {0}; static int page_idx = 0; static int prime_dmabuf_attach_impl(struct dma_buf* dmabuf, struct dma_buf_attachment* attachment) { log(\"attach dmabuf to device, return attachment\"); return 0; } static void prime_dmabuf_detach_impl(struct dma_buf* dmabuf, struct dma_buf_attachment* attachment) { log(\"detach dmabuf\"); } static struct sg_table* prime_dmabuf_map_impl(struct dma_buf_attachment* attachment, enum dma_data_direction dir) { struct page* page = attachment-&gt;dmabuf-&gt;priv; struct sg_table* table; int err; log(\"page:%p\", page); table = kmalloc(sizeof(*table), GFP_KERNEL); if (!table) { log(); return ERR_PTR(-ENOMEM); } // 生成散列表并赋值 err = sg_alloc_table(table, 1, GFP_KERNEL); if (err) { log(); kfree(table); return ERR_PTR(err); } sg_set_page(table-&gt;sgl, page, PAGE_SIZE, 0); sg_dma_address(table-&gt;sgl) = dma_map_page(&amp;(dumb_device-&gt;platform_dev-&gt;dev), page, 0, PAGE_SIZE, dir); log(\"map attachment into sg_table and return sg_table\"); return table; } static void prime_dmabuf_unmap_impl(struct dma_buf_attachment* attachment, struct sg_table* table, enum dma_data_direction dir) { log(); dma_unmap_page(attachment-&gt;dev, sg_dma_address(table-&gt;sgl), PAGE_SIZE, dir); sg_free_table(table); kfree(table); } static void prime_dmabuf_release_impl(struct dma_buf* dma_buf) { struct page* page = dma_buf-&gt;priv; log(\"put_page:%p\", page); put_page(page); } static int prime_dmabuf_vmap_impl(struct dma_buf* dma_buf, struct dma_buf_map* map) { void* vaddr = NULL; struct page* page = dma_buf-&gt;priv; vaddr = vmap(&amp;page, 1, 0, PAGE_KERNEL); dma_buf_map_set_vaddr(map, vaddr); log(\"mapping page:%p, get virtual addr:%p\", page, vaddr); return 0; } static void prime_dmabuf_vunmap_impl(struct dma_buf* dma_buf, struct dma_buf_map* map) { log(\"unmapping addr:%p\", map-&gt;vaddr); vunmap(map-&gt;vaddr); } static int prime_dmabuf_mmap_impl(struct dma_buf* dma_buf, struct vm_area_struct* vma) { struct page* page = dma_buf-&gt;priv; log(); return remap_pfn_range(vma, vma-&gt;vm_start, page_to_pfn(page), PAGE_SIZE, vma-&gt;vm_page_prot); } static const struct dma_buf_ops exp_dmabuf_ops = { .attach = prime_dmabuf_attach_impl, .detach = prime_dmabuf_detach_impl, .map_dma_buf = prime_dmabuf_map_impl, .unmap_dma_buf = prime_dmabuf_unmap_impl, .release = prime_dmabuf_release_impl, .mmap = prime_dmabuf_mmap_impl, .vmap = prime_dmabuf_vmap_impl, .vunmap = prime_dmabuf_vunmap_impl, }; static int prime_handle_to_fd_impl(struct drm_device* dev, struct drm_file* file_priv, uint32_t handle, uint32_t flags, int* prime_fd) { DEFINE_DMA_BUF_EXPORT_INFO(exp_info); struct dma_buf* dmabuf; log(\"dma_buf -&gt; page:%p\", pages[handle]); exp_info.ops = &amp;exp_dmabuf_ops; exp_info.size = buffer_size[handle]; exp_info.flags= O_CLOEXEC; exp_info.priv = pages[handle]; // buffer和dmabuf建立关联 // 构建一个dma_buf dmabuf = dma_buf_export(&amp;exp_info); if (IS_ERR(dmabuf)) { log(); return -1; } // 为该dma_buf生成fd *prime_fd = dma_buf_fd(dmabuf, O_CLOEXEC); if (prime_fd &lt;= 0) { log(); return -1; } return 0; } static int prime_fd_to_handle_impl(struct drm_device* dev, struct drm_file* file_priv, int prime_fd, uint32_t* handle) { struct dma_buf* dma_buf; struct page* page = NULL; int idx = 0; log(); dma_buf = dma_buf_get(prime_fd); page = dma_buf-&gt;priv; if (dma_buf-&gt;ops == &amp;exp_dmabuf_ops) { for (idx = 0; idx &lt; MAX_NUM; idx++) { if (pages[idx] == page) { break; } } *handle = idx; log(\"return handle:%d\", *handle); } else { log(\"doesn't support\"); return -1; } dma_buf_put(dma_buf); return 0; } static const struct file_operations dumb_driver_fops = { .owner = THIS_MODULE, .open = drm_open, .release = drm_release, .unlocked_ioctl = drm_ioctl, .compat_ioctl = drm_compat_ioctl, }; static void dumb_release(struct drm_device* dev) { log(); } static int dumb_create_impl(struct drm_file *file_priv, struct drm_device *dev, struct drm_mode_create_dumb* args) { u32 size = 0; log(); if(page_idx&gt;=MAX_NUM){ err(\"only support alloc %d buffers\", MAX_NUM); return -ENOMEM; } size = roundup((args-&gt;width * args-&gt;height * args-&gt;bpp/8), PAGE_SIZE); // 分配页面 pages[page_idx] = alloc_pages(GFP_KERNEL, get_order(size)); if (!pages[page_idx]) { err(\"alloc_pages() failed\"); return -ENOMEM; } buffer_size[page_idx] = size; // 赋值返回参数 args-&gt;size = size; args-&gt;pitch = args-&gt;width * args-&gt;bpp/8; args-&gt;handle = page_idx++; return 0; } static int dumb_destroy_impl(struct drm_file *file_priv, struct drm_device *dev, uint32_t handle){ log(\"handle:%d\", handle); //__free_pages(pages[handle], get_order(dumb_buffer_size[handle])); free_pages((unsigned long)page_address(pages[handle]), get_order(buffer_size[handle])); return 0; } static struct drm_driver dumb_driver = { .release = dumb_release, .fops = &amp;dumb_driver_fops, .dumb_create = dumb_create_impl, .dumb_destroy = dumb_destroy_impl, .prime_handle_to_fd = prime_handle_to_fd_impl, .prime_fd_to_handle = prime_fd_to_handle_impl, //其他驱动分配的dma_buf导入到DRM系统 .name = DRIVER_NAME, .desc = DRIVER_DESC, .date = DRIVER_DATE, .major = DRIVER_MAJOR, .minor = DRIVER_MINOR, }; static int __init dumb_drv_init(void) { int ret; struct platform_device* pdev = NULL; log(\"build time: %s %s\", __DATE__, __TIME__); pdev = platform_device_register_simple(DRIVER_NAME, -1, NULL, 0); if (IS_ERR(pdev)) return PTR_ERR(pdev); if (!devres_open_group(&amp;pdev-&gt;dev, NULL, GFP_KERNEL)) { ret = -ENOMEM; goto out_unregister; } // 分配 dumb_device = devm_drm_dev_alloc(&amp;pdev-&gt;dev, &amp;dumb_driver, struct dumb_device, drm); if (IS_ERR(dumb_device)) { ret = PTR_ERR(dumb_device); goto out_devres; } // 注册 ret = drm_dev_register(&amp;dumb_device-&gt;drm, 0); if (ret) goto out_devres; dumb_device-&gt;platform_dev = pdev; log(\"Finish\"); return 0; out_devres: devres_release_group(&amp;pdev-&gt;dev, NULL); out_unregister: platform_device_unregister(pdev); return ret; } static void __exit dumb_drv_exit(void) { struct platform_device *pdev = dumb_device-&gt;platform_dev; log(); drm_dev_unregister(&amp;dumb_device-&gt;drm); devres_release_group(&amp;pdev-&gt;dev, NULL); platform_device_unregister(pdev); } module_init(dumb_drv_init); module_exit(dumb_drv_exit); MODULE_AUTHOR(\"kevin\"); MODULE_DESCRIPTION(DRIVER_DESC); MODULE_LICENSE(\"GPL\"); 2.2.1.1 import驱动实现 import dmabuf 的驱动部分实现较为简单，主要是对下列函数的调用,这些函数正好和上面struct dma_buf_ops的实现相对应。 function 功能 dma_buf_get 由fd得到对应的struct dma_buf dma_buf_attach attach dmabuf 到一个设备，得到一个 dma_buf_attachment dma_buf_map_attachment 把一个dmabuf映射到一个设备的地址空间 dma_buf_unmap_attachment 取消dmabuf在设备地址空间的映射 dma_buf_detach 取消与设备的关联 #include &lt;linux/dma-buf.h&gt; #include &lt;linux/module.h&gt; #include &lt;linux/miscdevice.h&gt; #include &lt;linux/slab.h&gt; #define log(fmt, args...) printk(\"%s():%d \" fmt \"\\n\", __func__, __LINE__, ##args) static int test_dma_buf(struct dma_buf* dma_buf) { struct dma_buf_attachment* attachment; struct sg_table* table; struct device* dev; unsigned int reg_addr, reg_size; struct scatterlist* sg; struct page* page; int i = 0; if (!dma_buf) { log(); return -EINVAL; } dev = kzalloc(sizeof(*dev), GFP_KERNEL); if (!dev) { log(); return -ENOMEM; } dev_set_name(dev, \"importer\"); attachment = dma_buf_attach(dma_buf, dev); if (IS_ERR(attachment)) { pr_err(\"dma_buf_attach() failed\\n\"); return PTR_ERR(attachment); } log(\"call dma_buf_map_attachment to get sg_table\"); table = dma_buf_map_attachment(attachment, DMA_BIDIRECTIONAL); if (IS_ERR(table)) { pr_err(\"dma_buf_map_attachment() failed\\n\"); dma_buf_detach(dma_buf, attachment); return PTR_ERR(table); } log(\"table-&gt;nents:%d\", table-&gt;nents); sg = table-&gt;sgl; for (i = 0; i &lt; table-&gt;nents; i++) { reg_addr = sg_dma_address(sg); reg_size = sg_dma_len(sg); page = sg_page(sg); log(\"addr = 0x%08x, size = 0x%08x %p %p\\n\", reg_addr, reg_size, page, page_address(page)); sg = sg_next(sg); } // do something on dma-buf log(\"unmap and detach dma_buf\"); dma_buf_unmap_attachment(attachment, table, DMA_BIDIRECTIONAL); dma_buf_detach(dma_buf, attachment); return 0; } static long importer_ioctl(struct file* filp, unsigned int cmd, unsigned long arg) { int fd; struct dma_buf* dma_buf; if (copy_from_user(&amp;fd, (void __user*)arg, sizeof(int))) { log(\"copy_from_user() failed\"); return -EFAULT; } dma_buf = dma_buf_get(fd); log(\"get dma_buf:%p by fd:%d\", dma_buf, fd); if (IS_ERR(dma_buf)) { log(); return PTR_ERR(dma_buf); } test_dma_buf(dma_buf); return 0; } static struct file_operations importer_fops = { .owner = THIS_MODULE, .unlocked_ioctl = importer_ioctl, }; static struct miscdevice mdev = { .minor = MISC_DYNAMIC_MINOR, .name = \"importer\", .fops = &amp;importer_fops, }; static int __init importer_init(void) { log(); return misc_register(&amp;mdev); } static void __exit importer_exit(void) { log(); misc_deregister(&amp;mdev); } module_init(importer_init); module_exit(importer_exit); MODULE_LICENSE(\"GPL v2\"); 2.2.1.1 进程间分享fd 如果要不同设备中共享buffer，就需要导入dmabuf到不同的设备中，这就涉及到一个fd共享的问题。我们知道fd是和进程相关的，每个进程都有它自己的文件描述符表，不同进程的fd表是不同的。所以不能把一个进程的fd直接传递给另一个进程中使用，需要通过一定的方法来共享fd，也就是fd的跨进程传递。 这个方法就是UNIX域的socket接口。 代码如下： 发送方代码： #define SHARE_DMABUF_PATH \"./share_dmabuf_file\" static void send_fd(int fd) { int ret = 0; char c = 0; struct iovec iov[1]; iov[0].iov_base = &amp;c; iov[0].iov_len = 1; int sockfd = 0; struct sockaddr_un addr; bzero(&amp;addr, sizeof(addr)); addr.sun_family = AF_UNIX; strcpy(addr.sun_path, SHARE_DMABUF_PATH); sockfd = socket(AF_UNIX, SOCK_STREAM, 0); if (sockfd &lt; 0) { perror(\"socket error\"); exit(-1); } ret = connect(sockfd, (struct sockaddr *)&amp;addr, sizeof(addr)); if(ret &lt;0){ perror(\"connect() failed\"); exit(0); } int cmsgsize = CMSG_LEN(sizeof(int)); struct cmsghdr* cmptr = (struct cmsghdr*)malloc(cmsgsize); if(cmptr == NULL){ err_exit(); } cmptr-&gt;cmsg_level = SOL_SOCKET; cmptr-&gt;cmsg_type = SCM_RIGHTS; cmptr-&gt;cmsg_len = cmsgsize; struct msghdr msg; msg.msg_iov = iov; msg.msg_iovlen = 1; msg.msg_name = NULL; msg.msg_namelen = 0; msg.msg_control = cmptr; msg.msg_controllen = cmsgsize; *(int *)CMSG_DATA(cmptr) = fd; ret = sendmsg(sockfd, &amp;msg, 0); if (ret == -1){ perror(\"sendmsg() failed.\"); err_exit(); } free(cmptr); close(sockfd); } 接收方代码 static int recv_fd(int sock) { struct cmsghdr* pcmsg = NULL; union { struct cmsghdr cm; char control[CMSG_SPACE(sizeof(int))]; } control_un; char buf; struct iovec iov[1]; iov[0].iov_base = &amp;buf; iov[0].iov_len = sizeof(buf); struct msghdr msg; msg.msg_iov = iov; msg.msg_iovlen = 1; msg.msg_name = NULL; msg.msg_namelen = 0; msg.msg_control = control_un.control; msg.msg_controllen = sizeof(control_un.control);; int ret = recvmsg(sock, &amp;msg, 0); if (ret == -1) { printf(\"\\033[31m%s:%d sock:%d err:%m \\033[0m\\n\\n\",__func__,__LINE__, sock); exit(1); } pcmsg = CMSG_FIRSTHDR(&amp;msg); int fd = *(int *)CMSG_DATA(pcmsg); return fd; } static int recv_prime_fd_from_socket(void){ int sockfd = 0; struct sockaddr_un addr; unlink(SHARE_DMABUF_PATH); addr.sun_family = AF_UNIX; strcpy(addr.sun_path, SHARE_DMABUF_PATH); int prime_fd; int clientfd; struct sockaddr cliaddr; socklen_t clilen; unsigned int len = strlen(addr.sun_path) + sizeof(addr.sun_family); sockfd = socket(AF_UNIX, SOCK_STREAM, 0); if (sockfd &lt; 0) { perror(\"socket error\"); exit(-1); } if (bind(sockfd, (struct sockaddr*)&amp;addr, len) &lt; 0) { perror(\"bind error\"); close(sockfd); exit(-1); } listen(sockfd, 2); clientfd = accept(sockfd, (struct sockaddr *)&amp;cliaddr, &amp;clilen); if(clientfd&lt;=0){ log(\"clientfd:%d %m\", clientfd); exit(-1); } prime_fd = recv_fd(clientfd); log(\"Recv prime_fd: %d\", prime_fd); return prime_fd; } 2.2.1.2 测试程序 基于上述进程间分享fd的方法，结合PRIME export和import驱动实现，可以写出如下测试PRIME的code 导出 prime 部分 #include &lt;fcntl.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;unistd.h&gt; #include &lt;xf86drm.h&gt; #include &lt;sys/socket.h&gt; #include &lt;sys/un.h&gt; #define SHARE_DMABUF_PATH \"./tt\" #define log(fmt, args...) printf(\"%s():%d \" fmt \"\\n\", __func__, __LINE__, ##args) #define err_return(fmt, args...) do{ \\ printf(\"%s():%d \" fmt \"\\n\", __func__, __LINE__, ##args); \\ return -1;\\ }while(0) #define err_exit(fmt, args...) do{ \\ printf(\"%s():%d \" fmt \"\\n\", __func__, __LINE__, ##args); \\ exit(1);\\ }while(0) struct buffer_object { uint32_t width; uint32_t height; uint32_t pitch; uint32_t handle; uint32_t size; int prime_fd; }; struct buffer_object buf; static int create_dumb_get_prime_fd(int fd, struct buffer_object *bo){ int ret = 0; struct drm_mode_create_dumb create = {}; create.width = bo-&gt;width; create.height = bo-&gt;height; create.bpp = 4*8; //ARGB ret = drmIoctl(fd, DRM_IOCTL_MODE_CREATE_DUMB, &amp;create); if(ret){ err_return(\"drmIoctl(DRM_IOCTL_MODE_CREATE_DUMB) failed\"); } ret = drmPrimeHandleToFD(fd, create.handle, DRM_CLOEXEC, &amp;bo-&gt;prime_fd); if(ret){ err_return(\"drmPrimeHandleToFD() failed\"); } bo-&gt;handle = create.handle; log(\"get handle:%d prime fd:%d\", create.handle, bo-&gt;prime_fd); return 0; } static void destroy_fd(int fd, struct buffer_object *bo){ int ret = 0; uint32_t handle = 0; struct drm_mode_destroy_dumb destroy = {}; ret = drmPrimeFDToHandle(fd, bo-&gt;prime_fd, &amp;handle); if(ret){ err_exit(\"drmFDToPrimeHandle() failed\"); } log(\"handle:%d vs bo-&gt;handle:%d\", handle, bo-&gt;handle); destroy.handle = handle; drmIoctl(fd, DRM_IOCTL_MODE_DESTROY_DUMB, &amp;destroy); } int main(int argc, char **argv){ int fd; fd = open(\"/dev/dri/card0\", O_RDWR | O_CLOEXEC); if(fd&lt;=0){ printf(\"%s():%d\\n\", __func__,__LINE__); return -1; } buf.width = 1024; buf.height = 1; create_dumb_get_prime_fd(fd, &amp;buf); send_fd(buf.prime_fd); printf(\"press any key to exit\\n\"); getchar(); destroy_fd(fd, &amp;buf); close(fd); return 0; } 导入prime 部分 #include &lt;fcntl.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;unistd.h&gt; #include &lt;sys/socket.h&gt; #include &lt;sys/un.h&gt; #include &lt;sys/ioctl.h&gt; #define log(fmt, args...) printf(\"%s():%d \" fmt \"\\n\", __func__, __LINE__, ##args) #define SHARE_DMABUF_PATH \"./tt\" #define err_return(fmt, args...) do{ \\ printf(\"%s():%d \" fmt \"\\n\", __func__, __LINE__, ##args); \\ return -1;\\ }while(0) #define err_return_void(fmt, args...) do{ \\ printf(\"%s():%d \" fmt \"\\n\", __func__, __LINE__, ##args); \\ return;\\ }while(0) int main(int argc, char **argv){ int ret = 0; int fd; int prime_fd = 5; fd = open(\"/dev/importer\", O_RDWR | O_CLOEXEC); if(fd&lt;=0){ printf(\"%s():%d\\n\", __func__,__LINE__); return -1; } prime_fd = recv_prime_fd_from_socket(); // 把fd传递给import驱动进行访问 ret = ioctl(fd, 0, &amp;prime_fd); if(ret&lt;0){ err_return(\"ioctl failed\"); } close(prime_fd); close(fd); return 0; } 2.2.2 基于GEM的PRIME实现 下图展示了基于GEM如何去实现PRIME特性，代码冗长，就不再贴出。 在实现driver时，主要工作有两个方面。 实现 struct drm_driver，如图所示，就是各函数指针直接设定为GEM的对应函数即可 实现 drm_gem_object_funcs. 只要实现图中drm_gem_object_funcs 各项即可。它所要实现接口对应调用关系如图所示，从中也可看出它们需要实现的内容。 2.3 系统现有的三种实现 2.3.1 share memory 它是基于GEM和share memory实现的一组DRM操作，方便上层使用。 /** * DRM_GEM_SHMEM_DRIVER_OPS - Default shmem GEM operations * * This macro provides a shortcut for setting the shmem GEM operations in * the &amp;drm_driver structure. * 这个宏定义了一组shmem 的GEM操作，利用它可以快捷的在drm_driver结构中定义GEM操作。 * * 在udl, hyperv, vkms, tiny, mgag200和gud 驱动中有用到它，可做参考。 * */ #define DRM_GEM_SHMEM_DRIVER_OPS \\ .prime_handle_to_fd = drm_gem_prime_handle_to_fd, \\ .prime_fd_to_handle = drm_gem_prime_fd_to_handle, \\ .gem_prime_import_sg_table = drm_gem_shmem_prime_import_sg_table, \\ .gem_prime_mmap = drm_gem_prime_mmap, \\ .dumb_create = drm_gem_shmem_dumb_create // GEM 提供的可供driver使用的struct file_operations #define DEFINE_DRM_GEM_FOPS(name) \\ static const struct file_operations name = {\\ .owner = THIS_MODULE,\\ .open = drm_open,\\ .release = drm_release,\\ .unlocked_ioctl = drm_ioctl,\\ .compat_ioctl = drm_compat_ioctl,\\ .poll = drm_poll,\\ .read = drm_read,\\ .llseek = noop_llseek,\\ .mmap = drm_gem_mmap,\\ } 在现有的udl, hyperv, vkms, tiny, mgag200和gud 驱动中，都使用了DEFINE_DRM_GEM_FOPS 和DRM_GEM_SHMEM_DRIVER_OPS 来简化driver的开发。 shem_helper的实现，主要就是针对share memory，实现drm_gem_object_funcs中定义的各个函数接口。 关系图如下： 2.3.1.1 create dumb 实现流程图如下： 2.3.1.2 mmap 实现流程图如下： 2.3.1.3 其他关于GEM的实现 实现流程图如下： 2.3.2 CMA CMA: Contiguous Memory Allocator， CMA是一种内存分配机制，确保分配物理上连续的内存区域，它特别适用于需要具有连续内存的设备（例如显示控制器）的情况。 DRM的CMA helper提供了一种分配既具有物理连续性又适用于DMA（直接内存访问）操作的内存的方法，适合在硬件缺乏IOMMU（输入/输出内存管理单元）来映射分散的缓冲区的场景使用。 /** * DRM_GEM_CMA_DRIVER_OPS_WITH_DUMB_CREATE - CMA GEM driver operations * @dumb_create_func: callback function for .dumb_create * * This macro provides a shortcut for setting the default GEM operations in the * &amp;drm_driver structure. * * This macro is a variant of DRM_GEM_CMA_DRIVER_OPS for drivers that * override the default implementation of &amp;struct rm_driver.dumb_create. Use * DRM_GEM_CMA_DRIVER_OPS if possible. Drivers that require a virtual address * on imported buffers should use * DRM_GEM_CMA_DRIVER_OPS_VMAP_WITH_DUMB_CREATE() instead. * * 使用到它的现有驱动有: aspeed, sti vc4 hisilicon ingenic shmobile xlnx imx sun4i tiny meson 等 */ #define DRM_GEM_CMA_DRIVER_OPS_WITH_DUMB_CREATE(dumb_create_func) \\ .dumb_create = (dumb_create_func), \\ .prime_handle_to_fd = drm_gem_prime_handle_to_fd, \\ .prime_fd_to_handle = drm_gem_prime_fd_to_handle, \\ .gem_prime_import_sg_table = drm_gem_cma_prime_import_sg_table, \\ .gem_prime_mmap = drm_gem_prime_mmap #define DRM_GEM_CMA_DRIVER_OPS \\ DRM_GEM_CMA_DRIVER_OPS_WITH_DUMB_CREATE(drm_gem_cma_dumb_create) cma_helper的实现，主要就是针对CMA的特性调用DMA的接口实现drm_gem_object_funcs中定义的各个函数接口。 一些在CMA中实现的函数 function 功能 drm_gem_cma_create 分配由CMA内存支持的GEM对象。 drm_gem_cma_dumb_create_internal 为DRM帧缓冲创建内存区域。 drm_gem_cma_dumb_map_offset 将DRM帧缓冲的内存区域映射到用户空间。 drm_gem_cma_mmap 为用户空间访问映射分配的内存。 drm_gem_cma_free_object 释放GEM对象。 drm_gem_cma_prime_get_sg_table 获取导入PRIME缓冲区的散射/聚集表。 drm_gem_cma_prime_import_sg_table 从散射/聚集表导入GEM对象。 drm_gem_cma_prime_mmap 为PRIME mmap映射GEM对象。 drm_gem_cma_prime_vmap和drm_gem_cma_prime_vunmap 为PRIME映射和取消映射GEM对象。 关系图如下： 2.3.2.1 create dumb 实现流程图如下： 2.3.2.2 mmap 实现流程图如下： 2.3.2.3 其他关于GEM的实现 实现流程图如下： 2.3.3 VRAM VRAM: Video RAM VRAM是显卡上的专用内存，用于存储图像、纹理、帧缓冲区和其他与图形相关的数据。在显卡中，VRAM是用于显示输出的内存池。它通常位于显卡芯片上，具有高带宽和低延迟，适用于图形渲染。VRAM的大小直接影响显卡的性能。更大的VRAM允许存储更多图像数据，从而提高图形处理速度。 /** * define DRM_GEM_VRAM_DRIVER - default callback functions for \\ &amp;struct drm_driver * * Drivers that use VRAM MM and GEM VRAM can use this macro to initialize * &amp;struct drm_driver with default functions. * * 使用到它的现有驱动有: ast, tiny vboxvideo */ #define DRM_GEM_VRAM_DRIVER \\ .debugfs_init = drm_vram_mm_debugfs_init, \\ .dumb_create = drm_gem_vram_driver_dumb_create, \\ .dumb_map_offset = drm_gem_ttm_dumb_map_offset, \\ .gem_prime_mmap = drm_gem_prime_mmap vram_helper的实现，主要是对TTM接口的封装调用来实现drm_gem_object_funcs中定义的各个函数接口。 GEM、 TTM使用场景 GEM通常用于UMA（Unified Memory Architecture）设备，而TTM更适用于具有专用视频RAM的设备。 关系图如下： 2.3.3.1 create dumb 实现流程图如下： 2.3.3.2 mmap 实现流程图如下： 2.3.3.3 其他关于GEM的实现 实现流程图如下： 3.KMS 3.1 相关概念 KMS（Kernel Mode Setting）是DRM框架的一个重要模块， 主要两个功能： 显示参数设置： KMS负责设置显卡或图形适配器的模式，包括分辨率、刷新率、电源状态（休眠唤醒）等。 显示画面控制： KMS管理显示缓冲区的切换、多图层的合成方式，以及每个图层的显示位置。 KMS的组成部分： DRM FrameBuffer： 这是一个软件抽象，与硬件无关，描述了图层显示内容的信息，如宽度、高度、像素格式和行距等。 Planes： 基本的显示控制单元，每个图像都有一个Plane。Planes的属性控制着图像的显示区域、翻转方式和色彩混合方式。 CRTC： CRTC负责将要显示的图像转化为底层硬件上的具体时序要求。它还负责帧切换、电源控制和色彩调整，可以连接多个Encoder，实现屏幕复制功能。 Encoder： 将内存中的像素转换成显示器所需的信号。 Connector： 连接器负责硬件设备的接入，如HDMI、VGA等，还可以获取设备的EDID和DPMS连接状态。 这些组件共同构成了一个完整的DRM显示控制过程。KMS的目标是适应现代显示设备的逻辑，使其能够更好地支持新特性，如显示覆盖、GPU加速和硬件光标等功能。 3.2 重要结构体 3.3 函数流程 devm_drm_dev_alloc() drm_vblank_init() drm_mode_config_init() drmModeAddFb() init CRTC init plane init connector 3.4 传统实现 drmModeSetCrtc 3.5 atomic实现 smaple code #define _GNU_SOURCE #include &lt;errno.h&gt; #include &lt;fcntl.h&gt; #include &lt;stdbool.h&gt; #include &lt;stdint.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;sys/mman.h&gt; #include &lt;time.h&gt; #include &lt;unistd.h&gt; #include &lt;xf86drm.h&gt; #include &lt;xf86drmMode.h&gt; struct buffer_object { uint32_t width; uint32_t height; uint32_t pitch; uint32_t handle; uint32_t size; uint32_t fb_id; }; struct buffer_object buf; static int modeset_create_fb(int fd, struct buffer_object *bo) { struct drm_mode_create_dumb create = {}; struct drm_mode_map_dumb map = {}; create.width = bo-&gt;width; create.height = bo-&gt;height; create.bpp = 32; drmIoctl(fd, DRM_IOCTL_MODE_CREATE_DUMB, &amp;create); bo-&gt;pitch = create.pitch; bo-&gt;size = create.size; bo-&gt;handle = create.handle; drmModeAddFB(fd, bo-&gt;width, bo-&gt;height, 24, 32, bo-&gt;pitch,bo-&gt;handle, &amp;bo-&gt;fb_id); // drmModeAddFB2 可以传递多个handle // drmModeAddFB(fd, bo-&gt;width, bo-&gt;height, 24, 32, bo-&gt;pitch, // bo-&gt;handle, &amp;bo-&gt;fb_id); //--&gt; calling mode_config_funcs.fb_create() map.handle = create.handle; drmIoctl(fd, DRM_IOCTL_MODE_MAP_DUMB, &amp;map); return 0; } static void modeset_destroy_fb(int fd, struct buffer_object *bo) { struct drm_mode_destroy_dumb destroy = {}; drmModeRmFB(fd, bo-&gt;fb_id); destroy.handle = bo-&gt;handle; drmIoctl(fd, DRM_IOCTL_MODE_DESTROY_DUMB, &amp;destroy); } static uint32_t get_property_id(int fd, drmModeObjectProperties *props, const char *name) { drmModePropertyPtr property; uint32_t i, id = 0; for (i = 0; i &lt; props-&gt;count_props; i++) { property = drmModeGetProperty(fd, props-&gt;props[i]); if (!strcmp(property-&gt;name, name)){ id = property-&gt;prop_id; } drmModeFreeProperty(property); if (id) break; } return id; } int main(int argc, char **argv) { int fd; drmModeConnector *conn; drmModeRes *res; drmModePlaneRes *plane_res; drmModeObjectProperties *props; drmModeAtomicReq *req; uint32_t conn_id; uint32_t crtc_id; uint32_t plane_id; uint32_t blob_id; uint32_t property_crtc_id; uint32_t property_mode_id; uint32_t property_active; uint32_t property_fb_id; uint32_t property_crtc_x; uint32_t property_crtc_y; uint32_t property_crtc_w; uint32_t property_crtc_h; uint32_t property_src_x; uint32_t property_src_y; uint32_t property_src_w; uint32_t property_src_h; fd = open(\"/dev/dri/card0\", O_RDWR | O_CLOEXEC); res = drmModeGetResources(fd); crtc_id = res-&gt;crtcs[0]; conn_id = res-&gt;connectors[0]; drmSetClientCap(fd, DRM_CLIENT_CAP_UNIVERSAL_PLANES, 1); plane_res = drmModeGetPlaneResources(fd); plane_id = plane_res-&gt;planes[0]; conn = drmModeGetConnector(fd, conn_id); buf.width = conn-&gt;modes[0].hdisplay; buf.height = conn-&gt;modes[0].vdisplay; modeset_create_fb(fd, &amp;buf); drmSetClientCap(fd, DRM_CLIENT_CAP_ATOMIC, 1); props = drmModeObjectGetProperties(fd, conn_id, DRM_MODE_OBJECT_CONNECTOR); property_crtc_id = get_property_id(fd, props, \"CRTC_ID\"); drmModeFreeObjectProperties(props); props = drmModeObjectGetProperties(fd, crtc_id, DRM_MODE_OBJECT_CRTC); property_active = get_property_id(fd, props, \"ACTIVE\"); property_mode_id = get_property_id(fd, props, \"MODE_ID\"); drmModeFreeObjectProperties(props); drmModeCreatePropertyBlob(fd, &amp;conn-&gt;modes[0], sizeof(conn-&gt;modes[0]), &amp;blob_id); req = drmModeAtomicAlloc(); drmModeAtomicAddProperty(req, crtc_id, property_active, 1); drmModeAtomicAddProperty(req, crtc_id, property_mode_id, blob_id); drmModeAtomicAddProperty(req, conn_id, property_crtc_id, crtc_id); drmModeAtomicCommit(fd, req, DRM_MODE_ATOMIC_ALLOW_MODESET, NULL); drmModeAtomicFree(req); /* get plane properties */ props = drmModeObjectGetProperties(fd, plane_id, DRM_MODE_OBJECT_PLANE); property_crtc_id = get_property_id(fd, props, \"CRTC_ID\"); property_fb_id = get_property_id(fd, props, \"FB_ID\"); property_crtc_x = get_property_id(fd, props, \"CRTC_X\"); property_crtc_y = get_property_id(fd, props, \"CRTC_Y\"); property_crtc_w = get_property_id(fd, props, \"CRTC_W\"); property_crtc_h = get_property_id(fd, props, \"CRTC_H\"); property_src_x = get_property_id(fd, props, \"SRC_X\"); property_src_y = get_property_id(fd, props, \"SRC_Y\"); property_src_w = get_property_id(fd, props, \"SRC_W\"); property_src_h = get_property_id(fd, props, \"SRC_H\"); drmModeFreeObjectProperties(props); /* atomic plane update */ req = drmModeAtomicAlloc(); drmModeAtomicAddProperty(req, plane_id, property_crtc_id, crtc_id); drmModeAtomicAddProperty(req, plane_id, property_fb_id, buf.fb_id); drmModeAtomicAddProperty(req, plane_id, property_crtc_x, 50); drmModeAtomicAddProperty(req, plane_id, property_crtc_y, 50); drmModeAtomicAddProperty(req, plane_id, property_crtc_w, 320); drmModeAtomicAddProperty(req, plane_id, property_crtc_h, 320); drmModeAtomicAddProperty(req, plane_id, property_src_x, 0); drmModeAtomicAddProperty(req, plane_id, property_src_y, 0); drmModeAtomicAddProperty(req, plane_id, property_src_w, 320 &lt;&lt; 16); drmModeAtomicAddProperty(req, plane_id, property_src_h, 320 &lt;&lt; 16); drmModeAtomicCommit(fd, req, 0, NULL); drmModeAtomicFree(req); printf(\"drmModeAtomicCommit SetPlane done\\n\"); getchar(); modeset_destroy_fb(fd, &amp;buf); drmModeFreeConnector(conn); drmModeFreePlaneResources(plane_res); drmModeFreeResources(res); close(fd); return 0; } drmModeGetProperty drmModeAtomicCommit 3.6 vkms VKMS（Virtual Kernel Modesetting）是 Linux 内核中的一个软件模拟 KMS 驱动程序，主要用于测试和在无显示硬件的机器上运行 X（或类似的图形界面） 4 MISC 4.1 modifier 在 DRM（Direct Rendering Manager） 中，modifier 是用于描述图像帧的内存存储方式的标志。让我们详细了解一下： DRM Modifier 是什么？ DRM Modifier 是一个 64 位的、厂商前缀的、半透明的无符号整数。 大多数 modifier 表示图像的具体、厂商特定的平铺格式。 为什么需要 Modifier？ 图像帧在内存中的存储方式可能因硬件和驱动程序而异。 Modifier 描述了像素到内存样本之间的转换机制，以及缓冲区的实际内存存储方式。 常见 Modifier 示例： LINEAR Modifier：最直接的 Modifier，其中每个像素具有连续的存储，像素在内存中的位置可以通过步幅轻松计算。 TILED Modifier：描述了像素以 4x4 块的形式存储，按行主序排列。 其他 Modifier 可能涉及到更复杂的内存访问机制，例如平铺和可能的压缩。 应用场景： DRM Modifier 在跨设备的缓冲区共享中非常重要，例如在不同的图形硬件之间共享图像帧。 它们也用于描述图像帧的格式，例如颜色定义和像素格式。 总之，DRM Modifier 是描述图像帧内存存储方式的关键标志，对于图形硬件和驱动程序之间的交互至关重要。 4.2 gamma 在 DRM（Direct Rendering Manager） 中，gamma 是用于图像颜色校正的一个重要概念。让我详细解释一下： Gamma 是什么？ Gamma 是一个非线性的颜色校正过程，用于调整显示设备的亮度和对比度。 它主要影响图像的中间和暗部，而不是亮部。 Gamma 校正的作用： Gamma 校正用于补偿显示设备的非线性响应。 显示设备（例如显示器、电视）对输入信号的响应不是线性的，而是呈现出一种非线性的亮度-输入关系。 通过应用 Gamma 校正，可以使图像在显示时更接近人眼感知的线性亮度。 Gamma 曲线： Gamma 曲线描述了输入信号和显示亮度之间的关系。 通常，显示设备的 Gamma 曲线是一个幂函数，通常在 2.2 到 2.5 之间。 应用场景： Gamma 校正在图形、视频和游戏中都很重要。 在图像处理和显示中，应用正确的 Gamma 曲线可以确保图像的亮度和对比度在不同设备上保持一致。 总之，Gamma 是一种用于调整显示设备响应的非线性颜色校正方法，以确保图像在不同设备上呈现一致的亮度和对比度。 4.3 Blob 当涉及到 DRM（Direct Rendering Manager）中的“blob”时，我们实际上在讨论一种特定类型的属性。让我详细解释一下： 1 什么是 Blob？ 在 DRM 中，Blob 是一种特殊的属性，用于存储自定义数据块。它允许用户空间应用程序将自定义结构体数据传递给内核空间。 Blob 通常用于存储一些不适合使用标准属性的数据，例如模式信息、LUT（查找表）数据、校准数据等。 2 Blob 的结构和用法： Blob 由两部分组成： Blob ID：每个 Blob 都有一个唯一的 ID，用于在内核中标识该 Blob。 Blob 数据：这是一个自定义长度的内存块，可以存储任何类型的数据。 Blob 可以存储各种信息，例如显示模式（mode）的详细信息、颜色校准数据、Gamma 表等。 3 Blob 的示例用途： 模式信息（Mode Information）：Blob 可以存储显示模式的详细信息，例如分辨率、刷新率、像素格式等。 颜色校准数据：如果您需要在显示设备上进行颜色校准，可以使用 Blob 存储校准数据。 Gamma 表：Gamma 表用于调整显示设备的亮度和对比度。这些数据可以存储在 Blob 中。 4 如何操作 Blob？ 用户空间应用程序可以通过 DRM 接口来创建、获取和设置 Blob。 创建 Blob：使用 drmModeCreatePropertyBlob 函数来创建一个 Blob，并将自定义数据传递给内核。 获取 Blob 数据：使用 drmModeGetPropertyBlob 函数来获取 Blob 中存储的数据。 设置 Blob 数据：使用 drmModeAtomicAddProperty 函数将 Blob ID 添加到 Atomic 请求中，从而修改 Blob 数据。 5 示例 #include &lt;xf86drm.h&gt; #include &lt;xf86drmMode.h&gt; int main() { int drm_fd = open(\"/dev/dri/card0\", O_RDWR); // 打开 DRM 设备 // 读取 GPU 固件数据（假设存在 firmware.bin 文件） FILE *firmware_file = fopen(\"firmware.bin\", \"rb\"); fseek(firmware_file, 0, SEEK_END); size_t firmware_size = ftell(firmware_file); fseek(firmware_file, 0, SEEK_SET); void *firmware_data = malloc(firmware_size); fread(firmware_data, 1, firmware_size, firmware_file); fclose(firmware_file); // 创建 DRM blob uint32_t blob_handle; drmModeCreatePropertyBlob(drm_fd, firmware_data, firmware_size, &amp;blob_handle); // 将 blob 设置为 GPU 的固件 // ...（其他操作，例如加载到显卡） // 清理资源 free(firmware_data); close(drm_fd); return 0; } 总之，Blob 是一种用于存储自定义数据的特殊属性，允许用户空间应用程序与内核交换非标准化的信息。它在 DRM 中的应用范围很广，例如显示模式、颜色校准和 Gamma 表等。 4.4 drmModeSetCrtc与drmModePageFlip 在 Linux 图形显示框架中，drmModeSetCrtc、drmModePageFlip 和 drmModeSetPlane 是三个重要的函数，它们用于更新显示内容，但在功能和执行时机上存在一些区别： drmModeSetCrtc： drmModeSetCrtc 是最核心的函数之一，负责建立从帧缓存到显示器连接器的关联。 它执行两个主要任务： 更新画面：切换显示缓冲区，合成多图层，设置每个图层的显示位置。 设置显示参数：包括分辨率、刷新率、电源状态（休眠唤醒）等。 drmModePageFlip： drmModePageFlip 也用于更新显示内容，但与 drmModeSetCrtc 最大的区别在于： 它只会在 VSYNC 到来后才真正执行帧缓冲区切换动作。 等待 VSYNC 可以避免画面撕裂（tearing）现象。 适用于需要同步刷新的场景，如视频播放、游戏等。 drmModeSetPlane： drmModeSetPlane 用于设置硬件平面（overlay plane）的参数。 硬件平面是一种特殊的图层，可以在其他图层之上叠加显示。 适用于实现视频叠加、OSD（On-Screen Display）等功能。 总结： drmModeSetCrtc 负责整体显示设置。 drmModePageFlip 等待 VSYNC 后切换帧缓冲区。 drmModeSetPlane 控制硬件平面的显示。 5 IOCTL DRM_IOCTL_VERSION 它通过主要、次要和补丁程序级别的三元组来标识驱动程序版本。 这些信息在初始化时被打印到内核日志中 通过 DRM_IOCTL_VERSION ioctl 传递到用户空间。 驱动程序的描述是一个纯粹的信息字符串，通过 DRM_IOCTL_VERSION ioctl 传递给用户空间，但在内核中没有其他用途。驱动程序的日期以 YYYYMMDD 格式表示，用于标识驱动程序的最新修改日期。由于大多数驱动程序未能更新它，其值基本上是无用的。 DRM_IOCTL_GET_UNIQUE 它允许用户空间程序查询与 DRM 设备相关的唯一标识符。这个接口通常用于获取设备的 UUID 或其他唯一标识，以便在多个设备之间进行区分。 DRM_IOCTL_SET_UNIQUE 它允许用户空间程序设置 DRM 设备的唯一名称。让我们深入了解一下这个接口的作用和实现。 接口作用： DRM_IOCTL_SET_UNIQUE 允许用户空间程序使用指定的字符串设置 DRM 设备的唯一名称。 这个唯一名称通常用于标识不同的 DRM 设备，以便在多个设备之间进行区分。 实现细节： 在 Linux 内核中，DRM_IOCTL_SET_UNIQUE 的实现可能因不同的 DRM 驱动而异。 用户空间程序可以通过调用相应的 ioctl 函数来设置设备的唯一名称。 DRM_IOCTL_IRQ_BUSID 它用于基于总线 ID（busid）为 PCI 设备获取中断请求（IRQ）。在过去，这个接口是通用的 DRM 模块函数，可以为多个不同的设备提供服务。然而，现在它可能需要更改，以仅返回与特定 drm_device_t 相关联的设备的中断号。 DRM_IOCTL_GET_CLIENT 它用于查询 DRM 设备的客户端信息。让我们来详细了解一下这个接口的作用和实现。 接口作用： DRM_IOCTL_GET_CLIENT 允许用户空间程序查询与 DRM 设备相关的客户端信息。 这个接口通常用于获取客户端的唯一标识符或其他相关信息，以便在多个客户端之间进行区分。 实现细节： 在 Linux 内核中，DRM_IOCTL_GET_CLIENT 的实现可能因不同的 DRM 驱动而异。 通过调用 drmGetBusid() 函数，用户空间程序可以获取与总线 ID（busid）相关的客户端信息。 请注意，这个接口的具体实现可能因不同的驱动而有所不同，因此您可以查阅特定驱动的文档或源代码以获取更详细的信息。 DRM_IOCTL_GET_STATS 它允许用户空间程序查询与 DRM 设备相关的统计信息。让我们来详细了解一下这个接口的作用和实现。 接口作用： DRM_IOCTL_GET_STATS 允许用户空间程序获取与 DRM 设备相关的统计数据。 这个接口通常用于查询设备的性能指标、资源使用情况、错误统计等信息。 实现细节： 在 Linux 内核中，DRM_IOCTL_GET_STATS 的实现可能因不同的 DRM 驱动而异。 用户空间程序可以通过调用相应的 ioctl 函数来获取统计数据。 请注意，这个接口的具体实现可能因不同的驱动而有所不同，因此您可以查阅特定驱动的文档或源代码以获取更详细的信息。 DRM_IOCTL_GET_CAP 它允许用户空间程序查询与 DRM 设备相关的能力信息。让我们来详细了解一下这个接口的作用和实现。 接口作用： DRM_IOCTL_GET_CAP 允许用户空间程序获取与 DRM 设备相关的能力数据。 这个接口通常用于查询设备支持的功能、特性和限制。 实现细节： 在 Linux 内核中，DRM_IOCTL_GET_CAP 的实现可能因不同的 DRM 驱动而异。 用户空间程序可以通过调用相应的 ioctl 函数来获取能力数据。 请注意，这个接口的具体实现可能因不同的驱动而有所不同，因此您可以查阅特定驱动的文档或源代码以获取更详细的信息。 DRM_IOCTL_SET_CLIENT_CAP 它允许用户空间程序设置与 DRM 设备相关的能力信息。让我们来详细了解一下这个接口的作用和实现。 接口作用： DRM_IOCTL_SET_CLIENT_CAP 允许用户空间程序设置与 DRM 设备相关的能力数据。 这个接口通常用于查询设备支持的功能、特性和限制。 实现细节： 在 Linux 内核中，DRM_IOCTL_SET_CLIENT_CAP 的实现可能因不同的 DRM 驱动而异。 用户空间程序可以通过调用相应的 ioctl 函数来设置能力数据。 请注意，这个接口的具体实现可能因不同的驱动而有所不同，因此您可以查阅特定驱动的文档或源代码以获取更详细的信息。 DRM_CLIENT_CAP_ASPECT_RATIO: 是一个客户端能力标志，用于指示用户空间应用程序是否支持图像的纵横比信息。如果应用程序支持此标志，内核将在模式中传递纵横比信息。这对于显示图像时保持正确的纵横比非常重要。 如果设置为 1，DRM 内核将向用户空间公开原子属性。这隐式启用了 DRM_CLIENT_CAP_UNIVERSAL_PLANES 和 DRM_CLIENT_CAP_ASPECT_RATIO。如果驱动程序不支持原子模式设置，启用此功能将失败并返回 -EOPNOTSUPP 错误。这个功能是在内核版本 4.0 中引入的1。 DRM_IOCTL_WAIT_VBLANK 它允许用户空间程序在指定的vblank事件发生时阻塞或请求信号。让我们来详细了解一下这个接口的作用和实现： 接口作用： DRM_IOCTL_WAIT_VBLANK 允许用户空间程序在指定的vblank事件发生时阻塞或请求信号。 这个接口通常用于与显示相关的同步操作，例如在进行页面翻转时等待vblank。 实现细节： DRM 核心处理大部分vblank管理逻辑，包括过滤掉虚假中断、保持无竞争的空白计数、处理计数器回绕和重置，以及保持使用计数。 用户空间程序可以通过执行相应的 ioctl 函数来使用这个接口。 这个机制确保只有经过身份验证的调用者才能访问特定的 DRM 功能。 垂直同步（VSYNC）： 在图形渲染中，垂直同步是一种技术，用于确保图像在显示器上的刷新与显示器的垂直空白期（vertical blanking interval）同步。 vblank(垂直空白期)是显示器在绘制一帧图像后，准备绘制下一帧之间的时间间隔。 drmWaitVBlank 函数： 这个函数用于等待垂直同步信号。 它接受一个 DRM 设备文件描述符（file descriptor）和一个表示显示输出的 CRTC（Cathode Ray Tube Controller）的 ID。 当垂直同步信号到达时，函数会返回。 在游戏开发和图形渲染中，drmWaitVBlank 可以用于确保页面翻转（page flip）与垂直同步对齐，从而避免屏幕撕裂（tearing）。 DRM_IOCTL_MODE_GETGAMMA 用于从 Linux 内核模式设置（KMS） 中获取特定 CRTC（Cathode Ray Tube Controller） 的 伽马校正（Gamma Correction） 信息. 详情如下： 伽马校正是什么？ 伽马校正 是一种图像处理技术，用于调整显示设备的亮度和对比度。 它通过改变像素的亮度值来实现，以便更准确地显示不同亮度级别的图像。 DRM_IOCTL_MODE_GETGAMMA 的作用 通过调用 DRM_IOCTL_MODE_GETGAMMA，应用程序可以获取有关特定 CRTC 的伽马校正信息。 这些信息可能包括伽马校正曲线、亮度和对比度的调整等。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_MODE_GETGAMMA，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_GETCRTC：获取有关特定 CRTC 的信息。 DRM_IOCTL_MODE_SETCRTC：设置 CRTC 参数。 DRM_IOCTL_MODE_ADDFB：添加新的帧缓冲区对象。 DRM_IOCTL_MODE_RMFB：移除帧缓冲区对象。 DRM_IOCTL_MODE_DIRTYFB 用于定义一个帧缓冲区区域为“脏”（数据已更改，因此需要重新显示）。这个 ioctl 使用了 drm_mode_fb_dirty_cmd 结构，其中包含一个 num_clips 字段，指示更改的区域数量. 帧缓冲区是什么？ 帧缓冲区 是一个抽象的内存对象，用于向 CRTC 扫描输出像素。 应用程序通过 DRM_IOCTL_MODE_ADDFB（2）ioctl 显式请求创建帧缓冲区，并接收一个不透明的句柄，可以传递给 KMS CRTC 控制、平面配置和页面翻转功能。 帧缓冲区依赖于底层内存管理器进行低级内存操作。 DRM_IOCTL_MODE_DIRTYFB 的作用 通过调用 DRM_IOCTL_MODE_DIRTYFB，应用程序可以将特定帧缓冲区区域标记为“脏”。 这通常用于通知显示系统需要重新扫描和显示更改的像素数据。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_MODE_DIRTYFB，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_GETCRTC：获取有关特定 CRTC 的信息。 DRM_IOCTL_MODE_SETCRTC：设置 CRTC 参数。 DRM_IOCTL_MODE_ADDFB：添加新的帧缓冲区对象。 DRM_IOCTL_MODE_RMFB：移除帧缓冲区对象。 DRM_IOCTL_MODE_ATOMIC 用于在 Linux 内核模式设置（KMS） 中执行 原子操作（Atomic Operation）。详情如下： KMS 是什么？ KMS（Kernel Mode Setting） 是一种内核级别的图形显示设置机制，用于管理显示设备的模式和状态。 它允许用户空间应用程序与内核交互，以配置显示输出。 原子操作的概念 在图形渲染中，原子操作 是指一组状态更改，要么全部成功应用，要么全部失败，不会出现部分应用的情况。 在 KMS 中，原子操作用于一次性更新多个显示对象的状态，例如 CRTC、平面、连接器等。 DRM_IOCTL_MODE_ATOMIC 的作用 通过调用 DRM_IOCTL_MODE_ATOMIC，应用程序可以提交一组原子操作，以更新显示管道的状态。 这些操作可以包括更改 CRTC 模式、平面配置、连接器状态等。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_MODE_ATOMIC，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_GETCRTC：获取有关特定 CRTC 的信息。 DRM_IOCTL_MODE_SETCRTC：设置 CRTC 参数。 DRM_IOCTL_MODE_ADDFB：添加新的帧缓冲区对象。 DRM_IOCTL_MODE_RMFB：移除帧缓冲区对象。 DRM_IOCTL_CRTC_GET_SEQUENCE 用于从 Linux 内核模式设置（KMS） 中获取特定 CRTC（Cathode Ray Tube Controller） 的 帧序列（Frame Sequence） 信息. 详情如下： CRTC 是什么？ CRTC 是显示控制器，负责将图形数据发送到显示设备（例如显示器或电视）。 它管理像素时钟、扫描线和帧缓冲区的刷新。 帧序列是什么？ 在图形渲染中，帧序列 是指显示设备刷新图像的顺序。 通过调用 DRM_IOCTL_CRTC_GET_SEQUENCE，应用程序可以获取有关特定 CRTC 的帧序列信息，例如当前帧数、垂直同步信号等。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_CRTC_GET_SEQUENCE，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_GETCRTC：获取有关特定 CRTC 的信息。 DRM_IOCTL_MODE_SETCRTC：设置 CRTC 参数。 DRM_IOCTL_MODE_ADDFB：添加新的帧缓冲区对象。 DRM_IOCTL_MODE_RMFB：移除帧缓冲区对象。 DRM_IOCTL_CRTC_QUEUE_SEQUENCE 用于在 Linux 内核模式设置（KMS） 中将特定 CRTC（Cathode Ray Tube Controller） 的帧序列信息添加到队列中. 以下是关于 DRM_IOCTL_CRTC_QUEUE_SEQUENCE 的一些要点： CRTC 是什么？ CRTC 是显示控制器，负责将图形数据发送到显示设备（例如显示器或电视）。 它管理像素时钟、扫描线和帧缓冲区的刷新。 帧序列是什么？ 在图形渲染中，帧序列 是指显示设备刷新图像的顺序。 通过调用 DRM_IOCTL_CRTC_QUEUE_SEQUENCE，应用程序可以将特定 CRTC 的帧序列信息添加到队列中。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_CRTC_QUEUE_SEQUENCE，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_GETCRTC：获取有关特定 CRTC 的信息。 DRM_IOCTL_MODE_SETCRTC：设置 CRTC 参数。 DRM_IOCTL_MODE_ADDFB：添加新的帧缓冲区对象。 DRM_IOCTL_MODE_RMFB：移除帧缓冲区对象。 Magic &amp; Master DRM_IOCTL_GET_MAGIC 是一对 IOCTL（Input/Output Control）命令。详情如下： 魔数/幻数字（Magic Number）的作用 在图形设备驱动中，DRM_IOCTL_GET_MAGIC 用于设置魔数/幻数字，以进行 GEM ioctl 权限检查。 魔数是一个32位的标识符，用于验证对图形资源的访问权限。 具体操作 DRM_IOCTL_GET_MAGIC 函数会返回一个32位的魔数，然后将该魔数传递给 DRM-Master。 DRM-Master 使用此魔数通过 DRM_IOCTL_AUTH_MAGIC 给发起鉴权的非 DRM-Master 应用程序授权。 DRM_IOCTL_AUTH_MAGIC 它用于对非 DRM 主用户空间程序进行身份验证。让我们详细了解一下这个接口的作用和实现： 接口作用： DRM_IOCTL_AUTH_MAGIC 用于对非 DRM 主用户空间程序进行身份验证。 具体流程如下： 非 DRM 主用户空间程序通过执行 DRM_IOCTL_GET_MAGIC ioctl 从 DRM 设备获取一个唯一的令牌（32 位魔数）。 然后，用户空间程序将此令牌传递给 DRM 主（例如通过 IPC 或 X 客户端中的 DRI2Authenticate 请求）。 DRM 主进程随后使用 DRM_IOCTL_AUTH_MAGIC ioctl 将令牌发送回 DRM 设备。 设备根据接收到的令牌，授予发起身份验证的非 DRM 主应用特殊权限。 实现细节： 身份验证令牌允许非 DRM 主进程执行特定的特权操作。 通过将令牌与相应的文件描述符（fd）关联，设备授权应用访问特定资源或执行受限操作。 这种机制确保只有经过身份验证的调用者才能访问特定的 DRM 功能。 DRM_IOCTL_SET_MASTER 它允许用户空间程序成为唯一的 DRM 主显示管理程序。执行此 ioctl 后，该程序获得了独占的权限，用于管理与显示相关的操作。相反，DRM_IOCTL_DROP_MASTER ioctl 可用于放弃 DRM 主身份。通常情况下，X 服务器（Xorg）充当 DRM 主。 其他非 DRM 主用户空间程序可以通过 DRM-Auth 进行身份验证。具体过程如下： 执行 DRM_IOCTL_GET_MAGIC ioctl，从 DRM 设备获取一个唯一的令牌（魔数）。 将此令牌传递给 DRM 主（例如通过 IPC 或 X 客户端中的 DRI2Authenticate 请求）。 DRM 主进程随后使用 DRM_IOCTL_AUTH_MAGIC ioctl 将令牌发送回 DRM 设备。 基于接收到的令牌，设备授予发起身份验证的非 DRM 主应用特殊权限。 这个身份验证令牌允许非 DRM 主进程执行特定的特权操作。通过将令牌与相应的文件描述符（fd）关联，设备授权应用访问特定资源或执行受限操作。这种机制确保只有经过身份验证的调用者才能访问特定的 DRM 功能。 DRM_IOCTL_DROP_MASTER 它允许用户空间程序放弃 DRM 主身份。让我们详细了解一下这个接口的作用和实现： 接口作用： DRM_IOCTL_DROP_MASTER 允许用户空间程序放弃 DRM 主身份。 当程序执行此 ioctl 时，它会失去独占管理显示相关操作的特权。 相反，DRM_IOCTL_SET_MASTER ioctl 可用于成为 DRM 主。 实现细节： 通过执行 DRM_IOCTL_DROP_MASTER，用户空间程序可以放弃 DRM 主身份。 这在需要切换 DRM 主时很有用，例如在关闭/打开主设备节点时。 通常情况下，X 服务器（Xorg）充当 DRM 主。 GEM DRM_IOCTL_GEM_CLOSE 它用于关闭 GEM 缓冲区（Graphics Execution Manager）。让我们详细了解一下这个接口的作用和实现： 接口作用： DRM_IOCTL_GEM_CLOSE 用于关闭 GEM 缓冲区。 在执行此 ioctl 后，GEM 缓冲区的句柄将不再可用于当前进程，并且可能被 GEM API 重新用于新的 GEM 对象。 实现细节： 用户空间程序可以通过执行 DRM_IOCTL_GEM_CLOSE 来关闭 GEM 缓冲区。 这在释放资源或管理内存时非常有用。 请注意，GEM 缓冲区的关闭不会立即释放内存，而是将其标记为不再使用，以便稍后进行回收。 DRM_IOCTL_GEM_FLINK 它用于为 GEM 缓冲区（Graphics Execution Manager）创建一个名称。让我们详细了解一下这个接口的作用和实现： 接口作用： DRM_IOCTL_GEM_FLINK 用于为 GEM 缓冲区创建一个名称。 在执行此 ioctl 后，您可以使用这个名称来引用该 GEM 缓冲区。 实现细节： 用户空间程序可以通过执行 DRM_IOCTL_GEM_FLINK 来为 GEM 缓冲区创建一个名称。 这在需要在不同进程之间引用 GEM 对象时非常有用。 请注意，这个名称不能直接用于在 DRM API 中引用对象，应用程序必须使用 DRM_IOCTL_GEM_FLINK 和 DRM_IOCTL_GEM_OPEN ioctl 分别将句柄转换为名称和名称转换为句柄。 DRM_IOCTL_GEM_OPEN 它用于为 GEM 缓冲区（Graphics Execution Manager）创建一个名称。让我们详细了解一下这个接口的作用和实现： 接口作用： DRM_IOCTL_GEM_OPEN 允许用户空间程序为 GEM 缓冲区创建一个名称。 在执行此 ioctl 后，您可以使用这个名称来引用该 GEM 缓冲区。 实现细节： 用户空间程序可以通过执行 DRM_IOCTL_GEM_OPEN 来为 GEM 缓冲区创建一个名称。 这在需要在不同进程之间引用 GEM 对象时非常有用。 请注意，这个名称不能直接用于在 DRM API 中引用对象，应用程序必须使用 DRM_IOCTL_GEM_FLINK 和 DRM_IOCTL_GEM_OPEN ioctl 分别将句柄转换为名称和名称转换为句柄。 DRM_IOCTL_PRIME_HANDLE_TO_FD 它用于将 GEM 缓冲区（Graphics Execution Manager）的句柄转换为文件描述符（fd）。让我们详细了解一下这个接口的作用和实现： 接口作用： DRM_IOCTL_PRIME_HANDLE_TO_FD 允许用户空间程序将 GEM 缓冲区的句柄转换为文件描述符。 这在需要在不同进程之间共享 GEM 缓冲区时非常有用，例如用于跨进程的纹理共享。 实现细节： 用户空间程序可以通过执行 DRM_IOCTL_PRIME_HANDLE_TO_FD 来获取文件描述符。 这个接口通常与其他进程之间的 IPC（进程间通信）一起使用，以便共享 GEM 缓冲区。 请注意，这个接口的实现可能因不同的 DRM 驱动而有所不同，具体细节可以查阅特定驱动的文档或源代码。 相关CMD DRM_IOCTL_PRIME_FD_TO_HANDLE Resource DRM_IOCTL_MODE_GETRESOURCES 它允许用户空间程序获取与 DRM 设备相关的资源信息。让我们详细了解一下这个接口的作用和实现： 接口作用： DRM_IOCTL_MODE_GETRESOURCES 用于获取与 DRM 设备相关的资源信息。 这个接口通常用于查询设备的帧缓冲、连接器、CRTC（显示管道）和编码器的数量和标识符。 实现细节： 用户空间程序可以通过执行 DRM_IOCTL_MODE_GETRESOURCES 来获取资源信息。 返回的结构体 drm_mode_card_res 包含了帧缓冲、连接器、CRTC 和编码器的数量以及相应的标识符。 这个接口对于初始化显示管道、资源管理和模式设置非常重要。 DRM_IOCTL_MODE_GETPLANERESOURCES 它用于获取Direct Rendering Manager (DRM)的资源。DRM是Linux内核的一部分，负责处理图形硬件的底层细节。 在使用DRM_IOCTL_MODE_GETPLANERESOURCES时，你需要打开一个DRM设备（例如/dev/dri/card0），然后使用这个ioctl调用来获取资源。这些资源包括帧缓冲区（framebuffers）、CRTC（Cathode Ray Tube Controller）、连接器（connectors）和编码器（encoders）。 这些资源的含义如下： 帧缓冲区（Framebuffers）：它们包含要显示的像素数据。 CRTC：CRTC代表整个显示管道，它从一个或多个平面获取像素数据进行混合。 连接器（Connectors）：在DRM中，连接器是显示接收器的一般抽象，包括固定面板或任何其他可以以某种形式显示像素的设备。 编码器（Encoders）：编码器从CRTC获取像素数据，并将其转换为任何连接的连接器可以接受的格式。 请注意，这些资源的数量可能会根据你的硬件配置和当前的显示设置而变化。在使用这些资源之前，你可能需要检查它们的可用性和状态。。 DRM_IOCTL_MODE_GETCRTC 是一种用于获取有关给定 CRTC（Cathode Ray Tube Controller）的信息的 IOCTL（Input/Output Control）命令。详情如下： CRTC 是什么？ CRTC 是显示控制器，负责将图形数据发送到显示设备（例如显示器或电视）。 它管理像素时钟、扫描线和帧缓冲区的刷新。 DRM_IOCTL_MODE_GETCRTC 的作用 通过调用 DRM_IOCTL_MODE_GETCRTC，应用程序可以获取有关特定 CRTC 的信息。 这些信息可能包括 CRTC 的当前模式、分辨率、刷新率等。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_MODE_GETCRTC，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_GETOUTPUT：获取有关特定输出的信息。 DRM_IOCTL_MODE_SETCRTC：设置 CRTC 参数。 DRM_IOCTL_MODE_ADDFB：添加新的帧缓冲区对象。 DRM_IOCTL_MODE_RMFB：移除帧缓冲区对象。 DRM_IOCTL_MODE_SETCRTC 用于在 Linux 内核模式设置（KMS） 中设置特定 CRTC（Cathode Ray Tube Controller） 的参数。详情如下： CRTC 是什么？ CRTC 是显示控制器，负责将图形数据发送到显示设备（例如显示器或电视）。 它管理像素时钟、扫描线和帧缓冲区的刷新。 DRM_IOCTL_MODE_SETCRTC 的作用 通过调用 DRM_IOCTL_MODE_SETCRTC，应用程序可以设置特定 CRTC 的参数，例如分辨率、刷新率等。 这对于配置显示输出非常重要。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_MODE_SETCRTC，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_GETCRTC：获取有关特定 CRTC 的信息。 DRM_IOCTL_MODE_ADDFB：添加新的帧缓冲区对象。 DRM_IOCTL_MODE_RMFB：移除帧缓冲区对象。 DRM_IOCTL_MODE_GETPLANE 用于从 Linux 内核模式设置（KMS） 中获取特定 平面（Plane） 的信息。详情如下： DRM_IOCTL_MODE_GETPLANE 的作用 通过调用 DRM_IOCTL_MODE_GETPLANE，应用程序可以获取有关特定平面的信息。 这些信息可能包括平面的当前状态、位置、大小、像素格式等。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_MODE_GETPLANE，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_GETCRTC：获取有关特定 CRTC 的信息。 DRM_IOCTL_MODE_SETCRTC：设置 CRTC 参数。 DRM_IOCTL_MODE_ADDFB：添加新的帧缓冲区对象。 DRM_IOCTL_MODE_RMFB：移除帧缓冲区对象。 DRM_IOCTL_MODE_SETPLANE 用于在 Linux 内核模式设置（KMS） 中设置特定 平面（Plane） 的参数。详情如下： DRM_IOCTL_MODE_SETPLANE 的作用 通过调用 DRM_IOCTL_MODE_SETPLANE，应用程序可以设置特定平面的参数，例如分辨率、刷新率等。 这对于配置显示输出非常重要。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_MODE_SETPLANE，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_GETCRTC：获取有关特定 CRTC 的信息。 DRM_IOCTL_MODE_SETCRTC：设置 CRTC 参数。 DRM_IOCTL_MODE_ADDFB：添加新的帧缓冲区对象。 DRM_IOCTL_MODE_RMFB：移除帧缓冲区对象。 Cursor DRM_IOCTL_MODE_CURSOR 用于操作特定 CRTC（Cathode Ray Tube Controller） 的 光标平面（Cursor Plane）。详情如下： CRTC 是什么？ CRTC 是显示控制器，负责将图形数据发送到显示设备（例如显示器或电视）。 它管理像素时钟、扫描线和帧缓冲区的刷新。 光标平面（Cursor Plane）的作用 光标平面 是一种特殊的显示平面，用于显示光标或其他小型图形元素。 通过调用 DRM_IOCTL_MODE_CURSOR，应用程序可以操作光标平面，例如设置光标的位置、大小、图像等。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_MODE_CURSOR，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_GETCRTC：获取有关特定 CRTC 的信息。 DRM_IOCTL_MODE_SETCRTC：设置 CRTC 参数。 DRM_IOCTL_MODE_ADDFB：添加新的帧缓冲区对象。 DRM_IOCTL_MODE_RMFB：移除帧缓冲区对象。 DRM_IOCTL_MODE_CURSOR2 用于操作特定 CRTC（Cathode Ray Tube Controller） 的 光标平面（Cursor Plane）⁵。详情如下： CRTC 是什么？ CRTC 是显示控制器，负责将图形数据发送到显示设备（例如显示器或电视）。 它管理像素时钟、扫描线和帧缓冲区的刷新。 光标平面（Cursor Plane）的作用 光标平面 是一种特殊的显示平面，用于显示光标或其他小型图形元素。 通过调用 DRM_IOCTL_MODE_CURSOR2，应用程序可以操作光标平面，例如设置光标的位置、大小、图像等。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_MODE_CURSOR2，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_GETCRTC：获取有关特定 CRTC 的信息。 DRM_IOCTL_MODE_SETCRTC：设置 CRTC 参数。 DRM_IOCTL_MODE_ADDFB：添加新的帧缓冲区对象。 DRM_IOCTL_MODE_RMFB：移除帧缓冲区对象。 区别 DRM_IOCTL_MODE_CURSOR 和 DRM_IOCTL_MODE_CURSOR2 都是 IOCTL（Input/Output Control）命令，用于操作特定 CRTC（Cathode Ray Tube Controller） 的 光标平面（Cursor Plane）。它们之间的区别如下： DRM_IOCTL_MODE_CURSOR DRM_IOCTL_MODE_CURSOR 是旧版本的命令，用于设置光标平面的参数，例如光标的位置、大小、图像等。 它遵循旧的光标平面操作语义。 DRM_IOCTL_MODE_CURSOR2 DRM_IOCTL_MODE_CURSOR2 是新版本的命令，用于相同的目的，但可能具有更丰富的功能。 它可能支持更多属性，例如更灵活的光标形状、透明度等。 总之，DRM_IOCTL_MODE_CURSOR2 可能是对 DRM_IOCTL_MODE_CURSOR 的改进或扩展，以提供更好的光标平面控制。 Sync Obj DRM_IOCTL_SYNCOBJ_CREATE 用于在 Linux 内核模式设置（KMS） 中创建 同步对象（Sync Object）。详情如下： 同步对象是什么？ 同步对象 是一种用于协调多个并发任务之间的同步机制。 在图形渲染中，同步对象通常用于确保不同图形操作的执行顺序或避免竞态条件。 DRM_IOCTL_SYNCOBJ_CREATE 的作用 通过调用 DRM_IOCTL_SYNCOBJ_CREATE，应用程序可以创建一个同步对象。 同步对象可以用于跟踪图形操作的完成状态，例如等待渲染完成或等待其他事件。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_SYNCOBJ_CREATE，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_GETCRTC：获取有关特定 CRTC 的信息。 DRM_IOCTL_MODE_SETCRTC：设置 CRTC 参数。 DRM_IOCTL_MODE_ADDFB：添加新的帧缓冲区对象。 DRM_IOCTL_MODE_RMFB：移除帧缓冲区对象。 DRM_IOCTL_SYNCOBJ_HANDLE_TO_FD 用于在 Linux 内核模式设置（KMS） 中将特定 同步对象（Sync Object） 的句柄转换为文件描述符（File Descriptor）。 详情如下： 同步对象是什么？ 同步对象 是一种用于协调多个并发任务之间的同步机制。 在图形渲染中，同步对象通常用于确保不同图形操作的执行顺序或避免竞态条件。 DRM_IOCTL_SYNCOBJ_HANDLE_TO_FD 的作用 通过调用 DRM_IOCTL_SYNCOBJ_HANDLE_TO_FD，应用程序可以将同步对象的句柄转换为文件描述符。 文件描述符是一种用于在进程之间传递句柄的机制。这些文件描述符是不透明的，只能用于传递同步对象句柄。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_SYNCOBJ_HANDLE_TO_FD，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_GETCRTC：获取有关特定 CRTC 的信息。 DRM_IOCTL_MODE_SETCRTC：设置 CRTC 参数。 DRM_IOCTL_MODE_ADDFB：添加新的帧缓冲区对象。 DRM_IOCTL_MODE_RMFB：移除帧缓冲区对象。 DRM_IOCTL_SYNCOBJ_SIGNAL 用于在 Linux 内核模式设置（KMS） 中直接触发特定 同步对象（Sync Object）。这个命令提供了一种用户空间手动触发同步对象的机制。 以下是关于 DRM_IOCTL_SYNCOBJ_SIGNAL 的一些要点： 同步对象是什么？ 同步对象 是一种用于协调多个并发任务之间的同步机制。 在图形渲染中，同步对象通常用于确保不同图形操作的执行顺序或避免竞态条件。 DRM_IOCTL_SYNCOBJ_SIGNAL 的作用 通过调用 DRM_IOCTL_SYNCOBJ_SIGNAL，用户空间可以直接触发特定同步对象。 这对于手动触发同步对象非常有用。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_SYNCOBJ_SIGNAL，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_GETCRTC：获取有关特定 CRTC 的信息。 DRM_IOCTL_MODE_SETCRTC：设置 CRTC 参数。 DRM_IOCTL_MODE_ADDFB：添加新的帧缓冲区对象。 DRM_IOCTL_MODE_RMFB：移除帧缓冲区对象。 Lease DRM_IOCTL_MODE_CREATE_LEASE 用于在 Linux 内核模式设置（KMS） 中创建 租约（Lease）。详情如下： 租约是什么？ 租约 是一种机制，用于管理图形资源的共享和访问权限。 在多个图形客户端之间，租约允许控制对特定资源（例如帧缓冲区、平面、连接器等）的访问。 DRM_IOCTL_MODE_CREATE_LEASE 的作用 通过调用 DRM_IOCTL_MODE_CREATE_LEASE，应用程序可以创建一个租约。 租约可以用于协调多个图形客户端之间的资源共享，以确保资源的正确使用和访问权限。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_MODE_CREATE_LEASE，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_GETCRTC：获取有关特定 CRTC 的信息。 DRM_IOCTL_MODE_SETCRTC：设置 CRTC 参数。 DRM_IOCTL_MODE_ADDFB：添加新的帧缓冲区对象。 DRM_IOCTL_MODE_RMFB：移除帧缓冲区对象。 DRM_IOCTL_MODE_LIST_LESSEES 用于从 Linux 内核模式设置（KMS） 中获取特定 租约（Lease） 所有租户（lessees）的标识符（identifiers）。 以下是关于 DRM_IOCTL_MODE_LIST_LESSEES 的一些要点： 租约是什么？ 租约 是一种机制，用于管理图形资源的共享和访问权限。 在多个图形客户端之间，租约允许控制对特定资源（例如帧缓冲区、平面、连接器等）的访问。 DRM_IOCTL_MODE_LIST_LESSEES 的作用 通过调用 DRM_IOCTL_MODE_LIST_LESSEES，应用程序可以获取特定租约的所有租户的标识符。 这对于了解租约的使用情况以及资源共享非常有用。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_MODE_LIST_LESSEES，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_GETCRTC：获取有关特定 CRTC 的信息。 DRM_IOCTL_MODE_SETCRTC：设置 CRTC 参数。 DRM_IOCTL_MODE_ADDFB：添加新的帧缓冲区对象。 DRM_IOCTL_MODE_RMFB：移除帧缓冲区对象。 DRM_IOCTL_MODE_GET_LEASE 用于从 Linux 内核模式设置（KMS） 中获取特定 租约（Lease） 的信息。详情如下： 租约是什么？ 租约 是一种机制，用于管理图形资源的共享和访问权限。 在多个图形客户端之间，租约允许控制对特定资源（例如帧缓冲区、平面、连接器等）的访问。 DRM_IOCTL_MODE_GET_LEASE 的作用 通过调用 DRM_IOCTL_MODE_GET_LEASE，应用程序可以获取有关特定租约的信息。 这些信息可能包括租约的状态、租约的资源列表、租约的持有者等。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_MODE_GET_LEASE，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_CREATE_LEASE：创建租约。 DRM_IOCTL_MODE_LIST_LESSEES：列出租约的所有租户。 DRM_IOCTL_MODE_REVOKE_LEASE 用于在 Linux 内核模式设置（KMS） 中撤销特定 租约（Lease） 的权限。 以下是关于 DRM_IOCTL_MODE_REVOKE_LEASE 的一些要点： 租约是什么？ 租约 是一种机制，用于管理图形资源的共享和访问权限。 在多个图形客户端之间，租约允许控制对特定资源（例如帧缓冲区、平面、连接器等）的访问。 DRM_IOCTL_MODE_REVOKE_LEASE 的作用 通过调用 DRM_IOCTL_MODE_REVOKE_LEASE，应用程序可以撤销特定租约的权限。 这对于限制资源的访问或更改租约的状态非常有用。 其他 DRM IOCTL 命令 除了 DRM_IOCTL_MODE_REVOKE_LEASE，还有其他与显示设置相关的 IOCTL 命令，例如： DRM_IOCTL_MODE_CREATE_LEASE：创建租约。 DRM_IOCTL_MODE_LIST_LESSEES：列出租约的所有租户。"
  },"/blog/jekyll/2000-04-27-linux_grpahic_architecture.html": {
    "title": "Linux graphic arch",
    "keywords": "Jekyll",
    "url": "/blog/jekyll/2000-04-27-linux_grpahic_architecture.html",
    "body": ""
  }}
